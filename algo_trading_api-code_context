# File: app/channels/application_cable/channel.rb
# frozen_string_literal: true

module ApplicationCable
  class Channel < ActionCable::Channel::Base
  end
end


# File: app/channels/application_cable/connection.rb
# frozen_string_literal: true

require 'securerandom'

module ApplicationCable
  class Connection < ActionCable::Connection::Base
    identified_by :connection_id

    def connect
      self.connection_id = SecureRandom.uuid
    end
  end
end


# File: app/controllers/api/health_controller.rb
# frozen_string_literal: true

module Api
  class HealthController < ApplicationController
    def show
      render json: {
        mode: AlgoConfig.mode,
        watchlist: WatchlistItem.where(active: true).count,
        active_positions: PositionTracker.active.count,
        scheduler: scheduler_status,
        # circuit_breaker: Risk::CircuitBreaker.instance.status, # Disabled - removed per requirement
        websocket: {
          market_feed_running: Live::MarketFeedHub.instance.running?,
          # NOTE: Order updates use PositionSyncService polling (not WebSocket)
          order_update_running: Live::OrderUpdateHub.instance.running?,
          tick_cache_size: Live::TickCache.all.size,
          sample_ltps: {
            nifty: Live::TickCache.ltp('IDX_I', '13'),
            banknifty: Live::TickCache.ltp('IDX_I', '25'),
            sensex: Live::TickCache.ltp('IDX_I', '51')
          }
        }
      }
    end

    private

    def scheduler_status
      Thread.list.any? { |thread| thread.name == 'signal-scheduler' } ? 'running' : 'unknown'
    end
  end
end


# File: app/controllers/api/test_controller.rb
# frozen_string_literal: true

module Api
  class TestController < ApplicationController
    def broadcast
      tick_data = {
        segment: params[:segment] || 'IDX_I',
        security_id: params[:security_id] || '13',
        ltp: params[:ltp] || rand(25_000..25_999),
        kind: :quote,
        ts: Time.current.to_i
      }

      # Store in TickCache instead of broadcasting
      Live::TickCache.put(tick_data)

      render json: {
        success: true,
        message: 'Test tick stored in TickCache',
        data: tick_data
      }
    end
  end
end


# File: app/controllers/application_controller.rb
# frozen_string_literal: true

class ApplicationController < ActionController::API
end


# File: app/jobs/application_job.rb
# frozen_string_literal: true

class ApplicationJob < ActiveJob::Base
  # Automatically retry jobs that encountered a deadlock
  # retry_on ActiveRecord::Deadlocked

  # Most jobs are safe to ignore if the underlying records are no longer available
  # discard_on ActiveJob::DeserializationError
end


# File: app/lib/algo_config.rb
# frozen_string_literal: true

class AlgoConfig
  class << self
    def fetch
      @fetch ||= YAML.load_file(Rails.root.join('config/algo.yml')).deep_symbolize_keys
    end

    def mode
      fetch[:mode]
    end
  end
end


# File: app/lib/market/calendar.rb
# frozen_string_literal: true

module Market
  class Calendar
    # Indian market holidays for 2024-2025 (simplified list)
    # In production, this should be loaded from a more comprehensive source
    MARKET_HOLIDAYS = [].freeze

    class << self
      # Returns today if it's a trading day, otherwise the last trading day
      def today_or_last_trading_day
        today = Date.current
        return today if trading_day?(today)

        # Go back day by day until we find a trading day
        (1..7).each do |days_back|
          candidate = today - days_back.days
          return candidate if trading_day?(candidate)
        end

        # Fallback (shouldn't happen in normal circumstances)
        today - 1.day
      end

      # Returns the date that was n trading days ago
      def trading_days_ago(n)
        current = Date.current
        trading_days_counted = 0

        # Start from yesterday to avoid counting today if it's not a trading day
        (1..30).each do |days_back|
          candidate = current - days_back.days
          if trading_day?(candidate)
            trading_days_counted += 1
            return candidate if trading_days_counted == n
          end
        end

        # Fallback
        current - n.days
      end

      # Returns the next trading day
      def next_trading_day
        today = Date.current
        (1..7).each do |days_forward|
          candidate = today + days_forward.days
          return candidate if trading_day?(candidate)
        end

        # Fallback
        today + 1.day
      end

      # Checks if a given date is a trading day
      def trading_day?(date)
        return false if date.saturday? || date.sunday?
        return false if MARKET_HOLIDAYS.include?(date.strftime('%Y-%m-%d'))

        true
      end

      # Returns true if today is a trading day
      def trading_day_today?
        trading_day?(Date.current)
      end

      # Returns the number of trading days between two dates
      def trading_days_between(start_date, end_date)
        return 0 if start_date >= end_date

        count = 0
        current = start_date + 1.day

        while current <= end_date
          count += 1 if trading_day?(current)
          current += 1.day
        end

        count
      end
    end
  end
end


# File: app/mailers/application_mailer.rb
# frozen_string_literal: true

class ApplicationMailer < ActionMailer::Base
  default from: 'from@example.com'
  layout 'mailer'
end


# File: app/models/application_record.rb
# frozen_string_literal: true

class ApplicationRecord < ActiveRecord::Base
  primary_abstract_class
end


# File: app/models/candle.rb
# frozen_string_literal: true

class Candle
  attr_reader :timestamp, :open, :high, :low, :close, :volume

  def initialize(ts:, open:, high:, low:, close:, volume:)
    @timestamp = ts
    @open = open.to_f
    @high = high.to_f
    @low = low.to_f
    @close = close.to_f
    @volume = volume.to_i
  end

  def bullish?
    close >= open
  end

  def bearish?
    close < open
  end
end


# File: app/models/candle_series.rb
# frozen_string_literal: true

class CandleSeries
  include Enumerable

  attr_reader :symbol, :interval, :candles

  def initialize(symbol:, interval: '5')
    @symbol = symbol
    @interval = interval
    @candles = []
  end

  def each(&) = candles.each(&)
  def add_candle(candle) = candles << candle

  def load_from_raw(response)
    normalise_candles(response).each do |row|
      @candles << Candle.new(
        ts: Time.zone.parse(row[:timestamp].to_s),
        open: row[:open], high: row[:high],
        low: row[:low], close: row[:close],
        volume: row[:volume]
      )
    end
  end

  def normalise_candles(resp)
    return [] if resp.blank?

    return resp.map { |c| slice_candle(c) } if resp.is_a?(Array)

    raise "Unexpected candle format: #{resp.class}" unless resp.is_a?(Hash) && resp['high'].is_a?(Array)

    size = resp['high'].size
    (0...size).map do |i|
      {
        open: resp['open'][i].to_f,
        close: resp['close'][i].to_f,
        high: resp['high'][i].to_f,
        low: resp['low'][i].to_f,
        timestamp: Time.zone.at(resp['timestamp'][i]),
        volume: resp['volume'][i].to_i
      }
    end
  end

  def slice_candle(candle)
    if candle.is_a?(Hash)
      {
        open: candle[:open] || candle['open'],
        close: candle[:close] || candle['close'],
        high: candle[:high] || candle['high'],
        low: candle[:low] || candle['low'],
        timestamp: candle[:timestamp] || candle['timestamp'],
        volume: candle[:volume] || candle['volume'] || 0
      }
    elsif candle.respond_to?(:[]) && candle.size >= 6
      {
        timestamp: candle[0],
        open: candle[1],
        high: candle[2],
        low: candle[3],
        close: candle[4],
        volume: candle[5]
      }
    else
      raise "Unexpected candle format: #{candle.inspect}"
    end
  end

  def opens  = candles.map(&:open)
  def closes = candles.map(&:close)
  def highs  = candles.map(&:high)
  def lows   = candles.map(&:low)

  def to_hash
    {
      'timestamp' => candles.map { |c| c.timestamp.to_i },
      'open' => opens,
      'high' => highs,
      'low' => lows,
      'close' => closes,
      'volume' => candles.map(&:volume)
    }
  end

  def hlc
    candles.each_with_index.map do |c, _i|
      {
        date_time: Time.zone.at(c.timestamp || 0),
        high: c.high,
        low: c.low,
        close: c.close
      }
    end
  end

  def atr(period = 14)
    return nil if candles.size < period + 1

    TechnicalAnalysis::Atr.calculate(hlc, period: period).first.atr
  rescue TechnicalAnalysis::Validation::ValidationError => e
    Rails.logger.warn("[CandleSeries] ATR calculation failed: #{e.message}")
    nil
  rescue ArgumentError, TypeError => e
    Rails.logger.warn("[CandleSeries] ATR calculation failed: #{e.message}")
    nil
  rescue StandardError => e
    raise if e.is_a?(NoMethodError)

    Rails.logger.warn("[CandleSeries] ATR calculation failed: #{e.message}")
    nil
  end

  def adx(period = 14)
    return nil if candles.size < period + 1

    result = TechnicalAnalysis::Adx.calculate(hlc, period: period)
    return nil if result.empty?

    result.last.adx
  rescue ArgumentError, TypeError, StandardError => e
    # Don't catch NoMethodError as it indicates programming errors
    raise if e.is_a?(NoMethodError)

    Rails.logger.warn("[CandleSeries] ADX calculation failed: #{e.message}")
    nil
  end

  def swing_high?(index, lookback = 2)
    return false if index < lookback || index + lookback >= candles.size

    current = candles[index].high
    left = candles[(index - lookback)...index].map(&:high)
    right = candles[(index + 1)..(index + lookback)].map(&:high)
    current > left.max && current > right.max
  end

  def swing_low?(index, lookback = 2)
    return false if index < lookback || index + lookback >= candles.size

    current = candles[index].low
    left = candles[(index - lookback)...index].map(&:low)
    right = candles[(index + 1)..(index + lookback)].map(&:low)
    current < left.min && current < right.min
  end

  def recent_highs(n = 20)
    candles.last(n).map(&:high)
  end

  def recent_lows(n = 20)
    candles.last(n).map(&:low)
  end

  def previous_swing_high
    values = recent_highs
    return nil if values.size < 2

    values.sort[-2]
  end

  def previous_swing_low
    values = recent_lows
    return nil if values.size < 2

    values.sort[1]
  end

  def liquidity_grab_up?(_lookback: 20)
    return false if candles.empty?

    high_now = candles.last.high
    high_prev = previous_swing_high
    return false unless high_prev

    high_now > high_prev &&
      candles.last.close < high_prev &&
      candles.last.bearish?
  end

  def liquidity_grab_down?(_lookback: 20)
    return false if candles.empty?

    low_now = candles.last.low
    low_prev = previous_swing_low
    return false unless low_prev

    low_now < low_prev &&
      candles.last.close > low_prev &&
      candles.last.bullish?
  end

  def rsi(period = 14)
    return nil if candles.empty?

    RubyTechnicalAnalysis::RelativeStrengthIndex.new(series: closes, period: period).call
  rescue ArgumentError, TypeError => e
    Rails.logger.warn("[CandleSeries] RSI calculation failed: #{e.message}")
    nil
  rescue StandardError => e
    raise if e.is_a?(NoMethodError)

    Rails.logger.warn("[CandleSeries] RSI calculation failed: #{e.message}")
    nil
  end

  def moving_average(period = 20)
    return nil if candles.empty?

    RubyTechnicalAnalysis::MovingAverages.new(series: closes, period: period)
  end

  def sma(period = 20)
    return nil if candles.empty?

    moving_average(period)&.sma
  end

  def ema(period = 20)
    return nil if candles.empty?

    moving_average(period)&.ema
  end

  def macd(fast_period = 12, slow_period = 26, signal_period = 9)
    return nil if candles.empty?
    return nil if closes.size < slow_period + signal_period

    macd = RubyTechnicalAnalysis::Macd.new(series: closes, fast_period: fast_period, slow_period: slow_period,
                                           signal_period: signal_period)
    result = macd.call
    return nil if result.nil? || !result.is_a?(Array) || result.size < 3

    result # Returns [macd, signal, histogram] array
  rescue ArgumentError, TypeError, StandardError => e
    raise if e.is_a?(NoMethodError)

    Rails.logger.warn("[CandleSeries] MACD calculation failed: #{e.message}")
    nil
  end

  def rate_of_change(period = 5)
    return nil if closes.size < period + 1

    closes.each_with_index.map do |price, idx|
      if idx < period
        nil
      else
        previous_price = closes[idx - period]
        (((price - previous_price) / previous_price.to_f) * 100.0)
      end
    end
  end

  def supertrend_signal
    result = Indicators::Supertrend.new(series: self).call
    trend_line = result[:line] || []
    return nil if trend_line.empty?

    case result[:trend]
    when :bullish
      return :long_entry
    when :bearish
      return :short_entry
    end

    latest_index = trend_line.rindex { |value| !value.nil? }
    return nil if latest_index.nil?

    latest_close = closes[latest_index]
    latest_trend = trend_line[latest_index]
    return nil if latest_close.nil? || latest_trend.nil?

    return :long_entry if latest_close > latest_trend

    :short_entry if latest_close < latest_trend
  end

  def inside_bar?(i)
    return false if i < 1

    curr = @candles[i]
    prev = @candles[i - 1]
    curr.high < prev.high && curr.low > prev.low
  end

  def bollinger_bands(period: 20, std_dev: 2.0) # rubocop:disable Lint/UnusedMethodArgument
    # std_dev parameter kept for API compatibility but not used by library
    return nil if candles.size < period

    bb = RubyTechnicalAnalysis::BollingerBands.new(
      series: closes,
      period: period
    ).call

    { upper: bb[0], lower: bb[1], middle: bb[2] }
  end

  def donchian_channel(period: 20)
    return nil if candles.size < period

    dc = candles.each_with_index.map do |c, _i|
      {
        date_time: Time.zone.at(c.timestamp || 0),
        value: c.close
      }
    end
    TechnicalAnalysis::Dc.calculate(dc, period: period)
  end

  def obv
    return nil if candles.empty?

    dcv = candles.each_with_index.map do |c, _i|
      {
        date_time: Time.zone.at(c.timestamp || 0),
        close: c.close,
        volume: c.volume || 0
      }
    end

    # OBV.calculate is a class method that takes an array of hashes
    # The gem expects the data in a specific format
    TechnicalAnalysis::Obv.calculate(dcv)
  rescue ArgumentError => e
    # OBV.calculate might have different signature - try alternative approach
    Rails.logger.warn("[CandleSeries] OBV calculation failed: #{e.message}")
    nil
  rescue TypeError, StandardError => e
    raise if e.is_a?(NoMethodError)

    Rails.logger.warn("[CandleSeries] OBV calculation failed: #{e.message}")
    nil
  end
end


# File: app/models/concerns/candle_extension.rb
# frozen_string_literal: true

module CandleExtension
  extend ActiveSupport::Concern

  included do
    def candles(interval: '5')
      @ohlc_cache ||= {}

      # Check if caching is disabled for fresh data
      freshness_config = AlgoConfig.fetch[:data_freshness] || {}
      disable_caching = freshness_config[:disable_ohlc_caching] || false

      if disable_caching
        # Rails.logger.debug { "[CandleExtension] Fresh data mode - bypassing cache for #{symbol_name}" }
        return fetch_fresh_candles(interval)
      end

      cached_series = @ohlc_cache[interval]
      return cached_series if cached_series && !ohlc_stale?(interval)

      fetch_fresh_candles(interval)
    end

    def fetch_fresh_candles(interval)
      raw_data = intraday_ohlc(interval: interval)
      return nil if raw_data.blank?

      @ohlc_cache[interval] = CandleSeries.new(symbol: symbol_name, interval: interval).tap do |series|
        series.load_from_raw(raw_data)
      end
    end

    def ohlc_stale?(interval)
      @last_ohlc_fetched ||= {}

      # Use configured cache duration or default
      freshness_config = AlgoConfig.fetch[:data_freshness] || {}
      cache_duration_minutes = freshness_config[:ohlc_cache_duration_minutes] || 5

      return true unless @last_ohlc_fetched[interval]

      Time.current - @last_ohlc_fetched[interval] > cache_duration_minutes.minutes
    ensure
      @last_ohlc_fetched[interval] = Time.current
    end

    def candle_series(interval: '5')
      candles(interval: interval)
    end

    def rsi(period = 14, interval: '5')
      cs = candles(interval: interval)
      cs&.rsi(period)
    end

    def macd(fast_period = 12, slow_period = 26, signal_period = 9, interval: '5')
      cs = candles(interval: interval)
      macd_result = cs&.macd(fast_period, slow_period, signal_period)
      return nil unless macd_result

      {
        macd: macd_result[0],
        signal: macd_result[1],
        histogram: macd_result[2]
      }
    end

    def adx(period = 14, interval: '5')
      cs = candles(interval: interval)
      cs&.adx(period)
    end

    def supertrend_signal(interval: '5')
      cs = candles(interval: interval)
      cs&.supertrend_signal
    end

    def liquidity_grab_up?(interval: '5')
      cs = candles(interval: interval)
      cs&.liquidity_grab_up?
    end

    def liquidity_grab_down?(interval: '5')
      cs = candles(interval: interval)
      cs&.liquidity_grab_down?
    end

    def bollinger_bands(period: 20, interval: '5')
      cs = candles(interval: interval)
      return nil unless cs

      cs.bollinger_bands(period: period)
    end

    def donchian_channel(period: 20, interval: '5')
      cs = candles(interval: interval)
      return nil unless cs

      dc = cs.candles.each_with_index.map do |c, _i|
        {
          date_time: Time.zone.at(c.timestamp || 0),
          value: c.close
        }
      end
      TechnicalAnalysis::Dc.calculate(dc, period: period)
    end

    def obv(interval: '5')
      series = candles(interval: interval)
      return nil unless series

      dcv = series.candles.each_with_index.map do |c, _i|
        {
          date_time: Time.zone.at(c.timestamp || 0),
          close: c.close,
          volume: c.volume || 0
        }
      end

      TechnicalAnalysis::Obv.calculate(dcv)
    end
  end
end


# File: app/models/concerns/instrument_helpers.rb
# frozen_string_literal: true

require 'bigdecimal'
require 'date'

module InstrumentHelpers
  extend ActiveSupport::Concern
  include CandleExtension

  included do
    enum :exchange, { nse: 'NSE', bse: 'BSE', mcx: 'MCX' }
    enum :segment, { index: 'I', equity: 'E', currency: 'C', derivatives: 'D', commodity: 'M' }, prefix: true
    enum :instrument_code, {
      index: 'INDEX',
      futures_index: 'FUTIDX',
      options_index: 'OPTIDX',
      equity: 'EQUITY',
      futures_stock: 'FUTSTK',
      options_stock: 'OPTSTK',
      futures_currency: 'FUTCUR',
      options_currency: 'OPTCUR',
      futures_commodity: 'FUTCOM',
      options_commodity: 'OPTFUT'
    }, prefix: true

    scope :nse, -> { where(exchange: 'NSE') }
    scope :bse, -> { where(exchange: 'BSE') }

    def subscribe
      Live::WsHub.instance.subscribe(seg: exchange_segment, sid: security_id.to_s)
      # Rails.logger.info("Subscribed #{self.class.name} #{security_id} to WS feed.")
      true
    rescue StandardError => e
      Rails.logger.error("Failed to subscribe #{self.class.name} #{security_id}: #{e.message}")
      false
    end

    def unsubscribe
      Live::WsHub.instance.unsubscribe(seg: exchange_segment, sid: security_id.to_s)
      # Rails.logger.info("Unsubscribed #{self.class.name} #{security_id} from WS feed.")
      true
    rescue StandardError => e
      Rails.logger.error("Failed to unsubscribe #{self.class.name} #{security_id}: #{e.message}")
      false
    end
  end

  def ltp
    # Priority: WebSocket TickCache > REST API
    hub = Live::MarketFeedHub.instance

    # Check WebSocket cache first
    if hub.running? && hub.connected?
      cached_ltp = ws_ltp
      return cached_ltp if cached_ltp.present? && cached_ltp.to_f.positive?
    end

    # Fallback to REST API
    fetch_ltp_from_api
  rescue StandardError => e
    # Suppress 429 rate limit errors (expected during high load)
    error_msg = e.message.to_s
    is_rate_limit = error_msg.include?('429') || error_msg.include?('rate limit') || error_msg.include?('Rate limit')
    Rails.logger.error("Failed to fetch LTP for #{self.class.name} #{security_id}: #{error_msg}") unless is_rate_limit
    nil
  end

  def latest_ltp
    price = ws_ltp || quote_ltp || fetch_ltp_from_api
    price.present? ? BigDecimal(price.to_s) : nil
  end

  # Resolves an actionable LTP for downstream order placement.
  # Priority order:
  # 1. `meta[:ltp]` if provided
  # 2. WebSocket tick cache via Live::RedisPnlCache (if WS connected and fresh)
  # 3. REST API via instrument/derivative object (fallback when WS unavailable)
  # 4. nil (if all methods fail)
  #
  # @param segment [String]
  # @param security_id [String, Integer]
  # @param meta [Hash]
  # @param fallback_to_api [Boolean] Whether to fallback to REST API if WS unavailable
  # @return [BigDecimal, nil]
  def resolve_ltp(segment:, security_id:, meta: {}, fallback_to_api: true)
    ltp_from_meta = meta&.dig(:ltp)
    return BigDecimal(ltp_from_meta.to_s) if ltp_from_meta.present?

    # Try WebSocket cache if hub is connected and ticks are fresh
    hub = Live::MarketFeedHub.instance
    if hub.running? && hub.connected?
      tick = Live::TickCache.get(segment: segment, security_id: security_id)
      return BigDecimal(tick[:ltp].to_s) if tick&.dig(:ltp)
    end

    # Fallback to REST API when WebSocket unavailable or cache miss
    if fallback_to_api
      api_ltp = fetch_ltp_from_api_for_segment(segment: segment, security_id: security_id)
      return BigDecimal(api_ltp.to_s) if api_ltp.present?
    end

    nil
  rescue StandardError => e
    Rails.logger.error("Failed to resolve LTP for #{segment}:#{security_id} - #{e.message}")
    nil
  end

  # Fetches LTP from REST API for a specific segment and security_id
  # Prioritizes WebSocket/TickCache to avoid API rate limits
  # @param segment [String] Exchange segment (e.g., "IDX_I", "NSE_FNO")
  # @param security_id [String, Integer] Security ID
  # @return [Numeric, nil]
  def fetch_ltp_from_api_for_segment(segment:, security_id:)
    hub = Live::MarketFeedHub.instance

    # Strategy 1: Check WebSocket TickCache first (fastest, no API rate limits)
    if hub.running? && hub.connected?
      cached_ltp = Live::TickCache.ltp(segment, security_id)
      if cached_ltp.present? && cached_ltp.to_f.positive?
        Rails.logger.debug { "[InstrumentHelpers] Got LTP from TickCache for #{segment}:#{security_id}: ₹#{cached_ltp}" }
        return cached_ltp.to_f
      end

      # If not in cache, try subscribing and waiting briefly for a tick
      begin
        hub.subscribe(segment: segment, security_id: security_id)
        # Wait up to 200ms for tick to arrive
        4.times do
          sleep(0.05) # 50ms intervals
          cached_ltp = Live::TickCache.ltp(segment, security_id)
          if cached_ltp.present? && cached_ltp.to_f.positive?
            Rails.logger.debug { "[InstrumentHelpers] Got LTP from TickCache after subscription for #{segment}:#{security_id}: ₹#{cached_ltp}" }
            return cached_ltp.to_f
          end
        end
      rescue StandardError => e
        Rails.logger.debug { "[InstrumentHelpers] WebSocket subscription failed for #{segment}:#{security_id}: #{e.message}, falling back to API" }
      end
    end

    # Strategy 2: REST API fallback (only if WebSocket unavailable or no tick received)
    segment_enum = segment.to_s.upcase
    payload = { segment_enum => [security_id.to_i] }
    response = DhanHQ::Models::MarketFeed.ltp(payload)

    return nil unless response.is_a?(Hash) && response['status'] == 'success'

    data = response.dig('data', segment_enum, security_id.to_s)
    data&.dig('last_price')
  rescue StandardError => e
    # Suppress 429 rate limit errors (expected during high load)
    error_msg = e.message.to_s
    is_rate_limit = error_msg.include?('429') || error_msg.include?('rate limit') || error_msg.include?('Rate limit')
    unless is_rate_limit
      Rails.logger.error("Failed to fetch LTP from API for #{self.class.name} #{security_id}: #{error_msg}")
    end
    nil
  end

  # Generates a short, gateway-safe client order identifier.
  # @param side [Symbol, String]
  # @param security_id [String]
  # @return [String]
  def default_client_order_id(side:, security_id:)
    ts = Time.current.to_i.to_s[-6..]
    "AS-#{side.to_s.upcase[0..2]}-#{security_id}-#{ts}"
  end

  # Ensures the WebSocket hub is actively streaming ticks for the instrument.
  # Raises if the hub is offline to avoid blind entries.
  # @param segment [String]
  # @param security_id [String]
  # @return [true]
  def ensure_ws_subscription!(segment:, security_id:)
    hub = Live::WsHub.instance
    unless hub.running?
      Rails.logger.error('[InstrumentHelpers] WebSocket hub is not running. Aborting subscription.')
      raise 'WebSocket hub not running'
    end

    hub.subscribe(seg: segment, sid: security_id.to_s)
    true
  end

  # Creates a PositionTracker immediately after order placement and primes caches.
  # @param instrument [Instrument]
  # @param order_no [String]
  # @param segment [String]
  # @param security_id [String]
  # @param side [String]
  # @param qty [Integer]
  # @param entry_price [Numeric]
  # @param symbol [String]
  # @param index_key [String, nil]
  # @return [PositionTracker]
  def after_order_track!(instrument:, order_no:, segment:, security_id:, side:, qty:, entry_price:, symbol:,
                         index_key: nil)
    # Determine watchable: if self is a Derivative, use self; otherwise use instrument
    watchable = is_a?(Derivative) ? self : instrument

    tracker = PositionTracker.build_or_average!(
      watchable: watchable,
      instrument: watchable.is_a?(Derivative) ? watchable.instrument : watchable, # Backward compatibility
      order_no: order_no,
      security_id: security_id.to_s,
      symbol: symbol,
      segment: segment,
      side: side,
      status: 'active',
      quantity: qty.to_i,
      entry_price: BigDecimal(entry_price.to_s),
      meta: index_key ? { 'index_key' => index_key } : {}
    )

    ensure_ws_subscription!(segment: segment, security_id: security_id)
    Live::RedisPnlCache.instance.clear_tick(segment: segment, security_id: security_id.to_s)

    tracker
  end

  def quote_ltp
    return unless respond_to?(:quotes)

    quote = quotes.order(tick_time: :desc).first
    quote&.ltp&.to_f
  rescue StandardError => e
    Rails.logger.error("Failed to fetch latest quote LTP for #{self.class.name} #{security_id}: #{e.message}")
    nil
  end

  def fetch_ltp_from_api
    # This method is called by ltp() which already checks WebSocket first
    # But we still check here as a safety net in case called directly
    hub = Live::MarketFeedHub.instance

    if hub.running? && hub.connected?
      cached_ltp = ws_ltp
      return cached_ltp if cached_ltp.present? && cached_ltp.to_f.positive?

      # Try subscribing and waiting for tick
      begin
        segment = exchange_segment
        return nil unless segment.present? && security_id.present?

        hub.subscribe(segment: segment, security_id: security_id.to_s)
        # Wait up to 200ms for tick
        4.times do
          sleep(0.05)
          cached_ltp = ws_ltp
          return cached_ltp if cached_ltp.present? && cached_ltp.to_f.positive?
        end
      rescue StandardError => e
        Rails.logger.debug { "[InstrumentHelpers] WebSocket subscription failed for #{segment}:#{security_id}: #{e.message}" }
      end
    end

    # REST API fallback
    response = DhanHQ::Models::MarketFeed.ltp(exch_segment_enum)
    response.dig('data', exchange_segment, security_id.to_s, 'last_price') if response['status'] == 'success'
  rescue StandardError => e
    # Suppress 429 rate limit errors (expected during high load)
    error_msg = e.message.to_s
    is_rate_limit = error_msg.include?('429') || error_msg.include?('rate limit') || error_msg.include?('Rate limit')
    unless is_rate_limit
      Rails.logger.error("Failed to fetch LTP from API for #{self.class.name} #{security_id}: #{error_msg}")
    end
    nil
  end

  def subscribe_params
    { ExchangeSegment: exchange_segment, SecurityId: security_id.to_s }
  end

  def ws_get
    Live::TickCache.get(exchange_segment, security_id.to_s)
  end

  def ws_ltp
    ws_get&.dig(:ltp)
  end

  def ohlc
    response = DhanHQ::Models::MarketFeed.ohlc(exch_segment_enum)
    response['status'] == 'success' ? response.dig('data', exchange_segment, security_id.to_s) : nil
  rescue StandardError => e
    Rails.logger.error("Failed to fetch OHLC for #{self.class.name} #{security_id}: #{e.message}")
    nil
  end

  def historical_ohlc(from_date: nil, to_date: nil, oi: false)
    DhanHQ::Models::HistoricalData.daily(
      securityId: security_id,
      exchangeSegment: exchange_segment,
      instrument: instrument_type || resolve_instrument_code,
      oi: oi,
      fromDate: from_date || (Time.zone.today - 365).to_s,
      toDate: to_date || (Time.zone.today - 1).to_s,
      expiryCode: 0
    )
  rescue StandardError => e
    Rails.logger.error("Failed to fetch Historical OHLC for #{self.class.name} #{security_id}: #{e.message}")
    nil
  end

  def intraday_ohlc(interval: '5', oi: false, from_date: nil, to_date: nil, days: 2)
    to_date ||= if defined?(MarketCalendar) && MarketCalendar.respond_to?(:today_or_last_trading_day)
                  MarketCalendar.today_or_last_trading_day.to_s
                else
                  (Time.zone.today - 1).to_s
                end
    from_date ||= (Date.parse(to_date) - days).to_s

    instrument_code = resolve_instrument_code
    DhanHQ::Models::HistoricalData.intraday(
      security_id: security_id,
      exchange_segment: exchange_segment,
      instrument: instrument_code,
      interval: interval,
      oi: oi,
      from_date: from_date || (Time.zone.today - days).to_s,
      to_date: to_date || (Time.zone.today - 1).to_s
    )
  rescue StandardError => e
    Rails.logger.error("Failed to fetch Intraday OHLC for #{self.class.name} #{security_id}: #{e.message}")
    nil
  end

  def exchange_segment
    return self[:exchange_segment] if self[:exchange_segment].present?

    case [exchange&.to_sym, segment&.to_sym]
    when %i[nse index], %i[bse index]
      'IDX_I'
    when %i[nse equity]
      'NSE_EQ'
    when %i[bse equity]
      'BSE_EQ'
    when %i[nse derivatives]
      'NSE_FNO'
    when %i[bse derivatives]
      'BSE_FNO'
    when %i[nse currency]
      'NSE_CURRENCY'
    when %i[bse currency]
      'BSE_CURRENCY'
    when %i[mcx commodity]
      'MCX_COMM'
    else
      raise "Unsupported exchange and segment combination: #{exchange}, #{segment}"
    end
  end

  private

  def resolve_instrument_code
    code = instrument_code.presence || instrument_type.presence
    code ||= InstrumentTypeMapping.underlying_for(self[:instrument_code]).presence if respond_to?(:instrument_code)

    segment_value = respond_to?(:segment) ? segment.to_s.downcase : nil
    code ||= 'EQUITY' if segment_value == 'equity'
    code ||= 'INDEX' if segment_value == 'index'

    raise "Missing instrument code for #{symbol_name || security_id}" if code.blank?

    code.to_s.upcase
  end

  def depth
    response = DhanHQ::Models::MarketFeed.quote(exch_segment_enum)
    response['status'] == 'success' ? response.dig('data', exchange_segment, security_id.to_s) : nil
  rescue StandardError => e
    Rails.logger.error("Failed to fetch Depth for #{self.class.name} #{security_id}: #{e.message}")
    nil
  end

  def exch_segment_enum
    { exchange_segment => [security_id.to_i] }
  end

  def numeric_value?(value)
    value.is_a?(Numeric) || value.to_s.match?(/\A-?\d+(\.\d+)?\z/)
  end
end


# File: app/models/concerns/position_tracker_factory.rb
module PositionTrackerFactory
  extend ActiveSupport::Concern

  class_methods do
    def build_or_average!(instrument:, security_id:, segment:, quantity:, entry_price:, side:, symbol:, order_no:, meta: {})
      sid = security_id.to_s
      seg = segment.to_s

      # 1️⃣ Find active tracker
      active = PositionTracker.active.find_by(segment: seg, security_id: sid)

      if active
        Rails.logger.info("[TrackerFactory] Averaging -> #{seg}:#{sid} #{active.id}")

        old_qty = active.quantity.to_i
        new_qty = old_qty + quantity.to_i

        new_avg = (
          (active.entry_price.to_f * old_qty) +
          (entry_price.to_f * quantity.to_i)
        ) / new_qty

        active.update!(
          quantity: new_qty,
          entry_price: new_avg.round(2),
          avg_price: new_avg.round(2),
          meta: (active.meta || {}).merge(meta)
        )

        return active
      end

      # 2️⃣ No active tracker → create new one
      Rails.logger.info("[TrackerFactory] Creating NEW tracker for #{seg}:#{sid}")

      PositionTracker.create!(
        watchable: instrument.is_a?(Derivative) ? instrument : instrument,
        instrument: instrument.is_a?(Derivative) ? instrument.instrument : instrument,
        order_no: order_no,
        security_id: sid,
        symbol: symbol,
        segment: seg,
        side: side,
        quantity: quantity,
        entry_price: entry_price,
        avg_price: entry_price,
        status: 'active',
        meta: meta
      )
    end
  end
end


# File: app/models/derivative.rb
# == Schema Information
#
# Table name: derivatives
#
#  id                            :integer          not null, primary key
#  instrument_id                 :integer          not null
#  exchange                      :string
#  segment                       :string
#  security_id                   :string
#  isin                          :string
#  instrument_code               :string
#  underlying_security_id        :string
#  underlying_symbol             :string
#  symbol_name                   :string
#  display_name                  :string
#  instrument_type               :string
#  series                        :string
#  lot_size                      :integer
#  expiry_date                   :date
#  strike_price                  :decimal(, )
#  option_type                   :string
#  tick_size                     :decimal(, )
#  expiry_flag                   :string
#  bracket_flag                  :string
#  cover_flag                    :string
#  asm_gsm_flag                  :string
#  asm_gsm_category              :string
#  buy_sell_indicator            :string
#  buy_co_min_margin_per         :decimal(, )
#  sell_co_min_margin_per        :decimal(, )
#  buy_co_sl_range_max_perc      :decimal(, )
#  sell_co_sl_range_max_perc     :decimal(, )
#  buy_co_sl_range_min_perc      :decimal(, )
#  sell_co_sl_range_min_perc     :decimal(, )
#  buy_bo_min_margin_per         :decimal(, )
#  sell_bo_min_margin_per        :decimal(, )
#  buy_bo_sl_range_max_perc      :decimal(, )
#  sell_bo_sl_range_max_perc     :decimal(, )
#  buy_bo_sl_range_min_perc      :decimal(, )
#  sell_bo_sl_min_range          :decimal(, )
#  buy_bo_profit_range_max_perc  :decimal(, )
#  sell_bo_profit_range_max_perc :decimal(, )
#  buy_bo_profit_range_min_perc  :decimal(, )
#  sell_bo_profit_range_min_perc :decimal(, )
#  mtf_leverage                  :decimal(, )
#  created_at                    :datetime         not null
#  updated_at                    :datetime         not null
#
# Indexes
#
#  index_derivatives_on_instrument_code                    (instrument_code)
#  index_derivatives_on_instrument_id                      (instrument_id)
#  index_derivatives_on_symbol_name                        (symbol_name)
#  index_derivatives_on_underlying_symbol_and_expiry_date  (underlying_symbol,expiry_date)
#  index_derivatives_unique                                (security_id,symbol_name,exchange,segment) UNIQUE
#

# frozen_string_literal: true

class Derivative < ApplicationRecord
  include InstrumentHelpers

  belongs_to :instrument
  has_many :watchlist_items, as: :watchable, dependent: :nullify, inverse_of: :watchable
  has_one  :watchlist_item,  -> { where(active: true) }, as: :watchable, class_name: 'WatchlistItem'
  has_many :position_trackers, as: :watchable, dependent: :destroy

  validates :security_id, presence: true, uniqueness: { scope: %i[symbol_name exchange segment] }
  validates :option_type, inclusion: { in: %w[CE PE], allow_blank: true }

  scope :options, -> { where.not(option_type: [nil, '']) }
  scope :futures, -> { where(option_type: [nil, '']) }

  # Places a market BUY order for the derivative (CE/PE) with risk-aware sizing.
  # @param qty [Integer, nil]
  # @param product_type [String]
  # @param index_cfg [Hash, nil]
  # @param meta [Hash]
  # @return [Object, nil]
  def buy_option!(qty: nil, product_type: 'INTRADAY', index_cfg: nil, meta: {})
    segment_code = exchange_segment
    security = security_id.to_s
    raise 'Derivative missing segment/security_id' if segment_code.blank? || security.blank?

    ltp = resolve_ltp(segment: segment_code, security_id: security, meta: meta)
    raise 'LTP unavailable' unless ltp

    quantity = if qty.to_i.positive?
                 qty.to_i
               else
                 config = index_cfg || { key: underlying_symbol, segment: segment_code }
                 Capital::Allocator.qty_for(
                   index_cfg: config,
                   entry_price: ltp.to_f,
                   derivative_lot_size: lot_size.to_i,
                   scale_multiplier: 1
                 )
               end
    return nil if quantity.to_i <= 0

    order = Orders.config.place_market(
      side: 'buy',
      segment: segment_code,
      security_id: security,
      qty: quantity,
      meta: {
        client_order_id: meta[:client_order_id] || default_client_order_id(side: :buy, security_id: security),
        ltp: ltp,
        product_type: product_type
      }
    )
    return nil unless order&.respond_to?(:order_id) && order.order_id.present?

    side_label = option_type.to_s.upcase == 'CE' ? 'long_ce' : 'long_pe'

    after_order_track!(
      instrument: instrument,
      order_no: order.order_id,
      segment: segment_code,
      security_id: security,
      side: side_label,
      qty: quantity,
      entry_price: ltp,
      symbol: symbol_name || display_name,
      index_key: (index_cfg || {})[:key]
    )

    order
  end

  # Places a market SELL order to exit the derivative position.
  # @param qty [Integer, nil]
  # @param meta [Hash]
  # @return [Object, nil]
  def sell_option!(qty: nil, meta: {})
    segment_code = exchange_segment
    security = security_id.to_s
    raise 'Derivative missing segment/security_id' if segment_code.blank? || security.blank?

    quantity = if qty.to_i.positive?
                 qty.to_i
               else
                 PositionTracker.active.where(
                   "(watchable_type = 'Derivative' AND watchable_id = ?) OR instrument_id = ?",
                   id, instrument_id
                 ).where(security_id: security).sum(:quantity).to_i
               end
    return nil if quantity <= 0

    Orders.config.place_market(
      side: 'sell',
      segment: segment_code,
      security_id: security,
      qty: quantity,
      meta: {
        client_order_id: meta[:client_order_id] || default_client_order_id(side: :sell, security_id: security)
      }
    )
  end
end


# File: app/models/instrument.rb
# == Schema Information
#
# Table name: instruments
#
#  id                            :integer          not null, primary key
#  exchange                      :string           not null
#  segment                       :string           not null
#  security_id                   :string           not null
#  isin                          :string
#  instrument_code               :string
#  underlying_security_id        :string
#  underlying_symbol             :string
#  symbol_name                   :string
#  display_name                  :string
#  instrument_type               :string
#  series                        :string
#  lot_size                      :integer
#  expiry_date                   :date
#  strike_price                  :decimal(15, 5)
#  option_type                   :string
#  tick_size                     :decimal(, )
#  expiry_flag                   :string
#  bracket_flag                  :string
#  cover_flag                    :string
#  asm_gsm_flag                  :string
#  asm_gsm_category              :string
#  buy_sell_indicator            :string
#  buy_co_min_margin_per         :decimal(8, 2)
#  sell_co_min_margin_per        :decimal(8, 2)
#  buy_co_sl_range_max_perc      :decimal(8, 2)
#  sell_co_sl_range_max_perc     :decimal(8, 2)
#  buy_co_sl_range_min_perc      :decimal(8, 2)
#  sell_co_sl_range_min_perc     :decimal(8, 2)
#  buy_bo_min_margin_per         :decimal(8, 2)
#  sell_bo_min_margin_per        :decimal(8, 2)
#  buy_bo_sl_range_max_perc      :decimal(8, 2)
#  sell_bo_sl_range_max_perc     :decimal(8, 2)
#  buy_bo_sl_range_min_perc      :decimal(8, 2)
#  sell_bo_sl_min_range          :decimal(8, 2)
#  buy_bo_profit_range_max_perc  :decimal(8, 2)
#  sell_bo_profit_range_max_perc :decimal(8, 2)
#  buy_bo_profit_range_min_perc  :decimal(8, 2)
#  sell_bo_profit_range_min_perc :decimal(8, 2)
#  mtf_leverage                  :decimal(8, 2)
#  created_at                    :datetime         not null
#  updated_at                    :datetime         not null
#
# Indexes
#
#  index_instruments_on_instrument_code                    (instrument_code)
#  index_instruments_on_symbol_name                        (symbol_name)
#  index_instruments_on_underlying_symbol_and_expiry_date  (underlying_symbol,expiry_date)
#  index_instruments_unique                                (security_id,symbol_name,exchange,segment) UNIQUE
#

# frozen_string_literal: true

require 'bigdecimal'

class Instrument < ApplicationRecord
  include InstrumentHelpers

  has_many :derivatives, dependent: :destroy
  has_many :position_trackers, as: :watchable, dependent: :destroy
  accepts_nested_attributes_for :derivatives, allow_destroy: true
  has_many :watchlist_items, as: :watchable, dependent: :nullify, inverse_of: :watchable
  has_one  :watchlist_item,  -> { where(active: true) }, as: :watchable, class_name: 'WatchlistItem'
  has_many :position_trackers, dependent: :restrict_with_error

  scope :enabled, -> { where(enabled: true) }

  validates :security_id, presence: true, uniqueness: true
  validates :symbol_name, presence: true
  validates :exchange_segment, presence: true, unless: -> { exchange.present? && segment.present? }

  SEGMENT_FROM_EXCHANGE = {
    'IDX_I' => 'index',
    'BSE_IDX' => 'index',
    'NSE_IDX' => 'index',
    'I' => 'index',
    'NSE_EQ' => 'equity',
    'BSE_EQ' => 'equity',
    'E' => 'equity',
    'NSE_FNO' => 'derivatives',
    'BSE_FNO' => 'derivatives',
    'D' => 'derivatives',
    'NSE_CURRENCY' => 'currency',
    'BSE_CURRENCY' => 'currency',
    'C' => 'currency',
    'MCX_COMM' => 'commodity',
    'M' => 'commodity'
  }.freeze

  class << self
    def segment_key_for(segment_code)
      return if segment_code.blank?

      code = segment_code.to_s.upcase.strip
      SEGMENT_FROM_EXCHANGE[code] || code.downcase
    end

    def find_by_sid_and_segment(security_id:, segment_code:, symbol_name: nil)
      segment_key = segment_key_for(segment_code)
      return nil unless security_id.present? && segment_key.present?

      sid = security_id.to_s
      instrument = find_by(security_id: sid, segment: segment_key)
      return instrument if instrument.present? || symbol_name.blank?

      find_by(symbol_name: symbol_name.to_s, segment: segment_key)
    end
  end

  def subscribe!
    subscribe
  end

  def unsubscribe!
    unsubscribe
  end

  # Places a market BUY order for the underlying instrument and tracks it.
  # @param qty [Integer, nil]
  # @param product_type [String]
  # @param meta [Hash]
  # @return [Object, nil] Order response from gateway
  def buy_market!(qty: nil, product_type: 'INTRADAY', meta: {})
    segment_code = exchange_segment
    security = security_id.to_s
    raise 'Instrument missing segment/security_id' if segment_code.blank? || security.blank?

    ltp = resolve_ltp(segment: segment_code, security_id: security, meta: meta)
    raise 'LTP unavailable' unless ltp

    quantity = qty.to_i.positive? ? qty.to_i : 1

    order = Orders.config.place_market(
      side: 'buy',
      segment: segment_code,
      security_id: security,
      qty: quantity,
      meta: {
        client_order_id: meta[:client_order_id] || default_client_order_id(side: :buy, security_id: security),
        ltp: ltp,
        product_type: product_type
      }
    )
    return nil unless order&.respond_to?(:order_id) && order.order_id.present?

    after_order_track!(
      instrument: self,
      order_no: order.order_id,
      segment: segment_code,
      security_id: security,
      side: 'LONG',
      qty: quantity,
      entry_price: ltp,
      symbol: symbol_name || display_name
    )

    order
  end

  # Places a market SELL order to exit the underlying position.
  # @param qty [Integer, nil]
  # @param meta [Hash]
  # @return [Object, nil]
  def sell_market!(qty: nil, meta: {})
    segment_code = exchange_segment
    security = security_id.to_s
    raise 'Instrument missing segment/security_id' if segment_code.blank? || security.blank?

    quantity = if qty.to_i.positive?
                 qty.to_i
               else
                 PositionTracker.active.where(
                   "(watchable_type = 'Instrument' AND watchable_id = ?) OR instrument_id = ?",
                   id, id
                 ).where(security_id: security).sum(:quantity).to_i
               end
    return nil if quantity <= 0

    Orders.config.place_market(
      side: 'sell',
      segment: segment_code,
      security_id: security,
      qty: quantity,
      meta: {
        client_order_id: meta[:client_order_id] || default_client_order_id(side: :sell, security_id: security)
      }
    )
  end

  # API Methods
  def fetch_option_chain(expiry = nil)
    expiry ||= expiry_list.first

    # Check if caching is disabled for fresh data
    freshness_config = AlgoConfig.fetch[:data_freshness] || {}
    disable_caching = freshness_config[:disable_option_chain_caching] || false

    if disable_caching
      # Rails.logger.debug { "[Instrument] Fresh data mode - bypassing option chain cache for #{symbol_name}" }
      return fetch_fresh_option_chain(expiry)
    end

    # Use cached data if available and not stale
    cache_key = "option_chain:#{security_id}:#{expiry}"
    cached_data = Rails.cache.read(cache_key)

    if cached_data && !option_chain_stale?(expiry)
      # Rails.logger.debug { "[Instrument] Using cached option chain for #{symbol_name} #{expiry}" }
      return cached_data
    end

    # Fetch fresh data and cache it
    fresh_data = fetch_fresh_option_chain(expiry)
    if fresh_data
      cache_duration_minutes = freshness_config[:option_chain_cache_duration_minutes] || 2
      Rails.cache.write(cache_key, fresh_data, expires_in: cache_duration_minutes.minutes)
      Rails.cache.write("#{cache_key}:timestamp", Time.current, expires_in: cache_duration_minutes.minutes)
      # Rails.logger.debug { "[Instrument] Cached fresh option chain for #{symbol_name} #{expiry}" }
    end

    fresh_data
  end

  def fetch_fresh_option_chain(expiry)
    data = DhanHQ::Models::OptionChain.fetch(
      underlying_scrip: security_id.to_i,
      underlying_seg: exchange_segment,
      expiry: expiry
    )
    return nil unless data

    filtered_data = filter_option_chain_data(data)

    { last_price: data['last_price'], oc: filtered_data }
  rescue StandardError => e
    Rails.logger.error("Failed to fetch Option Chain for Instrument #{security_id}: #{e.message}")
    nil
  end

  def option_chain_stale?(expiry)
    freshness_config = AlgoConfig.fetch[:data_freshness] || {}
    cache_duration_minutes = freshness_config[:option_chain_cache_duration_minutes] || 2

    cache_key = "option_chain:#{security_id}:#{expiry}"
    cached_at = Rails.cache.read("#{cache_key}:timestamp")

    return true unless cached_at

    Time.current - cached_at > cache_duration_minutes.minutes
  end

  def filter_option_chain_data(data)
    data['oc'].select do |_strike, option_data|
      call_data = option_data['ce']
      put_data = option_data['pe']

      has_call_values = call_data && call_data.except('implied_volatility').values.any? do |v|
        numeric_value?(v) && v.to_f.positive?
      end
      has_put_values = put_data && put_data.except('implied_volatility').values.any? do |v|
        numeric_value?(v) && v.to_f.positive?
      end

      has_call_values || has_put_values
    end
  end

  def expiry_list
    DhanHQ::Models::OptionChain.fetch_expiry_list(
      underlying_scrip: security_id.to_i,
      underlying_seg: exchange_segment
    )
  end

  def option_chain(expiry: nil)
    fetch_option_chain(expiry)
  end
end


# File: app/models/instrument_type_mapping.rb
# frozen_string_literal: true

module InstrumentTypeMapping
  PARENT_TO_CHILDREN = {
    'INDEX' => %w[FUTIDX OPTIDX],
    'EQUITY' => %w[FUTSTK OPTSTK],
    'FUTCOM' => %w[OPTFUT],
    'FUTCUR' => %w[OPTCUR]
  }.freeze

  CHILD_TO_PARENT =
    PARENT_TO_CHILDREN.flat_map { |parent, kids| kids.map { |kid| [kid, parent] } }
                      .to_h
                      .freeze

  module_function

  def underlying_for(code)
    return nil if code.blank?

    CHILD_TO_PARENT[code] || code
  end

  def derivative_codes_for(parent_code)
    PARENT_TO_CHILDREN[parent_code] || []
  end

  def all_parents
    PARENT_TO_CHILDREN.keys
  end

  def all_children
    CHILD_TO_PARENT.keys
  end
end


# File: app/models/orders/config.rb
# frozen_string_literal: true

module Orders
  class Config
    attr_accessor :gateway

    def initialize(gateway:)
      @gateway = gateway
    end
  end
end


# File: app/models/position_tracker.rb
# == Schema Information
#
# Table name: position_trackers
#
#  id                        :integer         not null, primary key
#  instrument_id             :integer         not null
#  order_no                  :string          not null
#  security_id               :string          not null
#  symbol                    :string
#  segment                   :string
#  side                      :string
#  status                    :string          not null
#  quantity                  :integer
#  avg_price                 :decimal
#  entry_price               :decimal
#  last_pnl_rupees           :decimal
#  last_pnl_pct              :decimal
#  high_water_mark_pnl       :decimal
#  meta                      :jsonb
#  created_at                :datetime        not null
#  updated_at                :datetime        not null
#
# Indexes
#
#  index_position_trackers_on_instrument_id  (instrument_id)
#  index_position_trackers_on_order_no       (order_no) UNIQUE
#
# Foreign Keys
#
#  fk_rails_...  (instrument_id => instruments.id)
#

# frozen_string_literal: true

require 'bigdecimal'

class PositionTracker < ApplicationRecord
  include PositionTrackerFactory

  # Attribute accessors
  store_accessor :meta, :breakeven_locked, :trailing_stop_price, :index_key, :direction

  # Enums
  enum :status, {
    pending: 'pending',
    active: 'active',
    exited: 'exited',
    cancelled: 'cancelled'
  }

  # Validations
  validates :order_no, presence: true, uniqueness: true
  validates :security_id, presence: true

  # Callbacks
  after_commit :register_in_index, on: %i[create update]
  after_commit :unregister_from_index, on: :destroy
  after_update_commit :refresh_index_if_relevant
  after_update_commit :cleanup_if_exited
  after_create_commit :subscribe_to_feed
  after_destroy_commit :clear_redis_pnl_cache
  after_update_commit :clear_redis_cache_if_exited

  # Associations
  belongs_to :instrument # Kept for backward compatibility during transition
  belongs_to :watchable, polymorphic: true

  # Scopes
  # Note: enum automatically creates scopes for :pending, :active, :exited, :cancelled
  scope :paper, -> { where(paper: true) }
  scope :live, -> { where(paper: false) }
  scope :exited_paper, -> { where(paper: true, status: :exited) }

  # Class Methods
  class << self
    def active_for(seg, sid)
      where(segment: seg, security_id: sid, status: :active).first
    end

    def exited_for(seg, sid)
      where(segment: seg, security_id: sid, status: :exited).order(id: :desc).first
    end

    def paper_trading_stats_with_pct
      exited = exited_paper
      active = paper.active

      active_count = active.count
      realized_pnl_rupees = exited.sum { |t| t.last_pnl_rupees.to_f }
      realized_pnl_pct = exited.map { |t| t.last_pnl_pct.to_f }.compact.sum

      unrealized_pnl_rupees = active.sum { |t| t.last_pnl_rupees.to_f }
      unrealized_pnl_pct = active.map { |t| t.last_pnl_pct.to_f }.compact.sum

      total_pnl_rupees = realized_pnl_rupees + unrealized_pnl_rupees
      total_pnl_pct = realized_pnl_pct + unrealized_pnl_pct

      {
        total_trades: exited.count,
        active_positions: active_count,
        total_pnl_rupees: total_pnl_rupees.round(2),
        total_pnl_pct: total_pnl_pct.round(2),
        realized_pnl_rupees: realized_pnl_rupees.round(2),
        realized_pnl_pct: realized_pnl_pct.round(2),
        unrealized_pnl_rupees: unrealized_pnl_rupees.round(2),
        unrealized_pnl_pct: unrealized_pnl_pct.round(2),
        win_rate: paper_win_rate,
        avg_realized_pnl_pct: exited.any? ? (realized_pnl_pct / exited.count.to_f).round(2) : 0.0,
        avg_unrealized_pnl_pct: active.any? ? (unrealized_pnl_pct / active.count.to_f).round(2) : 0.0,
        winners: exited.count { |t| (t.last_pnl_rupees || 0).positive? },
        losers: exited.count { |t| (t.last_pnl_rupees || 0).negative? }
      }
    end

    def paper_positions_details
      paper.includes(:instrument).map do |t|
        entry_price = t.entry_price.to_f
        exit_price = t.last_pnl_rupees.present? && t.status == 'exited' ? t.exit_price.to_f : nil
        current_price = exit_price || t.avg_price.to_f
        side = t.side
        qty = t.quantity.to_i
        pnl_abs = t.last_pnl_rupees.to_f
        pnl_pct = if t.last_pnl_pct.present?
                    t.last_pnl_pct.to_f
                  elsif entry_price.positive? && current_price.positive?
                    if side == 'BUY'
                      ((current_price - entry_price) / entry_price * 100.0)
                    else
                      ((entry_price - current_price) / entry_price * 100.0)
                    end
                  else
                    0.0
                  end

        {
          id: t.id,
          order_no: t.order_no,
          symbol: t.symbol,
          side: side,
          status: t.status,
          quantity: qty,
          entry_price: entry_price,
          exit_price: exit_price,
          avg_price: t.avg_price.to_f,
          last_pnl_rupees: pnl_abs.round(2),
          last_pnl_pct: pnl_pct.round(2),
          high_water_mark_pnl: t.high_water_mark_pnl.to_f,
          created_at: t.created_at&.strftime('%Y-%m-%d %H:%M'),
          updated_at: t.updated_at&.strftime('%Y-%m-%d %H:%M'),
          watchable_type: t.watchable_type,
          segment: t.segment,
          security_id: t.security_id,
          paper: t.paper?,
          unrealized?: t.status != 'exited'
        }
      end
    end

    def total_paper_pnl
      exited_paper.sum do |tracker|
        tracker.last_pnl_rupees || BigDecimal(0)
      end
    end

    def active_paper_positions_count
      paper.active.count
    end

    def paper_win_rate
      exited = exited_paper
      return 0.0 if exited.empty?

      winners = exited.count { |t| (t.last_pnl_rupees || 0).positive? }
      (winners.to_f / exited.count * 100).round(2)
    end

    def paper_trading_stats
      exited = exited_paper
      active = paper.active
      active_count = active.count

      # Calculate realized PnL from exited positions
      realized_pnl = total_paper_pnl.to_f

      # Calculate unrealized PnL from active positions
      unrealized_pnl = active.sum do |tracker|
        tracker.last_pnl_rupees || BigDecimal(0)
      end.to_f

      # Total PnL = realized (exited) + unrealized (active)
      total_pnl = realized_pnl + unrealized_pnl

      {
        total_trades: exited.count,
        active_positions: active_count,
        total_pnl: total_pnl,
        realized_pnl: realized_pnl,
        unrealized_pnl: unrealized_pnl,
        win_rate: paper_win_rate,
        average_pnl: exited.empty? ? 0.0 : (realized_pnl / exited.count).to_f,
        winners: exited.count { |t| (t.last_pnl_rupees || 0).positive? },
        losers: exited.count { |t| (t.last_pnl_rupees || 0).negative? }
      }
    end

    def clear_orphaned_redis_pnl!
      return unless should_clear_orphaned?

      cache = Live::RedisPnlCache.instance
      # Only check active positions (most common case) - faster query
      existing_ids = PositionTracker.active.pluck(:id).to_set(&:to_s)

      cache.each_tracker_key do |_key, tracker_id|
        next if existing_ids.include?(tracker_id)

        Rails.logger.warn("[PositionTracker] Clearing orphaned Redis PnL cache for tracker #{tracker_id}")
        cache.clear_tracker(tracker_id)
      end

      @last_clear = Time.current
    end

    def should_clear_orphaned?
      @last_clear ||= 5.minutes.ago
      return true if Time.current - @last_clear >= 5.minutes

      false
    end
  end

  # Instance Methods
  def metadata_for_index
    {
      id: id,
      security_id: security_id.to_s,
      entry_price: entry_price.present? ? entry_price.to_s : nil,
      quantity: quantity.to_i,
      segment: segment
    }
  end

  def mark_active!(avg_price:, quantity:)
    price = avg_price.present? ? BigDecimal(avg_price.to_s) : nil
    attrs = {
      status: :active,
      avg_price: price,
      entry_price: entry_price.presence || price,
      quantity: quantity
    }

    update!(attrs.compact)
    subscribe

    # Initialize PnL in Redis (will be 0 initially since entry_price = avg_price)
    # This ensures the position is tracked in Redis from the start
    return if price.blank?

    initial_pnl = BigDecimal(0)
    Live::RedisPnlCache.instance.store_pnl(
      tracker_id: id,
      pnl: initial_pnl,
      pnl_pct: 0.0,
      ltp: price,
      hwm: initial_pnl,
      timestamp: Time.current
    )
  end

  def mark_cancelled!
    update!(status: :cancelled)
  end

  def paper?
    paper == true
  end

  def live?
    !paper?
  end

  def mark_exited!(exit_price: nil, exited_at: nil, exit_reason: nil)
    persist_final_pnl_from_cache

    exit_price = resolve_exit_price(exit_price)
    metadata = prepare_exit_metadata(exit_reason)

    update_exit_attributes(exit_price, exited_at, metadata)
    cleanup_exit_caches
    unsubscribe
    register_cooldown!

    self
  end

  def hydrate_pnl_from_cache!
    cache = Live::RedisPnlCache.instance.fetch_pnl(id)
    return unless cache

    cache_live_pnl(cache[:pnl], pnl_pct: cache[:pnl_pct]) if cache[:pnl]

    self.high_water_mark_pnl = BigDecimal(cache[:hwm_pnl].to_s) if cache[:hwm_pnl]
  rescue StandardError
    nil
  end

  def update_pnl!(pnl, pnl_pct: nil)
    pnl_value = BigDecimal(pnl.to_s)
    current_hwm = high_water_mark_pnl ? BigDecimal(high_water_mark_pnl.to_s) : BigDecimal(0)
    hwm = [current_hwm, pnl_value].max
    attrs = { last_pnl_rupees: pnl_value, high_water_mark_pnl: hwm }
    attrs[:last_pnl_pct] = BigDecimal(pnl_pct.to_s) if pnl_pct
    update!(attrs)
  end

  def trailing_stop_triggered?(pnl, drop_pct)
    return false if high_water_mark_pnl.blank? || BigDecimal(high_water_mark_pnl.to_s).zero?

    pnl_value = BigDecimal(pnl.to_s)
    hwm_value = BigDecimal(high_water_mark_pnl.to_s)
    threshold = hwm_value * (1 - drop_pct)
    pnl_value <= threshold
  end

  def ready_to_trail?(pnl, min_profit)
    BigDecimal(pnl.to_s) >= min_profit
  end

  def min_profit_lock(trail_step_pct)
    return BigDecimal(0) if trail_step_pct.to_f <= 0
    return BigDecimal(0) if entry_price.blank? || quantity.to_i <= 0

    BigDecimal(entry_price.to_s) * quantity.to_i * BigDecimal(trail_step_pct.to_s)
  end

  def breakeven_locked?
    ActiveModel::Type::Boolean.new.cast(meta_hash.fetch('breakeven_locked', false))
  end

  def lock_breakeven!
    update!(meta: meta_hash.merge('breakeven_locked' => true))
  end

  def unsubscribe
    return unless Live::MarketFeedHub.instance.running?

    segment_key = segment.presence || watchable&.exchange_segment || instrument&.exchange_segment
    return unless segment_key && security_id

    # Never unsubscribe from IDX_I (index feeds) - they're needed for signal generation
    # and may be used by multiple positions
    if segment_key == 'IDX_I'
      Rails.logger.debug { "[PositionTracker] Skipping unsubscribe for IDX_I:#{security_id} (index feed must stay subscribed)" }
      return
    end

    # Rails.logger.debug { "[PositionTracker] Unsubscribing from market feed: #{segment_key}:#{security_id}" }
    Live::MarketFeedHub.instance.unsubscribe(segment: segment_key, security_id: security_id)

    # Never unsubscribe from underlying instruments (especially IDX_I)
    # They are needed for signal generation and may be used by other positions
    # The underlying index feeds should remain subscribed at all times
  end

  def subscribe
    segment_key = segment.presence || watchable&.exchange_segment || instrument&.exchange_segment
    return unless segment_key && security_id

    hub = Live::MarketFeedHub.instance
    # Ensure hub is running (will start if not running)
    hub.start! unless hub.running?

    hub.subscribe(segment: segment_key, security_id: security_id)
  rescue StandardError => e
    Rails.logger.error("[PositionTracker] Failed to subscribe #{order_no}: #{e.message}")
    nil
  end

  def tradable
    watchable
  end

  def underlying_instrument
    if watchable.is_a?(Derivative)
      watchable.instrument
    elsif watchable.is_a?(Instrument)
      watchable
    else
      instrument
    end
  end

  def cache_live_pnl(pnl, pnl_pct: nil)
    pnl_value = BigDecimal(pnl.to_s)
    self.last_pnl_rupees = pnl_value

    self.last_pnl_pct = pnl_pct.nil? ? nil : BigDecimal(pnl_pct.to_s)

    current_hwm = high_water_mark_pnl.present? ? BigDecimal(high_water_mark_pnl.to_s) : BigDecimal(0)
    self.high_water_mark_pnl = [current_hwm, pnl_value].max
  end

  private

  def register_in_index
    return unless active? && entry_price.present? && quantity.to_i.positive?

    Live::PositionIndex.instance.add(metadata_for_index)
  rescue StandardError => e
    Rails.logger.warn("[PositionTracker] register_in_index failed for #{id}: #{e.message}")
  end

  def subscribe_to_feed
    # Use same segment resolution logic as subscribe method
    segment_key = segment.presence || watchable&.exchange_segment || instrument&.exchange_segment
    return unless segment_key && security_id

    hub = Live::MarketFeedHub.instance
    hub.start! unless hub.running?
    hub.subscribe(segment: segment_key, security_id: security_id)

    Live::PositionIndex.instance.add(id: id, security_id: security_id, segment: segment_key, entry_price: entry_price,
                                     quantity: quantity)
  end

  def unregister_from_index
    # Remove from in-memory index
    Live::PositionIndex.instance.remove(id, security_id)

    # Remove Redis tick cache
    Live::RedisTickCache.instance.clear_tick(segment, security_id)

    # Remove in-memory TickCache
    Live::TickCache.delete(segment, security_id)

    # Unsubscribe websocket feed
    unsubscribe
  rescue StandardError => e
    Rails.logger.warn("[PositionTracker] unregister_from_index failed for #{id}: #{e.message}")
  end

  def cleanup_if_exited
    return unless saved_change_to_status? && exited?

    unregister_from_index
    clear_redis_pnl_cache
  end

  def refresh_index_if_relevant
    # If status, security_id, entry_price or quantity changed, update index
    unless saved_change_to_status? || saved_change_to_security_id? || saved_change_to_entry_price? || saved_change_to_quantity?
      return
    end

    unregister_from_index
    register_in_index
  end

  def resolve_exit_price(exit_price)
    exit_price ||= fetch_ltp_from_cache
    exit_price = BigDecimal(exit_price.to_s) if exit_price.present?
    exit_price
  end

  def fetch_ltp_from_cache
    seg = segment.presence || watchable&.exchange_segment || instrument&.exchange_segment
    Live::TickCache.ltp(seg, security_id)
  end

  def prepare_exit_metadata(exit_reason)
    exit_reason ||= meta.is_a?(Hash) ? meta['exit_reason'] : nil
    metadata = meta.is_a?(Hash) ? meta.dup : {}
    metadata['exit_reason'] = exit_reason if exit_reason.present?
    metadata['exit_triggered_at'] ||= Time.current
    metadata
  end

  def update_exit_attributes(exit_price, exited_at, metadata)
    attrs = {
      status: :exited,
      exit_price: exit_price,
      exited_at: exited_at || Time.current,
      last_pnl_rupees: last_pnl_rupees,
      last_pnl_pct: last_pnl_pct,
      high_water_mark_pnl: high_water_mark_pnl,
      meta: metadata
    }.compact

    update!(attrs)
  end

  def cleanup_exit_caches
    Live::PositionIndex.instance.remove(id, security_id)
    Live::RedisPnlCache.instance.clear_tracker(id)
    Live::RedisTickCache.instance.clear_tick(segment, security_id)
    Live::TickCache.delete(segment, security_id)
  end

  def register_cooldown!
    return if symbol.blank?

    Rails.cache.write("reentry:#{symbol}", Time.current, expires_in: 8.hours)
  end

  def clear_redis_cache_if_exited
    return unless saved_change_to_status? && exited?

    clear_redis_pnl_cache
  end

  def clear_redis_pnl_cache
    Live::RedisPnlCache.instance.clear_tracker(id)
  end

  def persist_final_pnl_from_cache
    cache = Live::RedisPnlCache.instance.fetch_pnl(id)
    return unless cache

    if cache[:pnl]
      pnl_value = BigDecimal(cache[:pnl].to_s)
      self.last_pnl_rupees = pnl_value

      current_hwm = high_water_mark_pnl.present? ? BigDecimal(high_water_mark_pnl.to_s) : BigDecimal(0)
      self.high_water_mark_pnl = [current_hwm, pnl_value].max
    end

    self.last_pnl_pct = cache[:pnl_pct] ? BigDecimal(cache[:pnl_pct].to_s) : nil
  end

  def meta_hash
    value = self[:meta]
    value.is_a?(Hash) ? value : {}
  end

  def calculate_paper_pnl(exit_price = nil)
    return BigDecimal(0) unless paper? && entry_price.present? && quantity.present?

    exit = exit_price || last_pnl_rupees
    return BigDecimal(0) unless exit

    entry = BigDecimal(entry_price.to_s)
    exit_value = BigDecimal(exit.to_s)
    qty = quantity.to_i

    # For long positions: PnL = (exit - entry) * quantity
    pnl = (exit_value - entry) * qty
    BigDecimal(pnl.to_s)
  end
end


# File: app/models/setting.rb
# == Schema Information
#
# Table name: settings
#
#  id         :integer          not null, primary key
#  key        :string           not null
#  value      :text
#  created_at :datetime         not null
#  updated_at :datetime         not null
#
# Indexes
#
#  index_settings_on_key  (key) UNIQUE
#

# frozen_string_literal: true

class Setting < ApplicationRecord
  validates :key, presence: true, uniqueness: true

  # Cached read
  def self.fetch(key, default = nil, ttl: 30)
    Rails.cache.fetch("setting:#{key}", expires_in: ttl.seconds) do
      find_by(key:)&.value || default
    end
  end

  # Write + cache bust
  def self.put(key, value)
    rec = find_or_initialize_by(key:)
    rec.value = value.to_s
    rec.save!
    Rails.cache.delete("setting:#{key}")
    value
  end

  # Typed helpers (quality of life)
  def self.fetch_i(key, default = 0) = fetch(key, default).to_i
  def self.fetch_f(key, default = 0.0) = fetch(key, default).to_f

  def self.fetch_bool(key, default = false) # rubocop:disable Style/OptionalBooleanParameter,Naming/PredicateMethod
    raw = fetch(key, default)
    return !!raw if [true, false].include?(raw)

    %w[1 true yes on].include?(raw.to_s.strip.downcase)
  end
end


# File: app/models/trading_signal.rb
# == Schema Information
#
# Table name: trading_signals
#
#  id                        :integer         not null, primary key
#  index_key                 :string          not null
#  direction                 :string          not null
#  confidence_score          :decimal
#  timeframe                 :string          not null
#  supertrend_value          :decimal
#  adx_value                 :decimal
#  signal_timestamp          :datetime        not null
#  candle_timestamp          :datetime        not null
#  metadata                  :jsonb
#  created_at                :datetime        not null
#  updated_at                :datetime        not null
#

# frozen_string_literal: true

class TradingSignal < ApplicationRecord
  DIRECTIONS = {
    bullish: 'bullish',
    bearish: 'bearish',
    avoid: 'avoid'
  }.freeze

  validates :index_key, presence: true
  validates :direction, inclusion: { in: DIRECTIONS.values }
  validates :timeframe, presence: true
  validates :signal_timestamp, presence: true
  validates :candle_timestamp, presence: true
  validates :confidence_score, numericality: { in: 0.0..1.0 }, allow_nil: true

  scope :for_index, ->(index_key) { where(index_key: index_key) }
  scope :for_direction, ->(direction) { where(direction: direction) }
  scope :recent, ->(hours = 24) { where(signal_timestamp: hours.hours.ago..Time.current) }
  scope :high_confidence, ->(threshold = 0.7) { where(confidence_score: threshold..) }

  def self.create_from_analysis(index_key:, direction:, timeframe:, supertrend_value:, adx_value:, candle_timestamp:,
                                confidence_score: nil, metadata: {})
    create!(
      index_key: index_key,
      direction: direction,
      timeframe: timeframe,
      supertrend_value: supertrend_value,
      adx_value: adx_value,
      candle_timestamp: candle_timestamp,
      signal_timestamp: Time.current,
      confidence_score: confidence_score,
      metadata: metadata
    )
  rescue ActiveRecord::RecordInvalid => e
    # Rails.logger.error("Failed to persist trading signal: #{e.record.errors.full_messages.to_sentence}")
    nil
  end

  def confidence_level
    return 'unknown' unless confidence_score

    case confidence_score
    when 0.8..1.0 then 'very_high'
    when 0.6..0.8 then 'high'
    when 0.4..0.6 then 'medium'
    when 0.2..0.4 then 'low'
    else 'very_low'
    end
  end

  def bullish?
    direction == DIRECTIONS[:bullish]
  end

  def bearish?
    direction == DIRECTIONS[:bearish]
  end

  def calculate_accuracy
    return 0.0 if metadata.blank?

    execution_price = metadata['execution_price']
    exit_price = metadata['exit_price']
    final_status = metadata['final_status']

    return 0.0 unless execution_price && exit_price && final_status

    # Calculate accuracy based on final status and price movement
    case final_status
    when 'profitable'
      # Positive accuracy for profitable trades
      ((exit_price.to_f - execution_price.to_f) / execution_price.to_f) * 100
    when 'loss'
      # Negative accuracy for losing trades
      ((exit_price.to_f - execution_price.to_f) / execution_price.to_f) * 100
    else
      0.0
    end
  end

  def avoid?
    direction == DIRECTIONS[:avoid]
  end
end


# File: app/models/watchlist_item.rb
# == Schema Information
#
# Table name: watchlist_items
#
#  id                        :integer         not null, primary key
#  segment                   :string          not null
#  security_id               :string          not null
#  kind                      :integer
#  label                     :string
#  active                    :boolean         not null
#  watchable_type            :string
#  watchable_id              :integer
#  created_at                :datetime        not null
#  updated_at                :datetime        not null
#
# Indexes
#
#  index_watchlist_items_on_segment_and_security_id  (segment,security_id) UNIQUE
#  index_watchlist_items_on_watchable               (watchable_type,watchable_id)
#
# Foreign Keys
#
#  fk_rails_...  (watchable_id => watchable_type)
#

# frozen_string_literal: true

class WatchlistItem < ApplicationRecord
  belongs_to :watchable, polymorphic: true, optional: true
  # belongs_to :instrument, polymorphic: true, optional: true
  # belongs_to :derivative, polymorphic: true, optional: true

  validates :segment, presence: true, inclusion: { in: DhanHQ::Constants::EXCHANGE_SEGMENTS }
  validates :security_id, presence: true
  validates :security_id, uniqueness: { scope: :segment }

  # Avoid enum name 'index' to prevent ambiguous method names
  enum :kind, {
    index_value: 0,
    equity: 1,
    derivative: 2,
    currency: 3,
    commodity: 4
  }

  validate :kind_must_be_valid

  scope :active, -> { where(active: true) }
  scope :by_segment, ->(seg) { where(segment: seg) }
  scope :for, ->(seg, sid) { where(segment: seg, security_id: sid) }

  # Alias: segment stores exchange_segment values (IDX_I, NSE_FNO, etc.)
  def exchange_segment
    segment
  end

  def exchange_segment=(value)
    self.segment = value
  end

  # Convenience accessors for the polymorphic association
  def instrument
    watchable if watchable_type == 'Instrument'
  end

  def derivative
    watchable if watchable_type == 'Derivative'
  end

  def kind=(value)
    @invalid_kind_value = nil
    super
  rescue ArgumentError
    @invalid_kind_value = value
    super(nil)
  end

  private

  def kind_must_be_valid
    return unless defined?(@invalid_kind_value) && @invalid_kind_value

    errors.add(:kind, 'is not included in the list')
  end
end


# File: app/services/application_service.rb
# frozen_string_literal: true

class ApplicationService
  def self.call(*, **, &)
    new(*, **).call(&)
  end
end


# File: app/services/backtest_service.rb
# app/services/backtest_service.rb
# frozen_string_literal: true

class BacktestService
  attr_reader :instrument, :interval, :days_back, :strategy_class, :results

  def initialize(symbol:, interval: '5', days_back: 90, strategy: SimpleMomentumStrategy)
    @interval = interval
    @days_back = days_back
    @strategy_class = strategy
    @results = []

    ActiveSupport::Notifications.instrument('backtest.instrument_lookup', symbol: symbol) do
      @instrument = Instrument.segment_index.find_by(symbol_name: symbol)
    end

    unless @instrument
      ActiveSupport::Notifications.instrument('backtest.instrument_missing', symbol: symbol)
      raise "Instrument #{symbol} not found"
    end

    instrument_event('instrument_ready', instrument_code: @instrument.instrument_code, segment: @instrument.segment)
    instrument_event('initialized', strategy: strategy_name)
  end

  def self.run(symbol:, interval: '5', days_back: 90, strategy: SimpleMomentumStrategy)
    service = new(symbol: symbol, interval: interval, days_back: days_back, strategy: strategy)
    service.execute
    service
  end

  def execute
    instrument_event('execute.start')
    Rails.logger.info("[Backtest] Starting backtest for #{instrument.symbol_name}")

    # Fetch historical OHLC data
    ohlc_data = instrument_event('ohlc.fetch') { fetch_ohlc_data }
    return { error: 'No OHLC data available' } if ohlc_data.blank?

    instrument_event('ohlc.received', candles: ohlc_data.size)

    # Create CandleSeries
    series = instrument_event('series.build', raw_candles: ohlc_data.size) { build_candle_series(ohlc_data) }
    @series = series
    return { error: 'Failed to build candle series' } if series.candles.empty?

    instrument_event('series.ready', candles: series.candles.size)

    # Initialize strategy
    strategy = instrument_event('strategy.initialize') { instantiate_strategy(series) }
    instrument_event('strategy.ready', strategy_class: strategy.class.name)

    # Simulate bar-by-bar
    instrument_event('simulation.run', candles: series.candles.size) { simulate_trading(series, strategy) }

    Rails.logger.info("[Backtest] Completed: #{@results.size} trades")
    instrument_event('execute.complete', trades: @results.size)
    instrument_event('execute.no_trades') if @results.empty?
    self
  end

  def summary
    return {} if @results.empty?

    wins = @results.select { |r| r[:pnl_percent] > 0 }
    losses = @results.select { |r| r[:pnl_percent] <= 0 }
    trade_count = @results.size
    win_total_percent = wins.sum { |w| w[:pnl_percent] }
    loss_total_percent = losses.sum { |l| l[:pnl_percent] }
    total_pnl_percent = @results.sum { |r| r[:pnl_percent] }

    {
      total_trades: trade_count,
      winning_trades: wins.size,
      losing_trades: losses.size,
      win_rate: (wins.size.to_f / trade_count * 100).round(2),
      avg_win_percent: wins.any? ? (win_total_percent / wins.size.to_f).round(2) : 0,
      avg_loss_percent: losses.any? ? (loss_total_percent / losses.size.to_f).round(2) : 0,
      total_pnl_percent: total_pnl_percent.round(2),
      expectancy: (total_pnl_percent / trade_count.to_f).round(2),
      max_win: wins.any? ? wins.max_by { |w| w[:pnl_percent] }[:pnl_percent].round(2) : 0,
      max_loss: losses.any? ? losses.min_by { |l| l[:pnl_percent] }[:pnl_percent].round(2) : 0,
      trades: @results
    }
  end

  def print_summary
    s = summary
    return puts 'No trades executed' if s.empty?

    separator = '=' * 60
    divider = '-' * 60

    puts "\n#{separator}"
    puts "BACKTEST RESULTS: #{instrument.symbol_name}"
    puts separator
    puts "Period: Last #{days_back} days | Interval: #{interval} min"
    puts divider
    puts "Total Trades:      #{s[:total_trades]}"
    puts "Winning Trades:    #{s[:winning_trades]} (#{s[:win_rate]}%)"
    puts "Losing Trades:     #{s[:losing_trades]}"
    puts divider
    puts "Avg Win:           +#{s[:avg_win_percent]}%"
    puts "Avg Loss:          #{s[:avg_loss_percent]}%"
    puts "Max Win:           +#{s[:max_win]}%"
    puts "Max Loss:          #{s[:max_loss]}%"
    puts divider
    puts "Total P&L:         #{'+' if s[:total_pnl_percent] > 0}#{s[:total_pnl_percent]}%"
    puts "Expectancy:        #{'+' if s[:expectancy] > 0}#{s[:expectancy]}% per trade"
    puts "#{separator}\n"
  end

  private

  def fetch_ohlc_data
    to_date = Date.today - 1.day
    from_date = to_date - @days_back.days

    @instrument.intraday_ohlc(
      interval: @interval,
      from_date: from_date.to_s,
      to_date: to_date.to_s,
      days: @days_back
    )
  rescue StandardError => e
    Rails.logger.error("[Backtest] Failed to fetch OHLC: #{e.message}")
    nil
  end

  def build_candle_series(ohlc_data)
    series = CandleSeries.new(symbol: @instrument.symbol_name, interval: @interval)
    series.load_from_raw(ohlc_data)
    series
  end

    # ----------------------------- UPDATED SECTION -----------------------------
    def simulate_trading(series, strategy)
      open_position = nil
      i = 0

      while i < series.candles.size
        candle = series.candles[i]

        if open_position
          exit_result = check_exit(open_position, candle, i, series)
          if exit_result
            @results << exit_result
            open_position = nil
            instrument_event('trade.exited', exit_result)
          end
        end

        if open_position.nil?
          signal = strategy.generate_signal(i)
          open_position = enter_position(signal, candle, i) if signal
        end

        i += 1
      end

      if open_position
        last_candle = series.candles.last
        exit_result = force_exit(open_position, last_candle, series.candles.size - 1, 'end_of_data')
        @results << exit_result
      end
    end

    def enter_position(signal, candle, index)
      option_data = fetch_option_series(signal[:type], candle.timestamp)
      return unless option_data.present?
      entry_premium = fetch_premium_price(option_data, candle.timestamp)

      position = {
        signal_type: signal[:type],
        entry_index: index,
        entry_time: candle.timestamp,
        entry_price: entry_premium,
        option_data: option_data,
        stop_loss: calculate_stop_loss(entry_premium, signal[:type]),
        target: calculate_target(entry_premium, signal[:type])
      }

      instrument_event('trade.entered', position)
      position
    end

    # removed duplicate check_exit (option-premium based) to avoid method redefinition

    # ------------------------- NEW METHODS --------------------------

    def fetch_option_series(type, date)
      fetcher = Options::ExpiredFetcher.call(symbol: @instrument.symbol_name, expiry_flag: 'WEEK', date: date)
      fetcher[type]
    rescue StandardError => e
      Rails.logger.error("[Backtest] fetch_option_series failed: #{e.message}")
      []
    end

    def fetch_premium_price(option_data, ts)
      # get closest timestamp bar
      return 0.0 if option_data.blank?
      bar = option_data.min_by { |b| (b[:timestamp] - ts).abs }
      bar[:close].to_f
    end


  def calculate_stop_loss(entry_price, signal_type)
    if signal_type == :ce
      entry_price * 0.70 # -30%
    else
      entry_price * 1.30 # +30% (for PE, price going up is a loss)
    end
  end

  def calculate_target(entry_price, signal_type)
    if signal_type == :ce
      entry_price * 1.50 # +50%
    else
      entry_price * 0.50 # -50% (for PE, price going down is profit)
    end
  end

  def check_exit(position, candle, index, _series)
    current_price = fetch_premium_price(position[:option_data], candle.timestamp)
    entry_price = position[:entry_price]
    signal_type = position[:signal_type]

    # Calculate P&L %
    pnl_percent = if signal_type == :ce
                    ((current_price - entry_price) / entry_price * 100)
                  else # :pe
                    ((entry_price - current_price) / entry_price * 100)
                  end

    # Check target hit
    target_hit =
      (signal_type == :ce && current_price >= position[:target]) ||
      (signal_type == :pe && current_price <= position[:target])
    return build_exit_result(position, candle, index, pnl_percent, 'target') if target_hit

    # Check stop loss
    stop_loss_hit =
      (signal_type == :ce && current_price <= position[:stop_loss]) ||
      (signal_type == :pe && current_price >= position[:stop_loss])
    return build_exit_result(position, candle, index, pnl_percent, 'stop_loss') if stop_loss_hit

    # Activate trailing stop at 40% profit
    if pnl_percent >= 40 && !position[:trailing_activated]
      position[:trailing_activated] = true
      position[:trailing_stop] = current_price * (signal_type == :ce ? 0.90 : 1.10) # Trail by 10%
    end

    # Update trailing stop
    if position[:trailing_activated]
      if signal_type == :ce
        new_trailing = current_price * 0.90
        position[:trailing_stop] = [position[:trailing_stop], new_trailing].max

        # Check trailing stop hit
        if current_price <= position[:trailing_stop]
          return build_exit_result(position, candle, index, pnl_percent, 'trailing_stop')
        end
      else # :pe
        new_trailing = current_price * 1.10
        position[:trailing_stop] = [position[:trailing_stop], new_trailing].min

        # Check trailing stop hit
        if current_price >= position[:trailing_stop]
          return build_exit_result(position, candle, index, pnl_percent, 'trailing_stop')
        end
      end
    end

    # Time-based exit (3:20 PM)
    if candle.timestamp.hour >= 15 && candle.timestamp.min >= 20
      return build_exit_result(position, candle, index, pnl_percent, 'time_exit')
    end

    nil # No exit
  end

  def force_exit(position, candle, index, reason)
    current_price = candle.close
    entry_price = position[:entry_price]
    signal_type = position[:signal_type]

    pnl_percent = if signal_type == :ce
                    ((current_price - entry_price) / entry_price * 100)
                  else
                    ((entry_price - current_price) / entry_price * 100)
                  end

    build_exit_result(position, candle, index, pnl_percent, reason)
  end

  def build_exit_result(position, candle, index, pnl_percent, exit_reason)
    result = {
      signal_type: position[:signal_type],
      entry_time: position[:entry_time],
      entry_price: position[:entry_price],
      exit_time: candle.timestamp,
      exit_price: candle.close,
      pnl_percent: pnl_percent.round(2),
      exit_reason: exit_reason,
      bars_held: index - position[:entry_index]
    }
    instrument_event('trade.exit_evaluated', result)
    result
  end

  def instrument_event(event, extra_payload = {}, &)
    payload = base_payload.merge(extra_payload)
    if block_given?
      ActiveSupport::Notifications.instrument("backtest.#{event}", payload, &)
    else
      ActiveSupport::Notifications.instrument("backtest.#{event}", payload)
    end
  end

  def instantiate_strategy(series)
    if @strategy_class.respond_to?(:call)
      # It's a proc/lambda - call it with series
      @strategy_class.call(series)
    else
      # It's a class - instantiate it
      @strategy_class.new(series: series)
    end
  end

  def strategy_name
    if @strategy_class.respond_to?(:call)
      # For procs/lambdas, use a generic name
      # The actual strategy class name will be available after instantiation
      'CustomStrategy'
    else
      @strategy_class.name
    end
  end

  def base_payload
    {
      symbol: instrument&.symbol_name,
      instrument_id: instrument&.id,
      interval: interval,
      days_back: days_back,
      strategy: strategy_name
    }.compact
  end
end


# File: app/services/capital/allocator.rb
# frozen_string_literal: true

require 'bigdecimal'

module Capital
  class Allocator
    # Capital-aware deployment policy based on account size
    # Bands are inclusive upper-bounds. Smaller accounts get higher allocation % but lower risk %
    CAPITAL_BANDS = [
      { upto: 75_000, alloc_pct: 0.30, risk_per_trade_pct: 0.050, daily_max_loss_pct: 0.050 }, # small a/c (≈ ₹50k)
      { upto: 150_000, alloc_pct: 0.25, risk_per_trade_pct: 0.035, daily_max_loss_pct: 0.060 }, # ≈ ₹1L
      { upto: 300_000, alloc_pct: 0.20, risk_per_trade_pct: 0.030, daily_max_loss_pct: 0.060 }, # ≈ ₹2–3L
      { upto: Float::INFINITY, alloc_pct: 0.20, risk_per_trade_pct: 0.025, daily_max_loss_pct: 0.050 }
    ].freeze

    class << self
      def qty_for(index_cfg:, entry_price:, derivative_lot_size:, scale_multiplier: 1)
        multiplier = normalize_multiplier(scale_multiplier)
        capital_available = available_cash

        return 0 unless valid_for_allocation?(index_cfg, entry_price, derivative_lot_size, capital_available)

        calculate_and_apply_quantity(
          index_cfg: index_cfg,
          entry_price: entry_price,
          derivative_lot_size: derivative_lot_size,
          capital_available: capital_available,
          multiplier: multiplier
        )
      rescue StandardError => e
        log_allocation_error(index_cfg, e)
        0
      end

      def deployment_policy(balance)
        band = find_capital_band(balance)
        build_policy_with_overrides(band)
      end

      def available_cash
        return paper_trading_balance if paper_trading_enabled?

        fetch_live_trading_balance
      rescue StandardError => e
        log_balance_fetch_error(e)
        BigDecimal(0)
      end

      def paper_trading_enabled?
        AlgoConfig.fetch.dig(:paper_trading, :enabled) == true
      end

      def paper_trading_balance
        balance = AlgoConfig.fetch.dig(:paper_trading, :balance) || 100_000
        BigDecimal(balance.to_s)
      end

      private

      def normalize_multiplier(scale_multiplier)
        [scale_multiplier.to_i, 1].max
      end

      def valid_for_allocation?(index_cfg, entry_price, derivative_lot_size, capital_available)
        return log_and_return_false("[Capital] Available capital is zero for #{index_cfg[:key]}") if capital_available.zero?
        return log_and_return_false("[Capital] Invalid entry price for #{index_cfg[:key]}: #{entry_price}") if entry_price.to_f <= 0

        lot_size = derivative_lot_size.to_i
        return log_and_return_false("[Capital] Invalid lot size for #{index_cfg[:key]}: #{lot_size}") if lot_size <= 0

        unless can_afford_minimum_lot?(
          entry_price, lot_size, capital_available
        )
          return log_insufficient_capital(index_cfg, entry_price, lot_size,
                                          capital_available)
        end

        true
      end

      def can_afford_minimum_lot?(entry_price, lot_size, capital_available)
        min_lot_cost = entry_price.to_f * lot_size
        capital_available >= min_lot_cost
      end

      def log_insufficient_capital(index_cfg, entry_price, lot_size, capital_available)
        min_lot_cost = entry_price.to_f * lot_size
        Rails.logger.warn("[Capital] Insufficient capital for minimum lot for #{index_cfg[:key]}: Available ₹#{capital_available}, Required ₹#{min_lot_cost} (price: ₹#{entry_price}, lot_size: #{lot_size})")
        false
      end

      def log_and_return_false(message)
        Rails.logger.warn(message)
        false
      end

      def calculate_and_apply_quantity(index_cfg:, entry_price:, derivative_lot_size:, capital_available:, multiplier:)
        @index_key = index_cfg[:key] || 'UNKNOWN'
        capital_available_f = capital_available.to_f
        entry_price_f = entry_price.to_f
        lot_size = derivative_lot_size.to_i

        policy = deployment_policy(capital_available_f)
        effective_alloc_pct = index_cfg[:capital_alloc_pct] || policy[:alloc_pct]
        effective_risk_pct = policy[:risk_per_trade_pct]

        quantity = calculate_quantity_by_constraints(
          capital_available_f: capital_available_f,
          entry_price_f: entry_price_f,
          lot_size: lot_size,
          effective_alloc_pct: effective_alloc_pct,
          effective_risk_pct: effective_risk_pct,
          multiplier: multiplier
        )

        final_quantity = apply_quantity_safety_checks(
          quantity: quantity,
          entry_price_f: entry_price_f,
          lot_size: lot_size,
          capital_available_f: capital_available_f
        )

        log_allocation_breakdown(
          capital_available: capital_available,
          policy: policy,
          effective_alloc_pct: effective_alloc_pct,
          effective_risk_pct: effective_risk_pct,
          multiplier: multiplier,
          entry_price_f: entry_price_f,
          lot_size: lot_size,
          final_quantity: final_quantity
        )

        final_quantity
      end

      def calculate_quantity_by_constraints(capital_available_f:, entry_price_f:, lot_size:, effective_alloc_pct:,
                                            effective_risk_pct:, multiplier:)
        max_by_allocation = calculate_max_by_allocation(capital_available_f, entry_price_f, lot_size,
                                                        effective_alloc_pct, multiplier)
        max_by_risk = calculate_max_by_risk(capital_available_f, entry_price_f, lot_size, effective_risk_pct,
                                            multiplier)

        [max_by_allocation, max_by_risk].min
      end

      def calculate_max_by_allocation(capital_available_f, entry_price_f, lot_size, effective_alloc_pct, multiplier)
        allocation = capital_available_f * effective_alloc_pct
        scaled_allocation = [allocation * multiplier, capital_available_f].min
        cost_per_lot = entry_price_f * lot_size

        (scaled_allocation / cost_per_lot).floor * lot_size
      end

      def calculate_max_by_risk(capital_available_f, entry_price_f, lot_size, effective_risk_pct, multiplier)
        risk_capital = capital_available_f * effective_risk_pct
        risk_capital_scaled = [risk_capital * multiplier, capital_available_f].min
        stop_loss_per_share = entry_price_f * 0.30

        (risk_capital_scaled / stop_loss_per_share).floor * lot_size
      end

      def apply_quantity_safety_checks(quantity:, entry_price_f:, lot_size:, capital_available_f:)
        final_quantity = enforce_lot_size_constraints(quantity, lot_size)
        adjust_if_exceeds_capital(final_quantity, entry_price_f, lot_size, capital_available_f)
      end

      def enforce_lot_size_constraints(quantity, lot_size)
        [[quantity, lot_size].max, lot_size * 100].min
      end

      def adjust_if_exceeds_capital(final_quantity, entry_price_f, lot_size, capital_available_f)
        final_buy_value = entry_price_f * final_quantity
        return final_quantity if final_buy_value <= capital_available_f

        reduce_to_affordable_quantity(entry_price_f, lot_size, capital_available_f)
      end

      def reduce_to_affordable_quantity(entry_price_f, lot_size, capital_available_f)
        cost_per_lot = entry_price_f * lot_size
        max_affordable_lots = (capital_available_f / cost_per_lot).floor
        final_quantity = max_affordable_lots * lot_size

        [final_quantity, lot_size].max
      end

      def find_capital_band(balance)
        CAPITAL_BANDS.find { |b| balance <= b[:upto] } || CAPITAL_BANDS.last
      end

      def build_policy_with_overrides(band)
        {
          upto: band[:upto],
          alloc_pct: allocation_percentage_with_override(band),
          risk_per_trade_pct: risk_per_trade_with_override(band),
          daily_max_loss_pct: daily_max_loss_with_override(band)
        }
      end

      def allocation_percentage_with_override(band)
        ENV['ALLOC_PCT']&.to_f || band[:alloc_pct]
      end

      def risk_per_trade_with_override(band)
        ENV['RISK_PER_TRADE_PCT']&.to_f || band[:risk_per_trade_pct]
      end

      def daily_max_loss_with_override(band)
        ENV['DAILY_MAX_LOSS_PCT']&.to_f || band[:daily_max_loss_pct]
      end

      def fetch_live_trading_balance
        data = DhanHQ::Models::Funds.fetch
        value = data.available_balance

        return handle_missing_balance(data) if value.nil?

        convert_to_bigdecimal(value)
      end

      def handle_missing_balance(data)
        Rails.logger.warn("[Capital] Failed to extract available_balance from funds data: #{data.inspect}")
        BigDecimal(0)
      end

      def convert_to_bigdecimal(value)
        result = value.is_a?(BigDecimal) ? value : BigDecimal(value.to_s)
        Rails.logger.debug { "[Capital] Available cash: ₹#{result}" }
        result
      end

      def log_balance_fetch_error(error)
        Rails.logger.error("[Capital] Failed to fetch available cash: #{error.class} - #{error.message}")
        Rails.logger.error("[Capital] Backtrace: #{error.backtrace.first(3).join(', ')}")
      end

      def log_allocation_error(index_cfg, error)
        Rails.logger.error("[Capital] Allocator failed for #{index_cfg[:key]}: #{error.class} - #{error.message}")
        Rails.logger.error("[Capital] Backtrace: #{error.backtrace.first(3).join(', ')}")
      end

      def log_allocation_breakdown(capital_available:, policy:, effective_alloc_pct:, effective_risk_pct:, multiplier:,
                                   entry_price_f:, lot_size:, final_quantity:)
        capital_available_f = capital_available.to_f
        cost_per_lot = entry_price_f * lot_size
        total_buy_value = entry_price_f * final_quantity
        index_key = @index_key || 'UNKNOWN'

        reason = if final_quantity.zero?
                   'insufficient_capital'
                 elsif final_quantity < lot_size
                   'below_minimum_lot'
                 else
                   'allocated'
                 end

        Rails.logger.info(
          "[Allocator] index:#{index_key} lot_cost:₹#{cost_per_lot.round(2)} " \
          "capital:₹#{capital_available_f.round(2)} qty:#{final_quantity} reason:#{reason}"
        )
      end
    end
  end
end


# File: app/services/core/event_bus.rb
# frozen_string_literal: true

require 'singleton'
require 'concurrent/map'
require 'concurrent/array'

module Core
  # Central pub/sub event bus for NEMESIS V3 architecture
  # Provides internal event broadcasting for system components
  # Thread-safe singleton for high-performance tick processing
  # rubocop:disable Metrics/ClassLength
  class EventBus
    include Singleton

    # Event types
    EVENTS = {
      ltp: :ltp,
      entry_filled: :entry_filled,
      sl_hit: :sl_hit,
      tp_hit: :tp_hit,
      structure_break: :structure_break,
      exit_triggered: :exit_triggered,
      risk_alert: :risk_alert,
      breakeven_lock: :breakeven_lock,
      trailing_triggered: :trailing_triggered,
      danger_zone: :danger_zone,
      volatility_spike: :volatility_spike,
      trend_flip: :trend_flip
    }.freeze

    def initialize
      @subscribers = Concurrent::Map.new { |h, k| h[k] = Concurrent::Array.new }
      @lock = Mutex.new
      @stats = {
        events_published: 0,
        events_delivered: 0,
        errors: 0
      }
    end

    # Subscribe to an event type
    # @param event_type [Symbol] Event type (e.g., :ltp, :sl_hit)
    # @param subscriber [Object, Proc] Subscriber object or proc
    # @param method_name [Symbol, nil] Method name to call on subscriber (if object)
    # @return [String] Subscription ID for unsubscribing
    def subscribe(event_type, subscriber = nil, method_name: nil, &block)
      raise ArgumentError, "Unknown event type: #{event_type}" unless EVENTS.value?(event_type)

      handler = if block
                  block
                elsif subscriber.is_a?(Proc)
                  subscriber
                elsif subscriber && method_name
                  ->(event) { subscriber.public_send(method_name, event) }
                elsif subscriber.respond_to?(:call)
                  ->(event) { subscriber.call(event) }
                else
                  raise ArgumentError, 'Must provide block, proc, or subscriber with method_name'
                end

      subscription_id = SecureRandom.uuid
      @subscribers[event_type] << {
        id: subscription_id,
        handler: handler,
        subscriber: subscriber
      }

      Rails.logger.debug { "[Core::EventBus] Subscribed to #{event_type} (#{subscription_id[0..7]})" }
      subscription_id
    end

    # Publish an event to all subscribers
    # @param event_type [Symbol] Event type
    # @param event [Object] Event object (must respond to #to_h or be a Hash)
    # @return [Integer] Number of subscribers notified
    def publish(event_type, event)
      raise ArgumentError, "Unknown event type: #{event_type}" unless EVENTS.value?(event_type)

      subscribers = @subscribers[event_type]
      return 0 if subscribers.empty?

      @stats[:events_published] += 1
      notified = 0

      subscribers.each do |subscription|
        subscription[:handler].call(event)
        notified += 1
        @stats[:events_delivered] += 1
      rescue StandardError => e
        @stats[:errors] += 1
        Rails.logger.error(
          "[Core::EventBus] Error delivering #{event_type} to subscriber: #{e.class} - #{e.message}"
        )
        Rails.logger.debug { e.backtrace.first(5).join("\n") }
      end

      notified
    end

    # Unsubscribe from an event
    # @param subscription_id [String] Subscription ID returned from subscribe
    # @return [Boolean] True if unsubscribed, false if not found
    def unsubscribe(subscription_id)
      found = false
      @subscribers.each_value do |subs|
        subs.delete_if do |sub|
          if sub[:id] == subscription_id
            found = true
            true
          else
            false
          end
        end
      end

      Rails.logger.debug { "[Core::EventBus] Unsubscribed (#{subscription_id[0..7]})" } if found
      found
    end

    # Unsubscribe all handlers for a specific subscriber object
    # @param subscriber [Object] Subscriber object to remove
    # @return [Integer] Number of subscriptions removed
    def unsubscribe_all(subscriber)
      removed = 0
      @subscribers.each_value do |subs|
        subs.delete_if do |sub|
          if sub[:subscriber] == subscriber
            removed += 1
            true
          else
            false
          end
        end
      end

      Rails.logger.debug { "[Core::EventBus] Unsubscribed all for #{subscriber.class.name} (#{removed} subscriptions)" } if removed.positive?
      removed
    end

    # Get statistics
    # @return [Hash] Statistics hash
    def stats
      @stats.dup
    end

    # Clear all subscriptions (for testing/cleanup)
    def clear
      @subscribers.clear
      @stats = {
        events_published: 0,
        events_delivered: 0,
        errors: 0
      }
      Rails.logger.debug('[Core::EventBus] Cleared all subscriptions')
    end

    # Get subscriber count for an event type
    # @param event_type [Symbol] Event type
    # @return [Integer] Number of subscribers
    def subscriber_count(event_type)
      @subscribers[event_type]&.size || 0
    end
  end
  # rubocop:enable Metrics/ClassLength
end


# File: app/services/entries/entry_guard.rb
# frozen_string_literal: true

module Entries
  class EntryGuard
    class << self
      def try_enter(index_cfg:, pick:, direction:, scale_multiplier: 1)
        instrument = find_instrument(index_cfg)
        unless instrument
          Rails.logger.warn("[EntryGuard] Instrument not found for #{index_cfg[:key]} (segment: #{index_cfg[:segment]}, sid: #{index_cfg[:sid]})")
          return false
        end

        multiplier = [scale_multiplier.to_i, 1].max
        Rails.logger.info("[EntryGuard] Scale multiplier for #{index_cfg[:key]}: x#{multiplier}") if multiplier > 1

        side = direction == :bullish ? 'long_ce' : 'long_pe'
        unless exposure_ok?(instrument: instrument, side: side, max_same_side: index_cfg[:max_same_side])
          Rails.logger.debug { "[EntryGuard] Exposure check failed for #{index_cfg[:key]}: #{pick[:symbol]} (side: #{side}, max_same_side: #{index_cfg[:max_same_side]})" }
          return false
        end

        if cooldown_active?(pick[:symbol], index_cfg[:cooldown_sec].to_i)
          Rails.logger.warn("[EntryGuard] Cooldown active for #{index_cfg[:key]}: #{pick[:symbol]}")
          return false
        end

        # Never block due to WebSocket - always allow REST API fallback
        # Log WebSocket status for monitoring but don't block
        hub = Live::MarketFeedHub.instance
        unless hub.running? && hub.connected?
          Rails.logger.info('[EntryGuard] WebSocket not connected - will use REST API fallback for LTP')
        end

        # Rails.logger.debug { "[EntryGuard] Pick data: #{pick.inspect}" }
        # Resolve LTP with REST API fallback if WebSocket unavailable
        ltp = pick[:ltp]
        if ltp.blank? || needs_api_ltp?(pick)
          # Fetch fresh LTP from REST API when WS unavailable or pick LTP is stale
          resolved_ltp = resolve_entry_ltp(instrument: instrument, pick: pick, index_cfg: index_cfg)
          ltp = resolved_ltp if resolved_ltp.present?
        end

        unless ltp.present? && ltp.to_f.positive?
          Rails.logger.warn("[EntryGuard] Invalid LTP for #{index_cfg[:key]}: #{pick[:symbol]} (ltp: #{ltp.inspect})")
          return false
        end

        quantity = Capital::Allocator.qty_for(
          index_cfg: index_cfg,
          entry_price: ltp.to_f,
          derivative_lot_size: pick[:lot_size],
          scale_multiplier: multiplier
        )
        if quantity <= 0
          Rails.logger.warn("[EntryGuard] Invalid quantity for #{index_cfg[:key]}: #{pick[:symbol]} (qty: #{quantity}, ltp: #{ltp}, lot_size: #{pick[:lot_size]})")
          return false
        end

        # Paper trading mode: Skip real order placement, create PositionTracker directly
        if paper_trading_enabled?
          return create_paper_tracker!(
            instrument: instrument,
            pick: pick,
            side: side,
            quantity: quantity,
            index_cfg: index_cfg,
            ltp: ltp
          )
        end

        # Live trading: Place real order
        response = Orders.config.place_market(
          side: 'buy',
          segment: pick[:segment] || index_cfg[:segment],
          security_id: pick[:security_id],
          qty: quantity,
          meta: {
            client_order_id: build_client_order_id(index_cfg: index_cfg, pick: pick),
            ltp: ltp # Pass resolved LTP (from WS or API)
          }
        )

        order_no = extract_order_no(response)
        unless order_no
          Rails.logger.warn("[EntryGuard] Order placement failed for #{index_cfg[:key]}: #{pick[:symbol]} (response: #{response.inspect})")
          return false
        end

        create_tracker!(
          instrument: instrument,
          order_no: order_no,
          pick: pick,
          side: side,
          quantity: quantity,
          index_cfg: index_cfg,
          ltp: ltp
        )

        Rails.logger.info("[EntryGuard] Successfully placed order #{order_no} for #{index_cfg[:key]}: #{pick[:symbol]}")
        true
      rescue StandardError => e
        Rails.logger.error("EntryGuard failed for #{index_cfg[:key]}: #{e.class} - #{e.message}")
        false
      end

      def exposure_ok?(instrument:, side:, max_same_side:)
        max_allowed = max_same_side.to_i

        # Safety check: if max_same_side is not configured (nil or 0), default to 1
        if max_allowed <= 0
          Rails.logger.warn("[EntryGuard] Invalid max_same_side value: #{max_same_side.inspect}, defaulting to 1")
          max_allowed = 1
        end

        # Check positions by underlying instrument (for derivatives, check their underlying instrument)
        # This ensures all positions on the same index count together, regardless of strike
        # Query by instrument_id (for direct positions) OR by watchable_type='Derivative' with instrument_id
        active_positions = PositionTracker.active.where(side: side).where(
          "(instrument_id = ? OR (watchable_type = 'Derivative' AND watchable_id IN (SELECT id FROM derivatives WHERE instrument_id = ?)))",
          instrument.id, instrument.id
        ).limit(max_allowed + 1)
        current_count = active_positions.count

        Rails.logger.debug { "[EntryGuard] Exposure check for #{instrument.symbol_name}: side=#{side}, current=#{current_count}, max=#{max_allowed}" }

        # Check if we've reached the maximum allowed positions
        if current_count >= max_allowed
          Rails.logger.warn("[EntryGuard] Exposure limit reached for #{instrument.symbol_name}: #{current_count} >= #{max_allowed} (side: #{side})")
          return false
        end

        # If this would be the second position, check pyramiding rules
        if current_count == 1
          first_position = active_positions.first

          # Reload to get latest data
          first_position.reload

          # Try to hydrate PnL from Redis cache first (has live PnL data)
          first_position.hydrate_pnl_from_cache!

          # If PnL is still nil or zero, calculate it (especially for paper positions or if Redis cache is empty)
          if (first_position.last_pnl_rupees.nil? || first_position.last_pnl_rupees.zero?) && first_position.entry_price.present? && first_position.quantity.present?
            calculate_current_pnl(first_position)
            # Reload after calculation to get updated PnL
            first_position.reload
          end

          unless pyramiding_allowed?(first_position)
            pnl_display = first_position.last_pnl_rupees ? "₹#{first_position.last_pnl_rupees.round(2)}" : 'N/A'
            Rails.logger.warn("[EntryGuard] Pyramiding not allowed for #{instrument.symbol_name}: first position PnL=#{pnl_display}, updated_at=#{first_position.updated_at}")
            return false
          end
        end

        Rails.logger.debug { "[EntryGuard] Exposure check passed for #{instrument.symbol_name}: #{current_count} < #{max_allowed}" }
        true
      end

      def pyramiding_allowed?(first_position)
        # Second position only allowed if first position is profitable
        return false unless first_position.last_pnl_rupees&.positive?

        # Additional check: ensure first position has been profitable for at least 5 minutes
        # to avoid premature pyramiding
        min_profit_duration = 5.minutes
        return false unless first_position.updated_at < min_profit_duration.ago

        Rails.logger.info("[Pyramiding] Allowing second position - first position profitable: ₹#{first_position.last_pnl_rupees.round(2)}")
        true
      rescue StandardError => e
        Rails.logger.error("Pyramiding check failed: #{e.message}")
        false
      end

      def calculate_current_pnl(tracker)
        return unless tracker.entry_price.present? && tracker.quantity.present?

        # For paper positions, use get_paper_ltp method
        if tracker.paper?
          ltp = get_paper_ltp_for_tracker(tracker)
          return unless ltp

          entry = BigDecimal(tracker.entry_price.to_s)
          exit_price = BigDecimal(ltp.to_s)
          qty = tracker.quantity.to_i
          pnl = (exit_price - entry) * qty
          pnl_pct = ((exit_price - entry) / entry * 100).round(2)

          hwm = tracker.high_water_mark_pnl || BigDecimal(0)
          hwm = [hwm, pnl].max

          tracker.update!(
            last_pnl_rupees: pnl,
            last_pnl_pct: pnl_pct,
            high_water_mark_pnl: hwm,
            avg_price: exit_price
          )

          Rails.logger.debug { "[EntryGuard] Calculated PnL for paper position #{tracker.order_no}: PnL=₹#{pnl.round(2)}" }
          return
        end

        # For live positions, try to get from Redis PnL cache first (has pre-calculated PnL)
        # Then fall back to calculating from tick data
        pnl_cache = Live::RedisPnlCache.instance.fetch_pnl(tracker.id)
        if pnl_cache && pnl_cache[:pnl]
          # Use pre-calculated PnL from Redis
          tracker.update!(
            last_pnl_rupees: BigDecimal(pnl_cache[:pnl].to_s),
            last_pnl_pct: pnl_cache[:pnl_pct] ? BigDecimal(pnl_cache[:pnl_pct].to_s) : nil,
            high_water_mark_pnl: pnl_cache[:hwm_pnl] ? BigDecimal(pnl_cache[:hwm_pnl].to_s) : tracker.high_water_mark_pnl
          )
          Rails.logger.debug { "[EntryGuard] Loaded PnL from Redis cache for #{tracker.order_no}: PnL=₹#{pnl_cache[:pnl].round(2)}" }
          return
        end

        # Fallback: Calculate from tick data if Redis PnL cache is empty
        segment = tracker.segment.presence || tracker.watchable&.exchange_segment || tracker.instrument&.exchange_segment
        security_id = tracker.security_id
        return unless segment.present? && security_id.present?

        # Try Redis tick cache
        tick_data = Live::TickCache.fetch(segment, security_id)
        if tick_data&.dig(:ltp)
          ltp = BigDecimal(tick_data[:ltp].to_s)
          entry = BigDecimal(tracker.entry_price.to_s)
          qty = tracker.quantity.to_i
          pnl = (ltp - entry) * qty
          pnl_pct = entry.positive? ? ((ltp - entry) / entry * 100).round(2) : nil

          hwm = tracker.high_water_mark_pnl || BigDecimal(0)
          hwm = [hwm, pnl].max

          tracker.update!(
            last_pnl_rupees: pnl,
            last_pnl_pct: pnl_pct,
            high_water_mark_pnl: hwm
          )
          Rails.logger.debug { "[EntryGuard] Calculated PnL from tick data for #{tracker.order_no}: PnL=₹#{pnl.round(2)}" }
        end
      rescue StandardError => e
        Rails.logger.error("[EntryGuard] Failed to calculate PnL for #{tracker.order_no}: #{e.message}")
      end

      def get_paper_ltp_for_tracker(tracker)
        segment = tracker.segment.presence || tracker.watchable&.exchange_segment || tracker.instrument&.exchange_segment
        security_id = tracker.security_id
        return nil unless segment.present? && security_id.present?

        # Try WebSocket cache first
        cached = Live::TickCache.ltp(segment, security_id)
        return BigDecimal(cached.to_s) if cached

        # Try Redis PnL cache
        tick_data = Live::TickCache.fetch(segment, security_id)
        return BigDecimal(tick_data[:ltp].to_s) if tick_data&.dig(:ltp)

        # Try tradable's fetch method (derivative or instrument)
        tradable = tracker.tradable
        if tradable
          ltp = tradable.fetch_ltp_from_api_for_segment(segment: segment, security_id: security_id)
          return BigDecimal(ltp.to_s) if ltp
        end

        # Fallback: Direct API call
        begin
          response = DhanHQ::Models::MarketFeed.ltp({ segment => [security_id.to_i] })
          if response['status'] == 'success'
            option_data = response.dig('data', segment, security_id.to_s)
            return BigDecimal(option_data['last_price'].to_s) if option_data && option_data['last_price']
          end
        rescue StandardError => e
          Rails.logger.error("[EntryGuard] Failed to fetch LTP for #{tracker.order_no}: #{e.message}")
        end
        nil
      end

      def cooldown_active?(symbol, cooldown)
        return false if symbol.blank? || cooldown <= 0

        last = Rails.cache.read("reentry:#{symbol}")
        last.present? && (Time.current - last) < cooldown
      end

      # Checks if we need to fetch LTP from REST API
      # @param pick [Hash] Pick data from signal
      # @return [Boolean]
      def needs_api_ltp?(pick)
        hub = Live::MarketFeedHub.instance
        return true unless hub.running? && hub.connected?

        # If pick LTP is missing or zero, we need API fallback
        pick[:ltp].blank? || pick[:ltp].to_f.zero?
      end

      # Resolves LTP for entry order, prioritizing WebSocket subscription over API polling
      # Strategy: Subscribe to WebSocket feed, wait for tick, read from TickCache
      # Falls back to REST API only if WebSocket unavailable or tick doesn't arrive
      # @param instrument [Instrument]
      # @param pick [Hash] Pick data from signal
      # @param index_cfg [Hash] Index configuration
      # @return [BigDecimal, nil]
      def resolve_entry_ltp(instrument:, pick:, index_cfg:)
        segment = pick[:segment] || index_cfg[:segment]
        security_id = pick[:security_id]

        return nil unless segment.present? && security_id.present?

        hub = Live::MarketFeedHub.instance

        # Strategy 1: WebSocket subscription + TickCache (fastest, no API rate limits)
        if hub.running? && hub.connected?
          # Subscribe to the strike/derivative immediately
          begin
            hub.subscribe(segment: segment, security_id: security_id)
            Rails.logger.debug { "[EntryGuard] Subscribed to #{segment}:#{security_id} for LTP resolution" }

            # Wait briefly for tick to arrive (typically < 100ms)
            max_wait_ms = 300
            poll_interval_ms = 50
            attempts = (max_wait_ms / poll_interval_ms).to_i

            attempts.times do
              cached_ltp = Live::TickCache.ltp(segment, security_id)
              if cached_ltp.present? && cached_ltp.to_f.positive?
                Rails.logger.debug { "[EntryGuard] Got LTP from TickCache for #{segment}:#{security_id}: ₹#{cached_ltp}" }
                return BigDecimal(cached_ltp.to_s)
              end
              sleep(poll_interval_ms / 1000.0) # Convert ms to seconds
            end

            Rails.logger.debug { "[EntryGuard] No tick received from WebSocket for #{segment}:#{security_id} after #{max_wait_ms}ms, falling back to API" }
          rescue StandardError => e
            Rails.logger.warn("[EntryGuard] WebSocket subscription failed for #{segment}:#{security_id}: #{e.message}, falling back to API")
          end
        else
          Rails.logger.debug { "[EntryGuard] WebSocket not available, using API fallback for #{segment}:#{security_id}" }
        end

        # Strategy 2: REST API fallback (only if WebSocket unavailable or no tick received)
        # Try to resolve via instrument/derivative object
        if pick[:derivative_id].present?
          derivative = Derivative.find_by(id: pick[:derivative_id])
          if derivative
            api_ltp = derivative.fetch_ltp_from_api_for_segment(segment: segment, security_id: security_id)
            return BigDecimal(api_ltp.to_s) if api_ltp.present?
          end
        end

        # Fallback to instrument method
        api_ltp = instrument.fetch_ltp_from_api_for_segment(segment: segment, security_id: security_id)
        return BigDecimal(api_ltp.to_s) if api_ltp.present?

        Rails.logger.warn("[EntryGuard] Failed to resolve LTP from API for #{segment}:#{security_id}")
        nil
      rescue StandardError => e
        Rails.logger.error("[EntryGuard] Error resolving entry LTP: #{e.class} - #{e.message}")
        nil
      end

      private

      # Removed ensure_ws_connection! - no longer needed
      # WebSocket status is checked inline in try_enter for logging only
      # REST API fallback is always used when WS unavailable

      def find_instrument(index_cfg)
        segment_code = index_cfg[:segment]
        instrument = Instrument.find_by_sid_and_segment(
          security_id: index_cfg[:sid],
          segment_code: segment_code,
          symbol_name: index_cfg[:key]
        )

        unless instrument
          # Rails.logger.warn(
          #   "[EntryGuard] Instrument lookup failed for #{index_cfg[:key]} (segment: #{segment_code}, sid: #{index_cfg[:sid]})"
          # )
        end

        instrument
      end

      def build_client_order_id(index_cfg:, pick:)
        # DhanHQ correlation_id limit is 25 characters
        # Format: AS-{KEY}-{SID}-{TIMESTAMP}
        # Keep it under 25 chars by using shorter timestamp
        timestamp = Time.current.to_i.to_s[-6..] # Last 6 digits of timestamp
        "AS-#{index_cfg[:key][0..3]}-#{pick[:security_id]}-#{timestamp}"
      end

      def extract_order_no(response)
        return if response.blank?

        if response.respond_to?(:order_id)
          response.order_id
        elsif response.is_a?(Hash)
          response[:order_id] || response[:order_no]
        elsif response.respond_to?(:[]) # Struct-like (e.g., OpenStruct)
          response[:order_id] || response[:order_no] || response.order_id
        end
      end

      def paper_trading_enabled?
        AlgoConfig.fetch.dig(:paper_trading, :enabled) == true
      end

      def create_paper_tracker!(instrument:, pick:, side:, quantity:, index_cfg:, ltp:)
        # Generate synthetic order number for paper trading
        order_no = "PAPER-#{index_cfg[:key]}-#{pick[:security_id]}-#{Time.current.to_i}"

        # Determine watchable: derivative for options, instrument for indices
        watchable = find_watchable_for_pick(pick: pick, instrument: instrument)

        tracker = PositionTracker.create!(
          watchable: watchable,
          instrument: watchable.is_a?(Derivative) ? watchable.instrument : watchable, # Backward compatibility
          order_no: order_no,
          security_id: pick[:security_id].to_s,
          symbol: pick[:symbol],
          segment: pick[:segment] || index_cfg[:segment],
          side: side,
          quantity: quantity,
          entry_price: ltp,
          avg_price: ltp,
          status: 'active',
          paper: true,
          meta: {
            index_key: index_cfg[:key],
            direction: side,
            placed_at: Time.current,
            paper_trading: true
          }
        )

        # Subscription is handled automatically by after_create_commit :subscribe_to_feed callback
        # No need to call tracker.subscribe explicitly

        # Initialize PnL in Redis (will be 0 initially since entry_price = ltp)
        # This ensures the position is tracked in Redis from the start
        initial_pnl = BigDecimal(0)
        Live::RedisPnlCache.instance.store_pnl(
          tracker_id: tracker.id,
          pnl: initial_pnl,
          pnl_pct: 0.0,
          ltp: ltp,
          hwm: initial_pnl,
          timestamp: Time.current
        )

        Rails.logger.info("[EntryGuard] Paper trading: Created position #{order_no} for #{index_cfg[:key]}: #{pick[:symbol]} (qty: #{quantity}, entry: ₹#{ltp}, watchable: #{watchable.class.name})")
        true
      rescue ActiveRecord::RecordInvalid => e
        Rails.logger.error("Failed to persist paper tracker: #{e.record.errors.full_messages.to_sentence}")
        false
      end

      def create_tracker!(instrument:, order_no:, pick:, side:, quantity:, index_cfg:, ltp:)
        # Determine watchable: derivative for options, instrument for indices
        watchable = find_watchable_for_pick(pick: pick, instrument: instrument)

        PositionTracker.build_or_average!(
          watchable: watchable,
          instrument: watchable.is_a?(Derivative) ? watchable.instrument : watchable, # Backward compatibility
          order_no: order_no,
          security_id: pick[:security_id].to_s,
          symbol: pick[:symbol],
          segment: pick[:segment] || index_cfg[:segment],
          side: side,
          quantity: quantity,
          entry_price: ltp,
          meta: { index_key: index_cfg[:key], direction: side, placed_at: Time.current }
        )
      rescue ActiveRecord::RecordInvalid => e
        Rails.logger.error("Failed to persist tracker for order #{order_no}: #{e.record.errors.full_messages.to_sentence}")
      end

      def find_watchable_for_pick(pick:, instrument:)
        # If derivative_id is provided in pick, use it
        if pick[:derivative_id].present?
          derivative = Derivative.find_by(id: pick[:derivative_id])
          return derivative if derivative
        end

        # Try to find derivative by security_id and segment
        segment = pick[:segment] || instrument.exchange_segment
        if segment.present? && pick[:security_id].present?
          derivative = Derivative.find_by(
            security_id: pick[:security_id].to_s,
            exchange: instrument.exchange,
            segment: segment
          )
          return derivative if derivative
        end

        # Fallback to instrument (for index positions)
        instrument
      end
    end
  end
end


# File: app/services/index_instrument_cache.rb
# frozen_string_literal: true

class IndexInstrumentCache
  include Singleton

  CACHE_DURATION = 1.hour

  def initialize
    @cache = {}
    @cache_timestamps = {}
  end

  def get_or_fetch(index_cfg)
    cache_key = "#{index_cfg[:key]}_#{index_cfg[:sid]}_#{index_cfg[:segment]}"

    # Return cached instrument if still valid
    if cached?(cache_key)
      # Rails.logger.debug { "[IndexCache] Using cached instrument for #{index_cfg[:key]} (#{index_cfg[:segment]})" }
      return @cache[cache_key]
    end

    # Fetch and cache the instrument
    instrument = fetch_instrument(index_cfg)
    if instrument
      @cache[cache_key] = instrument
      @cache_timestamps[cache_key] = Time.current
      # Rails.logger.info("[IndexCache] Cached instrument for #{index_cfg[:key]} (#{index_cfg[:segment]}): #{instrument.symbol_name}")
    end

    instrument
  end

  def clear_cache(index_cfg = nil)
    if index_cfg
      cache_key = "#{index_cfg[:key]}_#{index_cfg[:sid]}_#{index_cfg[:segment]}"
      @cache.delete(cache_key)
      @cache_timestamps.delete(cache_key)
      # Rails.logger.info("[IndexCache] Cleared cache for #{index_cfg[:key]} (#{index_cfg[:segment]})")
    else
      @cache.clear
      @cache_timestamps.clear
      # Rails.logger.info('[IndexCache] Cleared all cached instruments')
    end
  end

  def cache_stats
    {
      cached_count: @cache.size,
      cache_keys: @cache.keys,
      oldest_cache: @cache_timestamps.values.min,
      newest_cache: @cache_timestamps.values.max
    }
  end

  private

  def cached?(cache_key)
    return false unless @cache[cache_key] && @cache_timestamps[cache_key]

    Time.current - @cache_timestamps[cache_key] < CACHE_DURATION
  end

  def fetch_instrument(index_cfg)
    # Try to find existing instrument in database first using both security_id and segment
    segment_key = Instrument.segment_key_for(index_cfg[:segment]) || 'index'
    instrument = Instrument.find_by_sid_and_segment(
      security_id: index_cfg[:sid],
      segment_code: segment_key,
      symbol_name: index_cfg[:key]
    )

    if instrument
      # Rails.logger.debug { "[IndexCache] Found existing instrument in DB: #{instrument.symbol_name} (#{segment_key})" }
      return instrument
    end

    # If not found, create a temporary instrument object with the config
    # Rails.logger.info("[IndexCache] Creating temporary instrument for #{index_cfg[:key]} (SID: #{index_cfg[:sid]}, Segment: #{index_cfg[:segment]})")

    exchange = determine_exchange(index_cfg)
    Instrument.new(
      security_id: index_cfg[:sid],
      symbol_name: index_cfg[:key],
      exchange: exchange,
      exchange_segment: determine_exchange_segment(index_cfg, exchange),
      segment: segment_key,
      instrument_code: 'index',
      enabled: true
    )
  end

  def determine_exchange(index_cfg)
    segment = index_cfg[:segment].to_s
    key = index_cfg[:key].to_s.upcase

    return 'BSE' if segment.start_with?('BSE') || key == 'SENSEX'

    'NSE'
  end

  def determine_exchange_segment(index_cfg, exchange)
    segment = index_cfg[:segment].to_s
    return segment if segment.present? && (exchange == 'NSE' || !segment.eql?('IDX_I'))

    if exchange == 'BSE'
      'IDX_I'
    else
      segment.presence || 'IDX_I'
    end
  end
end


# File: app/services/indicators/calculator.rb
# frozen_string_literal: true

module Indicators
  class Calculator
    def initialize(series)
      @series = series
    end

    def rsi(period = 14)
      # Use CandleSeries helper method instead of duplicating logic
      @series.rsi(period)
    end

    def macd(fast_period = 12, slow_period = 26, signal_period = 9)
      # Use CandleSeries helper method instead of duplicating logic
      @series.macd(fast_period, slow_period, signal_period)
    end

    def adx(period = 14)
      # Use CandleSeries helper method instead of duplicating hlc logic
      @series.adx(period)
    end

    def bullish_signal?
      rsi < 30 && adx > 20 && @series.closes.last > @series.closes[-2]
    end

    def bearish_signal?
      rsi > 70 && adx > 20 && @series.closes.last < @series.closes[-2]
    end
  end
end


# File: app/services/indicators/holy_grail.rb
# frozen_string_literal: true

require 'ruby_technical_analysis'
require 'technical_analysis'

module Indicators
  class HolyGrail < ApplicationService
    RTA = RubyTechnicalAnalysis
    TA  = TechnicalAnalysis

    EMA_FAST  = 34
    EMA_SLOW  = 100
    RSI_LEN   = 14
    ADX_LEN   = 14
    ATR_LEN   = 20
    MACD_F = 12
    MACD_S = 26
    MACD_SIG = 9

    DEFAULTS = {
      ema_fast: EMA_FAST,
      ema_slow: EMA_SLOW,
      rsi_len: RSI_LEN,
      adx_len: ADX_LEN,
      atr_len: ATR_LEN,
      macd_f: MACD_F,
      macd_s: MACD_S,
      macd_sig: MACD_SIG,

      adx_gate: 20.0,
      rsi_up_min: 40.0,
      rsi_down_max: 60.0,

      min_candles: EMA_SLOW
    }.freeze

    def self.demo_config
      {
        adx_gate: 0.0,
        rsi_up_min: 0.0,
        rsi_down_max: 100.0,
        min_candles: 1
      }
    end

    Result = Struct.new(
      :bias, :adx, :momentum, :proceed?,
      :sma50, :ema200, :rsi14, :atr14, :macd, :trend,
      keyword_init: true
    ) do
      def to_h = members.zip(values).to_h
    end

    def initialize(candles:, config: {})
      @candles = candles

      @cfg = DEFAULTS.merge((config || {}).transform_keys(&:to_sym))

      min_needed = @cfg[:min_candles].to_i.positive? ? @cfg[:min_candles].to_i : DEFAULTS[:min_candles]
      raise ArgumentError, "need ≥ #{min_needed} candles" if closes.size < min_needed
    end

    def call
      ema_fast = @cfg[:ema_fast]
      ema_slow = @cfg[:ema_slow]
      rsi_len  = @cfg[:rsi_len]
      adx_len  = @cfg[:adx_len]
      atr_len  = @cfg[:atr_len]

      sma50  = sma(ema_fast)
      ema200 = ema(ema_slow)
      rsi14  = rsi(rsi_len)
      macd_h = macd_hash
      adx14  = adx(adx_len)
      atr14  = atr(atr_len)

      bias =
        if    sma50 > ema200 then :bullish
        elsif sma50 < ema200 then :bearish
        else
          :neutral
        end

      rsi_up_min   = @cfg[:rsi_up_min].to_f
      rsi_down_max = @cfg[:rsi_down_max].to_f

      momentum =
        if macd_h[:macd] > macd_h[:signal] && rsi14 >= rsi_up_min
          :up
        elsif macd_h[:macd] < macd_h[:signal] && rsi14 <= rsi_down_max
          :down
        else
          :flat
        end

      adx_gate = @cfg[:adx_gate].to_f

      proceed =
        case bias
        when :bullish
          passed = adx14 >= adx_gate && momentum == :up
          # Rails.logger.debug { "[HolyGrail] Not proceeding (bullish): adx=#{adx14} gate=#{adx_gate}, momentum=#{momentum}" } unless passed
          passed
        when :bearish
          passed = adx14 >= adx_gate && momentum == :down
          # Rails.logger.debug { "[HolyGrail] Not proceeding (bearish): adx=#{adx14} gate=#{adx_gate}, momentum=#{momentum}" } unless passed
          passed
        else
          # Rails.logger.debug { "[HolyGrail] Not proceeding (#{bias}): neutral bias, adx=#{adx14}, momentum=#{momentum}, gate=#{adx_gate}" }
          false
        end

      latest_time = Time.zone.at(stamps.last)
      # Rails.logger.debug { "[HolyGrail] (#{latest_time}) proceed?=#{proceed}" }

      trend =
        if ema200 < closes.last && sma50 > ema200 then :up
        elsif ema200 > closes.last && sma50 < ema200 then :down
        else
          :side
        end

      Result.new(
        bias:, adx: adx14, momentum:, proceed?: proceed,
        sma50:, ema200:, rsi14:, atr14:, macd: macd_h, trend:
      )
    end

    def analyze_volatility
      atr_len = @cfg[:atr_len]
      atr_value = atr(atr_len)

      # Calculate volatility percentile based on recent ATR values
      recent_atrs = []
      (1..20).each do |_i|
        recent_atrs << atr(atr_len)
      rescue StandardError
        # Skip if not enough data
      end

      volatility_percentile = if recent_atrs.any?
                                sorted_atrs = recent_atrs.sort
                                current_rank = sorted_atrs.index(atr_value) || 0
                                current_rank.to_f / (sorted_atrs.size - 1)
                              else
                                0.5
                              end

      # Determine volatility level
      level = case volatility_percentile
              when 0.0...0.3
                :low
              when 0.3...0.7
                :medium
              else
                :high
              end

      {
        level: level,
        atr_value: atr_value,
        volatility_percentile: volatility_percentile
      }
    end

    private

    def closes = @candles['close'].map(&:to_f)
    def highs  = @candles['high'].map(&:to_f)
    def lows   = @candles['low'].map(&:to_f)
    def stamps = @candles['timestamp'] || []

    def ohlc_rows
      @ohlc_rows ||= highs.each_index.map do |i|
        {
          date_time: Time.zone.at(stamps[i] || 0),
          high: highs[i],
          low: lows[i],
          close: closes[i]
        }
      end
    end

    # — ruby-technical-analysis —
    def sma(len) = closes.last(len).sum / len.to_f
    def ema(len) = RTA::MovingAverages.new(series: closes, period: len).ema
    def rsi(len) = RTA::RelativeStrengthIndex.new(series: closes, period: len).call

    def macd_hash
      m, s, h = RTA::Macd.new(series: closes,
                              fast_period: @cfg[:macd_f],
                              slow_period: @cfg[:macd_s],
                              signal_period: @cfg[:macd_sig]).call
      { macd: m, signal: s, hist: h }
    end

    # — technical_analysis gem —
    def atr(len)
      TA::Atr.calculate(ohlc_rows.last(len * 2), period: len).first.atr
    end

    def adx(len)
      TA::Adx.calculate(ohlc_rows.last(len * 2), period: len).first.adx
    end
  end
end


# File: app/services/indicators/supertrend.rb
# frozen_string_literal: true

module Indicators
  # Adaptive Supertrend indicator with volatility-aware optimisation.
  # Dynamically adjusts the ATR multiplier using a lightweight clustering approach.
  class Supertrend < ApplicationService
    DEFAULT_MULTIPLIER_CANDIDATES = [1.5, 2.0, 2.5, 3.0, 3.5].freeze
    MAX_KMEANS_ITERATIONS = 20

    attr_reader :series, :period, :base_multiplier, :training_period, :num_clusters,
                :performance_alpha, :multiplier_candidates, :performance_scores,
                :adaptive_multipliers, :atr_values

    def initialize(series:, period: 10, base_multiplier: 2.0, training_period: 50,
                   num_clusters: 3, performance_alpha: 0.1, multiplier_candidates: DEFAULT_MULTIPLIER_CANDIDATES)
      @series = series
      @period = period
      @base_multiplier = base_multiplier.to_f
      @training_period = training_period
      @num_clusters = [num_clusters.to_i, 1].max
      @performance_alpha = performance_alpha.to_f
      @multiplier_candidates = Array(multiplier_candidates).map(&:to_f)
      @performance_scores = Hash.new(0.0)
      # Initialize with size from candles or 0 if not available yet
      candles_size = series.respond_to?(:candles) ? (series.candles&.size || 0) : 0
      @adaptive_multipliers = Array.new(candles_size, @base_multiplier)
      @atr_values = []
    end

    def call
      # Handle both CandleSeries objects and objects with candles array
      if series.respond_to?(:highs) && series.respond_to?(:lows) && series.respond_to?(:closes)
        highs = series.highs
        lows = series.lows
        closes = series.closes
      elsif series.respond_to?(:candles)
        # Extract from candles array
        candles = series.candles
        return default_result if candles.nil? || candles.empty?

        highs = candles.map(&:high)
        lows = candles.map(&:low)
        closes = candles.map(&:close)
      else
        return default_result
      end

      return default_result if highs.nil? || lows.nil? || closes.nil?
      return default_result if highs.empty? || lows.empty? || closes.empty?

      minimum_required = [training_period, period + 1].max
      return default_result if closes.size < minimum_required

      @atr_values = calculate_adaptive_atr(highs, lows, closes)
      optimize_multipliers_with_clustering(closes, atr_values)
      supertrend_line = calculate_adaptive_supertrend(highs, lows, closes, atr_values, adaptive_multipliers)

      last_index = last_valid_index(supertrend_line)
      trend = determine_trend(supertrend_line, closes, last_index)

      {
        line: supertrend_line,
        values: supertrend_line.compact,
        trend: trend,
        last_value: last_index ? supertrend_line[last_index] : nil,
        atr: atr_values,
        adaptive_multipliers: adaptive_multipliers
      }
    end

    # Expose the latest volatility regime for external diagnostics.
    def get_current_volatility_regime(index)
      return :unknown if index.nil? || index < training_period

      multiplier = adaptive_multipliers[index] || base_multiplier

      case multiplier
      when 0...base_multiplier
        :low
      when base_multiplier...(base_multiplier + 0.75)
        :medium
      else
        :high
      end
    end

    def get_performance_metrics
      {
        multiplier_scores: performance_scores.dup,
        total_clusters: num_clusters,
        training_period: training_period
      }
    end

    def get_adaptive_multiplier(index)
      adaptive_multipliers[index] || base_multiplier
    end

    private

    def default_result
      {
        line: [],
        values: [],
        trend: nil,
        last_value: nil,
        atr: [],
        adaptive_multipliers: []
      }
    end

    def calculate_adaptive_atr(highs, lows, closes)
      size = closes.size
      true_ranges = Array.new(size)

      size.times do |i|
        high = highs[i]
        low = lows[i]
        next if high.nil? || low.nil?

        if i.zero?
          true_ranges[i] = high - low
          next
        end

        prev_close = closes[i - 1]
        next if prev_close.nil?

        candidates = [
          high - low,
          (high - prev_close).abs,
          (low - prev_close).abs
        ].compact

        true_ranges[i] = candidates.max
      end

      atr = Array.new(size)

      size.times do |i|
        next if true_ranges[i].nil?

        if i == period
          window_start = [1, i - period + 1].max
          window = true_ranges[window_start..i].compact
          atr[i] = window.any? ? window.sum / window.size.to_f : nil
          next
        end

        next unless i > period

        prev_atr = atr[i - 1]
        range = true_ranges[i]
        next if prev_atr.nil? || range.nil?

        volatility_factor = calculate_volatility_factor(closes, i)
        adaptive_alpha = [0.05, 0.2 / (1.0 + volatility_factor)].max
        atr[i] = (adaptive_alpha * range) + ((1.0 - adaptive_alpha) * prev_atr)
      end

      atr
    end

    def calculate_volatility_factor(closes, index)
      return 1.0 if index < 20 || index >= closes.size

      recent_window = closes[(index - 19)..index]
      historical_window = closes[[index - 100, 0].max..index]

      recent_returns = returns_for_window(recent_window)
      historical_returns = returns_for_window(historical_window)

      recent_vol = volatility_from_returns(recent_returns)
      historical_vol = volatility_from_returns(historical_returns)

      return 1.0 if historical_vol.zero?

      recent_vol / (historical_vol + 1e-8)
    end

    def returns_for_window(window)
      return [] if window.nil? || window.size < 2

      window.each_cons(2).filter_map do |a, b|
        next if a.to_f.zero?

        (b - a) / a.to_f
      end
    end

    def volatility_from_returns(returns)
      return 0.0 if returns.empty?

      sum_sq = returns.sum { |r| r * r }
      Math.sqrt(sum_sq / returns.size.to_f)
    end

    def optimize_multipliers_with_clustering(closes, atr)
      size = closes.size
      return adaptive_multipliers if size <= training_period

      (training_period...size).each do |i|
        features = extract_volatility_features(closes, atr, i)
        next if features.empty?

        cluster_assignment = perform_kmeans_clustering(features)
        optimal_multiplier = select_optimal_multiplier(cluster_assignment)

        adaptive_multipliers[i] = optimal_multiplier
        update_performance_scores(i, closes, atr, optimal_multiplier)
      end

      backfill_adaptive_multipliers
    end

    def extract_volatility_features(closes, atr, current_index)
      return [] if current_index < period + 10

      lookback_start = [current_index - training_period, period].max
      features = []

      (lookback_start...current_index).each do |i|
        next if atr[i].nil?

        atr_window = atr[lookback_start...current_index].compact
        avg_atr = atr_window.any? ? atr_window.sum / atr_window.size.to_f : atr[i]
        normalized_atr = avg_atr&.zero? ? 1.0 : atr[i] / (avg_atr + 1e-8)

        volatility = if i >= 10
                       recent_prices = closes[(i - 9)..i]
                       returns = returns_for_window(recent_prices)
                       volatility_from_returns(returns)
                     else
                       0.0
                     end

        ma_period = [10, i + 1].min
        ma_start = [i - ma_period + 1, 0].max
        ma_prices = closes[ma_start..i] || []
        moving_avg = ma_prices.any? ? ma_prices.sum / ma_prices.size.to_f : closes[i].to_f
        trend_strength = moving_avg.zero? ? 0.0 : (closes[i] - moving_avg) / moving_avg

        features << [normalized_atr.to_f, volatility * 100.0, trend_strength * 100.0]
      end

      features
    end

    def perform_kmeans_clustering(features)
      k = [num_clusters, features.size].min
      return 0 if k <= 1

      centroids = features.sample(k)
      assignments = []

      MAX_KMEANS_ITERATIONS.times do
        assignments = features.map do |point|
          distances = centroids.map { |centroid| euclidean_distance(point, centroid) }
          distances.index(distances.min) || 0
        end

        new_centroids = []
        k.times do |cluster|
          cluster_points = features.each_with_index.filter_map { |point, idx| point if assignments[idx] == cluster }
          if cluster_points.empty?
            new_centroids << centroids[cluster]
          else
            dims = cluster_points.first.size
            mean = Array.new(dims) do |dim|
              cluster_points.sum { |point| point[dim] } / cluster_points.size.to_f
            end
            new_centroids << mean
          end
        end

        break if converged?(centroids, new_centroids)

        centroids = new_centroids
      end

      assignments.last || 0
    end

    def converged?(centroids, new_centroids)
      centroids.zip(new_centroids).all? do |old_centroid, new_centroid|
        euclidean_distance(old_centroid, new_centroid) < 0.001
      end
    end

    def euclidean_distance(point1, point2)
      return Float::INFINITY if point1.nil? || point2.nil?

      sum = 0.0
      point1.each_index do |idx|
        sum += (point1[idx] - point2[idx])**2
      end
      Math.sqrt(sum)
    end

    def select_optimal_multiplier(cluster_assignment)
      candidates = case cluster_assignment
                   when 0
                     multiplier_candidates.select { |mult| mult <= base_multiplier + 0.5 }
                   when 1
                     multiplier_candidates.select { |mult| mult.between?(base_multiplier, base_multiplier + 1.0) }
                   when 2
                     multiplier_candidates.select { |mult| mult >= base_multiplier + 0.5 }
                   else
                     []
                   end

      candidates = multiplier_candidates if candidates.empty?
      candidates.max_by { |mult| performance_scores[mult] }
    end

    def update_performance_scores(current_index, closes, atr, used_multiplier)
      return if current_index < period + 5
      return if current_index + 1 >= closes.size

      highs = series.highs
      lows = series.lows

      lookback = 5
      start_idx = [current_index - lookback, period].max
      correct_signals = 0
      total_signals = 0

      (start_idx...current_index).each do |i|
        next if atr[i].nil?

        mid = average_price(highs[i], lows[i])
        next if mid.nil?

        upper_band = mid + (used_multiplier * atr[i])
        lower_band = mid - (used_multiplier * atr[i])

        current_close = closes[i]
        next_close = closes[i + 1]
        next if current_close.nil? || next_close.nil?

        if current_close > upper_band && next_close > current_close
          correct_signals += 1
        elsif current_close < lower_band && next_close < current_close
          correct_signals += 1
        end

        total_signals += 1
      end

      return if total_signals.zero?

      accuracy = correct_signals.to_f / total_signals
      performance_scores[used_multiplier] =
        ((1 - performance_alpha) * performance_scores[used_multiplier]) +
        (performance_alpha * accuracy)
    end

    def calculate_adaptive_supertrend(highs, lows, closes, atr, multipliers)
      size = closes.size
      upperband = Array.new(size)
      lowerband = Array.new(size)
      supertrend = Array.new(size)

      size.times do |i|
        next if atr[i].nil? || multipliers[i].nil?

        mid = average_price(highs[i], lows[i])
        next if mid.nil?

        multiplier = multipliers[i]
        upperband[i] = mid + (multiplier * atr[i])
        lowerband[i] = mid - (multiplier * atr[i])
      end

      size.times do |i|
        next if atr[i].nil? || upperband[i].nil? || lowerband[i].nil?

        if i <= period
          supertrend[i] = closes[i] && closes[i] <= upperband[i] ? upperband[i] : lowerband[i]
          next
        end

        prev_supertrend = supertrend[i - 1]
        prev_upper = upperband[i - 1]
        prev_lower = lowerband[i - 1]

        if prev_supertrend.nil? || prev_upper.nil? || prev_lower.nil?
          supertrend[i] = closes[i] && closes[i] <= upperband[i] ? upperband[i] : lowerband[i]
          next
        end

        supertrend[i] = if prev_supertrend == prev_upper
                          if closes[i] && closes[i] <= upperband[i]
                            [upperband[i], prev_supertrend].compact.min
                          else
                            lowerband[i]
                          end
                        elsif closes[i] && closes[i] >= lowerband[i]
                          [lowerband[i], prev_supertrend].compact.max
                        else
                          upperband[i]
                        end
      end

      supertrend
    end

    def determine_trend(supertrend, closes, last_index)
      return nil if last_index.nil?

      last_close = closes[last_index]
      last_line = supertrend[last_index]
      return nil if last_close.nil? || last_line.nil?

      last_close >= last_line ? :bullish : :bearish
    end

    def last_valid_index(values)
      (values.size - 1).downto(0) do |i|
        return i unless values[i].nil?
      end
      nil
    end

    def average_price(high, low)
      return nil if high.nil? || low.nil?

      (high + low) / 2.0
    end

    def backfill_adaptive_multipliers
      last_value = base_multiplier
      adaptive_multipliers.each_index do |i|
        if adaptive_multipliers[i].nil?
          adaptive_multipliers[i] = last_value
        else
          last_value = adaptive_multipliers[i]
        end
      end
      adaptive_multipliers
    end
  end
end


# File: app/services/instruments_importer.rb
# app/services/instruments_importer.rb
# frozen_string_literal: true

require 'csv'
require 'open-uri'

class InstrumentsImporter
  CSV_URL         = 'https://images.dhan.co/api-data/api-scrip-master-detailed.csv'
  CACHE_PATH      = Rails.root.join('tmp/dhan_scrip_master.csv') # ← NEW
  CACHE_MAX_AGE   = 24.hours # ← NEW
  VALID_EXCHANGES = %w[NSE BSE].freeze
  BATCH_SIZE      = 1_000

  class << self
    # ------------------------------------------------------------
    # Public entry point
    # ------------------------------------------------------------
    def import_from_url
      started_at = Time.current
      csv_text   = fetch_csv_with_cache # ← NEW (was: URI.open(CSV_URL).read)
      summary    = import_from_csv(csv_text)

      finished_at = Time.current
      summary[:started_at]  = started_at
      summary[:finished_at] = finished_at
      summary[:duration]    = finished_at - started_at

      record_success!(summary)
      summary
    end

    # ------------------------------------------------------------
    # Fetch CSV with 24-hour cache
    # ------------------------------------------------------------
    # ← NEW helper
    def fetch_csv_with_cache
      if CACHE_PATH.exist? && Time.current - CACHE_PATH.mtime < CACHE_MAX_AGE
        # Rails.logger.info "Using cached CSV (#{CACHE_PATH})"
        return CACHE_PATH.read
      end

      # Rails.logger.info 'Downloading fresh CSV from Dhan…'
      csv_text = URI.open(CSV_URL, &:read) # rubocop:disable Security/Open

      CACHE_PATH.dirname.mkpath
      File.write(CACHE_PATH, csv_text)
      # Rails.logger.info "Saved CSV to #{CACHE_PATH}"

      csv_text
    rescue StandardError => e
      # Rails.logger.warn "CSV download failed: #{e.message}"
      raise e if CACHE_PATH.exist? == false # don’t swallow if no fallback

      # Rails.logger.warn 'Falling back to cached CSV (may be stale)'
      CACHE_PATH.read
    end
    private :fetch_csv_with_cache # keep helper private

    def import_from_csv(csv_content)
      instruments_rows, derivatives_rows = build_batches(csv_content)
      # Rails.logger.debug do
      #   "instrument rows: #{instruments_rows.size}; derivative rows: #{derivatives_rows.size}"
      # end
      # instruments_rows.uniq!  { |r| r.values_at(:security_id, :symbol_name, :exchange, :segment) }
      # derivatives_rows.uniq!  { |r| r.values_at(:security_id, :symbol_name, :exchange, :segment) }

      instrument_import = instruments_rows.empty? ? nil : import_instruments!(instruments_rows)
      derivative_import = derivatives_rows.empty? ? nil : import_derivatives!(derivatives_rows)

      {
        instrument_rows: instruments_rows.size,
        derivative_rows: derivatives_rows.size,
        instrument_upserts: instrument_import&.ids&.size.to_i,
        derivative_upserts: derivative_import&.ids&.size.to_i,
        instrument_total: Instrument.count,
        derivative_total: Derivative.count
      }
    end

    private

    # ------------------------------------------------------------
    # 1. Split CSV rows
    # ------------------------------------------------------------
    def build_batches(csv_content)
      instruments = []
      derivatives = []

      CSV.parse(csv_content, headers: true).each do |row|
        next unless VALID_EXCHANGES.include?(row['EXCH_ID'])

        attrs = build_attrs(row)

        if row['SEGMENT'] == 'D'   # Derivative
          derivatives << attrs.slice(*Derivative.column_names.map(&:to_sym))
        else                       # Cash / Index
          instruments << attrs.slice(*Instrument.column_names.map(&:to_sym))
        end
      end

      [instruments, derivatives]
    end

    def build_attrs(row)
      now = Time.zone.now
      {
        security_id: row['SECURITY_ID'],
        exchange: row['EXCH_ID'],
        segment: row['SEGMENT'],
        isin: row['ISIN'],
        instrument_code: row['INSTRUMENT'],
        underlying_security_id: row['UNDERLYING_SECURITY_ID'],
        underlying_symbol: row['UNDERLYING_SYMBOL'],
        symbol_name: row['SYMBOL_NAME'],
        display_name: row['DISPLAY_NAME'],
        instrument_type: row['INSTRUMENT_TYPE'],
        series: row['SERIES'],
        lot_size: row['LOT_SIZE']&.to_i,
        expiry_date: safe_date(row['SM_EXPIRY_DATE']),
        strike_price: row['STRIKE_PRICE']&.to_f,
        option_type: row['OPTION_TYPE'],
        tick_size: row['TICK_SIZE']&.to_f,
        expiry_flag: row['EXPIRY_FLAG'],
        bracket_flag: row['BRACKET_FLAG'],
        cover_flag: row['COVER_FLAG'],
        asm_gsm_flag: row['ASM_GSM_FLAG'],
        asm_gsm_category: row['ASM_GSM_CATEGORY'],
        buy_sell_indicator: row['BUY_SELL_INDICATOR'],
        buy_co_min_margin_per: row['BUY_CO_MIN_MARGIN_PER']&.to_f,
        sell_co_min_margin_per: row['SELL_CO_MIN_MARGIN_PER']&.to_f,
        buy_co_sl_range_max_perc: row['BUY_CO_SL_RANGE_MAX_PERC']&.to_f,
        sell_co_sl_range_max_perc: row['SELL_CO_SL_RANGE_MAX_PERC']&.to_f,
        buy_co_sl_range_min_perc: row['BUY_CO_SL_RANGE_MIN_PERC']&.to_f,
        sell_co_sl_range_min_perc: row['SELL_CO_SL_RANGE_MIN_PERC']&.to_f,
        buy_bo_min_margin_per: row['BUY_BO_MIN_MARGIN_PER']&.to_f,
        sell_bo_min_margin_per: row['SELL_BO_MIN_MARGIN_PER']&.to_f,
        buy_bo_sl_range_max_perc: row['BUY_BO_SL_RANGE_MAX_PERC']&.to_f,
        sell_bo_sl_range_max_perc: row['SELL_BO_SL_RANGE_MAX_PERC']&.to_f,
        buy_bo_sl_range_min_perc: row['BUY_BO_SL_RANGE_MIN_PERC']&.to_f,
        sell_bo_sl_min_range: row['SELL_BO_SL_MIN_RANGE']&.to_f,
        buy_bo_profit_range_max_perc: row['BUY_BO_PROFIT_RANGE_MAX_PERC']&.to_f,
        sell_bo_profit_range_max_perc: row['SELL_BO_PROFIT_RANGE_MAX_PERC']&.to_f,
        buy_bo_profit_range_min_perc: row['BUY_BO_PROFIT_RANGE_MIN_PERC']&.to_f,
        sell_bo_profit_range_min_perc: row['SELL_BO_PROFIT_RANGE_MIN_PERC']&.to_f,
        mtf_leverage: row['MTF_LEVERAGE']&.to_f,
        created_at: now,
        updated_at: now
      }
    end

    # ------------------------------------------------------------
    # 3. Upsert instruments
    # ------------------------------------------------------------
    def import_instruments!(rows)
      Instrument.import(
        rows,
        batch_size: BATCH_SIZE,
        on_duplicate_key_update: {
          conflict_target: %i[security_id symbol_name exchange segment],
          columns: %i[
            display_name isin instrument_code instrument_type
            underlying_symbol lot_size tick_size updated_at
          ]
        }
      ).tap do |res|
        # Rails.logger.info "Upserted Instruments: #{res.ids.size}"
      end
    end

    # ------------------------------------------------------------
    # 4. Upsert derivatives
    # ------------------------------------------------------------
    def import_derivatives!(rows)
      with_parent, without_parent = attach_instrument_ids(rows)

      # Rails.logger.info "Derivatives w/ parent: #{with_parent.size}"
      # Rails.logger.info "Derivatives w/o parent: #{without_parent.size}"

      return if with_parent.empty?

      Derivative.import(
        with_parent,
        batch_size: BATCH_SIZE,
        on_duplicate_key_update: {
          conflict_target: %i[security_id symbol_name exchange segment],
          columns: %i[
            symbol_name display_name isin instrument_code instrument_type
            underlying_symbol series lot_size tick_size updated_at
          ]
        }
      ).tap do |res|
        # Rails.logger.info "Upserted Derivatives: #{res.ids.size}"
      end
    end

    # ------------------------------------------------------------
    # 4a. Attach instrument_id to each derivative row
    # ------------------------------------------------------------
    def attach_instrument_ids(rows)
      enum_to_csv = Instrument.instrument_codes

      # 🔑 lookup key = [csv_code, UNDERLYING_SYMBOL]
      lookup = Instrument.pluck(
        :id, :instrument_code, :underlying_symbol, :exchange, :segment
      ).each_with_object({}) do |(id, enum_code, sym, _exch, _seg), h|
        next if sym.blank?

        csv_code = enum_to_csv[enum_code] || enum_code # keep CSV code itself
        key      = [csv_code, sym.upcase]
        h[key]   = id
      end

      # Rails.logger.debug { "lookup size: #{lookup.size}" }

      with_parent    = []
      without_parent = []
      count = 0
      rows.each do |h|
        count += 1 if h[:underlying_symbol]
        next without_parent << h if h[:underlying_symbol].blank?

        parent_code = InstrumentTypeMapping.underlying_for(h[:instrument_code]) # FUTIDX ➜ INDEX
        key         = [parent_code, h[:underlying_symbol].upcase]

        if (pid = lookup[key])
          h[:instrument_id] = pid
          with_parent << h
        else
          without_parent << h
        end
      end

      [with_parent, without_parent]
    end

    # ------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------
    def safe_date(str)
      Date.parse(str)
    rescue StandardError
      nil
    end

    def map_segment(char)
      { 'I' => 'index', 'E' => 'equity', 'C' => 'currency',
        'D' => 'derivatives', 'M' => 'commodity' }[char] || char.downcase
    end

    def record_success!(summary)
      Setting.put('instruments.last_imported_at', summary[:finished_at].iso8601)
      Setting.put('instruments.last_import_duration_sec', summary[:duration].to_f.round(2))
      Setting.put('instruments.last_instrument_rows', summary[:instrument_rows])
      Setting.put('instruments.last_derivative_rows', summary[:derivative_rows])
      Setting.put('instruments.last_instrument_upserts', summary[:instrument_upserts])
      Setting.put('instruments.last_derivative_upserts', summary[:derivative_upserts])
      Setting.put('instruments.instrument_total', summary[:instrument_total])
      Setting.put('instruments.derivative_total', summary[:derivative_total])
    end
  end
end


# File: app/services/live/exit_engine.rb
# frozen_string_literal: true

module Live
  class ExitEngine
    def initialize(order_router:)
      @router = order_router
      @running = false
      @thread = nil
      @lock = Mutex.new
      @risk_manager = Live::RiskManagerService.new(exit_engine: self)
    end

    # ExitEngine DOES NOT call risk logic.
    # It only exists to process exit requests when invoked by RiskManagerService.
    def start
      @lock.synchronize do
        return if @running

        @running = true

        @thread = Thread.new do
          Thread.current.name = 'exit-engine'
          loop do
            break unless @running

            # begin
            #   # Let RiskManager fetch positions itself. Pass the engine via keyword.
            #   @risk_manager.enforce_hard_limits(exit_engine: self)
            #   @risk_manager.enforce_trailing_stops(exit_engine: self)
            #   @risk_manager.enforce_time_based_exit(exit_engine: self)
            # rescue StandardError => e
            #   Rails.logger.error("[ExitEngine] crash: #{e.class} - #{e.message}\n#{e.backtrace.first(6).join("\n")}")
            # end
            # sleep 1
            sleep 0.5
          end
        end
      end
    end

    def stop
      @lock.synchronize do
        return unless @running

        @running = false
      end

      @thread&.kill
      @thread&.join(1)
    end

    # Called by RiskManagerService when it delegates the exit to the engine.
    # ExitEngine is authoritative for placing router exit orders, then marking trackers exited.
    # Primary method called by RiskManagerService
    def execute_exit(tracker, reason)
      ltp = safe_ltp(tracker)

      result = @router.exit_market(tracker)
      success = (result == true) ||
                (result.is_a?(Hash) && result[:success] == true)

      if success
        tracker.mark_exited!(
          exit_price: ltp,
          exit_reason: reason
        )
        Rails.logger.info("[ExitEngine] Exit executed #{tracker.order_no}: #{reason}")
      else
        Rails.logger.error("[ExitEngine] Router failed for #{tracker.order_no}: #{result.inspect}")
      end
    rescue StandardError => e
      Rails.logger.error("[ExitEngine] Failed executing exit for #{tracker.order_no}: #{e.class} - #{e.message}")
      raise
    end

    private

    # get LTP from cache or fallback
    def safe_ltp(tracker)
      if Live::TickCache.respond_to?(:ltp)
        Live::TickCache.ltp(tracker.segment, tracker.security_id)
      elsif Live::TickCache.respond_to?(:instance)
        Live::TickCache.ltp(tracker.segment, tracker.security_id)
      end
    rescue StandardError
      nil
    end
  end
end


# File: app/services/live/feed_health_service.rb
# frozen_string_literal: true

require 'singleton'

module Live
  # Centralised guard for DhanHQ data feeds.
  # Tracks last successful refresh per feed and blocks trading
  # when required data is stale.
  class FeedHealthService
    include Singleton

    DEFAULT_THRESHOLDS = {
      funds: 60.seconds,
      positions: 30.seconds,
      ticks: 10.seconds
    }.freeze

    FeedStaleError = Class.new(StandardError) do
      attr_reader :feed, :last_seen_at, :threshold, :last_error

      def initialize(feed:, last_seen_at:, threshold:, last_error: nil)
        @feed = feed
        @last_seen_at = last_seen_at
        @threshold = threshold
        @last_error = last_error

        message = "#{feed} feed stale for #{stale_duration(last_seen_at, threshold)}"
        message += "; last error: #{last_error[:error]}" if last_error&.dig(:error)
        super(message)
      end

      private

      def stale_duration(last_seen_at, threshold)
        last_seen_at ? "#{(Time.current - last_seen_at).round(1)}s (> #{threshold}s)" : 'unknown duration'
      end
    end

    def initialize
      @timestamps = {}
      @failures = {}
      @threshold_overrides = {}
      @mutex = Mutex.new
    end

    def mark_success!(feed)
      with_lock do
        @timestamps[feed.to_sym] = Time.current
        @failures.delete(feed.to_sym)
      end
    end

    def mark_failure!(feed, error: nil)
      with_lock do
        @failures[feed.to_sym] = { error: error&.message, at: Time.current }
      end
    end

    def stale?(feed)
      last_seen = with_lock { @timestamps[feed.to_sym] }
      return true unless last_seen

      Time.current - last_seen > threshold_for(feed)
    end

    def assert_healthy!(feeds)
      feeds.each do |feed|
        next unless stale?(feed)

        failure = with_lock { @failures[feed.to_sym] }
        raise FeedStaleError.new(
          feed: feed,
          last_seen_at: with_lock { @timestamps[feed.to_sym] },
          threshold: threshold_for(feed),
          last_error: failure
        )
      end

      true
    end

    def threshold_for(feed)
      with_lock { threshold_value(feed) }
    end

    def configure_threshold(feed, seconds)
      with_lock do
        @threshold_overrides[feed.to_sym] = seconds
      end
    end

    def status
      feeds = DEFAULT_THRESHOLDS.keys | with_lock { (@timestamps.keys + @threshold_overrides.keys + @failures.keys) }

      feeds.each_with_object({}) do |feed, memo|
        last_seen = with_lock { @timestamps[feed.to_sym] }
        memo[feed] = {
          last_seen_at: last_seen,
          threshold: threshold_for(feed),
          stale: last_seen ? (Time.current - last_seen > threshold_for(feed)) : true,
          last_error: with_lock { @failures[feed.to_sym] }
        }
      end
    end

    private

    def with_lock(&)
      @mutex.synchronize(&)
    end

    def threshold_value(feed)
      @threshold_overrides.fetch(feed.to_sym) { DEFAULT_THRESHOLDS.fetch(feed.to_sym, 30.seconds) }
    end
  end
end


# File: app/services/live/feed_listener.rb
# frozen_string_literal: true

require 'concurrent/executor'
require 'concurrent/array'

module Live
  # Enhanced feed listener for NEMESIS V3 architecture
  # Processes ticks from MarketFeedHub and emits structured events via EventBus
  # Multi-threaded tick processing with composite key support
  # rubocop:disable Metrics/ClassLength
  class FeedListener
    include Singleton

    def initialize
      @running = false
      @lock = Mutex.new
      @thread_pool = nil
      @event_bus = Core::EventBus.instance
      @tick_cache = Live::TickCache
      @redis_cache = Live::RedisTickCache.instance
      @stats = {
        ticks_processed: 0,
        events_emitted: 0,
        errors: 0
      }
    end

    # Start the feed listener
    # Subscribes to MarketFeedHub and begins processing ticks
    # @return [Boolean] True if started successfully
    def start!
      return false if @running

      @lock.synchronize do
        return false if @running

        # Create thread pool for async processing
        @thread_pool = Concurrent::FixedThreadPool.new(
          thread_count,
          name: 'feed-listener',
          max_queue: 1000
        )

        # Subscribe to MarketFeedHub (non-blocking - hub may not be running yet)
        hub = MarketFeedHub.instance
        hub.on_tick { |tick| process_tick(tick) }

        @running = true
        Rails.logger.info('[Live::FeedListener] Started feed listener')
        true
      end
    rescue StandardError => e
      Rails.logger.error("[Live::FeedListener] Failed to start: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
      false
    end

    # Stop the feed listener
    # @return [Boolean] True if stopped successfully
    def stop!
      return false unless @running

      @lock.synchronize do
        return false unless @running

        @running = false
        @thread_pool&.shutdown
        @thread_pool&.wait_for_termination(5)
        @thread_pool = nil

        Rails.logger.info('[Live::FeedListener] Stopped feed listener')
        true
      end
    rescue StandardError => e
      Rails.logger.error("[Live::FeedListener] Error during stop: #{e.class} - #{e.message}")
      false
    end

    # Check if listener is running
    # @return [Boolean]
    def running?
      @running
    end

    # Get statistics
    # @return [Hash]
    def stats
      @stats.dup
    end

    private

    # Process a single tick
    # @param tick [Hash] Raw tick data from MarketFeedHub
    def process_tick(tick)
      return unless tick.is_a?(Hash)
      return unless tick[:ltp].to_f.positive?
      return unless tick[:segment].present? && tick[:security_id].present?

      # Process asynchronously in thread pool
      @thread_pool&.post do
        process_tick_sync(tick)
      end
    rescue StandardError => e
      @stats[:errors] += 1
      Rails.logger.error("[Live::FeedListener] Error processing tick: #{e.class} - #{e.message}")
    end

    # Synchronous tick processing (runs in thread pool)
    # @param tick [Hash] Raw tick data
    def process_tick_sync(tick)
      @stats[:ticks_processed] += 1

      # Build LtpEvent with enriched data
      event = build_ltp_event(tick)
      return unless event.valid?

      # Emit event via EventBus
      @event_bus.publish(Core::EventBus::EVENTS[:ltp], event)
      @stats[:events_emitted] += 1
    rescue StandardError => e
      @stats[:errors] += 1
      Rails.logger.error("[Live::FeedListener] Error in process_tick_sync: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
    end

    # Build LtpEvent from raw tick data
    # Enriches tick with additional context (spot price, volatility state)
    # @param tick [Hash] Raw tick data
    # @return [LtpEvent]
    # rubocop:disable Metrics/AbcSize
    def build_ltp_event(tick)
      segment = tick[:segment].to_s
      security_id = tick[:security_id].to_s

      # Get enriched tick data from cache
      cached_tick = @tick_cache.fetch(segment, security_id) ||
                    @redis_cache.fetch_tick(segment, security_id)

      # Merge cached data with incoming tick
      enriched = (cached_tick || {}).merge(tick)

      # Determine spot price (for index instruments)
      spot_price = determine_spot_price(segment, security_id, enriched)

      # Determine volatility state
      volatility_state = determine_volatility_state(enriched)

      LtpEvent.new(
        segment: segment,
        security_id: security_id,
        ltp: enriched[:ltp] || tick[:ltp],
        timestamp: enriched[:timestamp] || Time.current,
        spot_price: spot_price,
        volatility_state: volatility_state,
        bid: enriched[:bid] || tick[:bid],
        ask: enriched[:ask] || tick[:ask],
        oi: enriched[:oi] || tick[:oi],
        oi_change: enriched[:oi_change] || tick[:oi_change],
        volume: enriched[:volume] || tick[:volume],
        high: enriched[:high] || tick[:high],
        low: enriched[:low] || tick[:low],
        open: enriched[:open] || tick[:open],
        close: enriched[:close] || tick[:close]
      )
    end
    # rubocop:enable Metrics/AbcSize

    # Determine spot price for index instruments
    # @param segment [String] Exchange segment
    # @param _security_id [String] Security ID (unused for now)
    # @param tick [Hash] Tick data
    # @return [Float, nil]
    def determine_spot_price(segment, _security_id, tick)
      # If this is an index segment, use LTP as spot
      return tick[:ltp].to_f if segment == 'IDX_I'

      # For derivatives, try to get underlying spot
      # This would require looking up the derivative's underlying
      # For now, return nil (can be enhanced later)
      nil
    end

    # Determine volatility state from tick data
    # @param tick [Hash] Tick data
    # @return [Symbol] :low, :normal, :high, or :extreme
    def determine_volatility_state(tick)
      # Simple heuristic based on price change
      # Can be enhanced with ATR, IV, etc.
      return :normal unless tick[:close]&.positive?

      change_pct = ((tick[:ltp].to_f - tick[:close].to_f) / tick[:close].to_f * 100.0).abs

      case change_pct
      when 0.0..0.5 then :low
      when 0.5..2.0 then :normal
      when 2.0..5.0 then :high
      else :extreme
      end
    end

    # Thread pool size
    # @return [Integer]
    def thread_count
      ENV.fetch('FEED_LISTENER_THREADS', '4').to_i
    end
  end
  # rubocop:enable Metrics/ClassLength
end


# File: app/services/live/gateway.rb
# frozen_string_literal: true

# Live Gateway wraps Orders::Placer to provide Orders::Gateway interface
# for live trading via DhanHQ
module Live
  class Gateway < Orders::Gateway
    def place_market(side:, segment:, security_id:, qty:, meta: {})
      case side.to_s.downcase
      when 'buy'
        Orders::Placer.buy_market!(
          seg: segment,
          sid: security_id,
          qty: qty,
          client_order_id: meta[:client_order_id] || generate_client_order_id(segment, security_id, side),
          product_type: meta[:product_type] || 'INTRADAY'
        )
      when 'sell'
        Orders::Placer.sell_market!(
          seg: segment,
          sid: security_id,
          qty: qty,
          client_order_id: meta[:client_order_id] || generate_client_order_id(segment, security_id, side)
        )
      else
        # Rails.logger.error("[Live::Gateway] Invalid side: #{side}")
        nil
      end
    end

    def flat_position(segment:, security_id:)
      Orders::Placer.exit_position!(
        seg: segment,
        sid: security_id,
        client_order_id: generate_client_order_id(segment, security_id, 'exit')
      )
    end

    def position(segment:, security_id:)
      # Fetch from DhanHQ Position API
      positions = DhanHQ::Models::Position.active
      pos = positions.find { |p| p.security_id.to_s == security_id.to_s && p.exchange_segment == segment }

      return nil unless pos

      ltp = TickCache.instance.ltp(segment, security_id.to_s)
      entry_price = BigDecimal(pos.buy_avg.to_s) if pos.buy_avg
      qty = pos.net_qty.to_i

      upnl = if entry_price && ltp && qty != 0
               (BigDecimal(ltp.to_s) - entry_price) * qty
             else
               BigDecimal(0)
             end

      {
        qty: qty,
        avg_price: entry_price || BigDecimal(0),
        upnl: upnl,
        rpnl: BigDecimal(0), # Realized PnL not directly available from Position API
        last_ltp: ltp ? BigDecimal(ltp.to_s) : (entry_price || BigDecimal(0))
      }
    rescue StandardError => e
      # Rails.logger.error("[Live::Gateway] position failed: #{e.message}")
      nil
    end

    def wallet_snapshot
      # Fetch from DhanHQ Funds API
      funds = DhanHQ::Models::Funds.fetch
      return default_wallet unless funds

      {
        cash: BigDecimal(funds.available.to_s || '0'),
        equity: BigDecimal(funds.available.to_s || '0'), # Simplified
        mtm: BigDecimal(0), # Not directly available
        exposure: BigDecimal(0) # Would need to calculate from positions
      }
    rescue StandardError => e
      # Rails.logger.error("[Live::Gateway] wallet_snapshot failed: #{e.message}")
      default_wallet
    end

    private

    def generate_client_order_id(segment, security_id, side)
      timestamp = Time.current.to_i.to_s[-6..]
      "AS-#{side.upcase[0..2]}-#{security_id}-#{timestamp}"
    end

    def default_wallet
      {
        cash: BigDecimal(0),
        equity: BigDecimal(0),
        mtm: BigDecimal(0),
        exposure: BigDecimal(0)
      }
    end
  end
end


# File: app/services/live/ltp_event.rb
# frozen_string_literal: true

module Live
  # LTP (Last Traded Price) event data structure
  # Carries tick data with additional context for NEMESIS V3 system
  # rubocop:disable Metrics/AbcSize
  class LtpEvent
    attr_reader :segment, :security_id, :ltp, :timestamp, :spot_price, :volatility_state,
                :bid, :ask, :oi, :oi_change, :volume, :high, :low, :open, :close

    def initialize(segment:, security_id:, ltp:, timestamp: nil, **options) # rubocop:disable Metrics/AbcSize
      @segment = segment.to_s
      @security_id = security_id.to_s
      @ltp = ltp.to_f
      @timestamp = timestamp || Time.current

      # Optional fields
      @spot_price = options[:spot_price]&.to_f
      @volatility_state = options[:volatility_state] || :normal # :low, :normal, :high, :extreme
      @bid = options[:bid]&.to_f
      @ask = options[:ask]&.to_f
      @oi = options[:oi]&.to_i
      @oi_change = options[:oi_change]&.to_i
      @volume = options[:volume]&.to_i
      @high = options[:high]&.to_f
      @low = options[:low]&.to_f
      @open = options[:open]&.to_f
      @close = options[:close]&.to_f
    end

    # Composite key for caching/lookup
    # @return [String] "SEGMENT:SECURITY_ID"
    def composite_key
      "#{@segment}:#{@security_id}"
    end

    # Check if event has valid LTP
    # @return [Boolean]
    def valid?
      @ltp.positive? && @segment.present? && @security_id.present?
    end

    # Convert to hash for serialization
    # @return [Hash]
    def to_h
      {
        segment: @segment,
        security_id: @security_id,
        ltp: @ltp,
        timestamp: @timestamp,
        spot_price: @spot_price,
        volatility_state: @volatility_state,
        bid: @bid,
        ask: @ask,
        oi: @oi,
        oi_change: @oi_change,
        volume: @volume,
        high: @high,
        low: @low,
        open: @open,
        close: @close,
        composite_key: composite_key
      }.compact
    end

    # Convert to hash with string keys (for JSON/Redis)
    # @return [Hash]
    def to_json_hash
      to_h.transform_keys(&:to_s)
    end

    # Spread percentage (bid-ask)
    # @return [Float, nil]
    def spread_pct
      return nil unless @bid && @ask && @bid.positive?

      mid = (@bid + @ask) / 2.0
      return nil if mid <= 0

      ((@ask - @bid) / mid * 100.0).round(4)
    end

    # Price change from previous close
    # @return [Float, nil]
    def price_change_pct
      return nil unless @close&.positive?

      ((@ltp - @close) / @close * 100.0).round(4)
    end
  end
  # rubocop:enable Metrics/AbcSize
end


# File: app/services/live/market_feed_hub.rb
# frozen_string_literal: true

require 'singleton'
require 'concurrent/array'

module Live
  class MarketFeedHub
    include Singleton

    DEFAULT_MODE = :ticker

    def initialize
      @callbacks = Concurrent::Array.new
      @watchlist = nil
      @lock = Mutex.new
      @last_tick_at = nil
      @connection_state = :disconnected
      @last_error = nil
      @started_at = nil
    end

    def start!
      return unless enabled?
      return if running?

      @lock.synchronize do
        return if running?

        @watchlist = load_watchlist || []
        @ws_client = build_client

        # Set up event handlers for connection monitoring
        setup_connection_handlers

        @ws_client.on(:tick) { |tick| handle_tick(tick) }
        @ws_client.start
        subscribe_watchlist
        @running = true
        @started_at = Time.current
        @connection_state = :connecting
        @last_error = nil

        # NOTE: Connection state will be updated to :connected when first tick is received
      end

      # Rails.logger.info("DhanHQ market feed started (mode=#{mode}, watchlist=#{@watchlist.count} instruments).")
      true
    rescue StandardError => e
      Rails.logger.error("Failed to start DhanHQ market feed: #{_e.class} - #{e.message}")
      stop!
      false
    end

    def stop!
      @lock.synchronize do
        @running = false
        @connection_state = :disconnected
        return unless @ws_client

        ws_client = @ws_client
        @ws_client = nil # Clear reference first to prevent new operations

        begin
          # Attempt graceful disconnect
          ws_client.disconnect! if ws_client.respond_to?(:disconnect!)
        rescue StandardError => e
          Rails.logger.warn("[MarketFeedHub] Error during disconnect: #{e.message}") if defined?(Rails.logger)
        end

        # Clear callbacks
        @callbacks.clear
      end
    end

    def running?
      @running
    end

    # Returns true if the WebSocket connection is actually connected (not just started)
    def connected?
      return false unless running?
      return false unless @ws_client

      # Check if client has a connection state method
      if @ws_client.respond_to?(:connected?)
        @ws_client.connected?
      else
        # Fallback: check if we've received ticks recently (within last 30 seconds)
        @last_tick_at && (Time.current - @last_tick_at) < 30.seconds
      end
    rescue StandardError => _e
      # Rails.logger.warn("Error checking WebSocket connection: #{_e.message}")
      false
    end

    # Get connection health status
    def health_status
      {
        running: running?,
        connected: connected?,
        connection_state: @connection_state,
        started_at: @started_at,
        last_tick_at: @last_tick_at,
        ticks_received: @last_tick_at ? true : false,
        last_error: @last_error,
        watchlist_size: @watchlist&.count || 0
      }
    end

    # Diagnostic information for troubleshooting
    def diagnostics
      status = health_status
      result = {
        hub_status: status,
        credentials: {
          client_id: ENV['DHANHQ_CLIENT_ID'].presence || ENV['CLIENT_ID'].presence ? '✅ Set' : '❌ Missing',
          access_token: ENV['DHANHQ_ACCESS_TOKEN'].presence || ENV['ACCESS_TOKEN'].presence ? '✅ Set' : '❌ Missing'
        },
        mode: mode,
        enabled: enabled?
      }

      if status[:last_tick_at]
        seconds_ago = (Time.current - status[:last_tick_at]).round(1)
        result[:last_tick] = "#{seconds_ago} seconds ago"
      else
        result[:last_tick] = 'Never'
      end

      result[:last_error_details] = status[:last_error] if status[:last_error]

      result
    end

    def subscribe(segment:, security_id:)
      ensure_running!
      @ws_client.subscribe_one(segment: segment, security_id: security_id.to_s)
      { segment: segment, security_id: security_id.to_s }
    end

    def subscribe_many(instruments)
      ensure_running!
      return [] if instruments.empty?

      # Convert to the format expected by DhanHQ WebSocket client
      list = instruments.map do |instrument|
        if instrument.is_a?(Hash)
          { segment: instrument[:segment], security_id: instrument[:security_id].to_s }
        else
          { segment: instrument.segment, security_id: instrument.security_id.to_s }
        end
      end

      # Convert to format expected by DhanHQ client: ExchangeSegment and SecurityId keys
      normalized_list = list.map do |item|
        {
          ExchangeSegment: item[:segment] || item['segment'],
          SecurityId: (item[:security_id] || item['security_id']).to_s
        }
      end

      @ws_client.subscribe_many(normalized_list)
      # Rails.logger.info("[MarketFeedHub] Batch subscribed to #{list.count} instruments")
      list
    end

    def unsubscribe(segment:, security_id:)
      return unless running?

      @ws_client.unsubscribe_one(segment: segment, security_id: security_id.to_s)
      { segment: segment, security_id: security_id.to_s }
    end

    def unsubscribe_many(instruments)
      return [] unless running?
      return [] if instruments.empty?

      # Convert to the format expected by DhanHQ WebSocket client
      list = instruments.map do |instrument|
        if instrument.is_a?(Hash)
          { segment: instrument[:segment], security_id: instrument[:security_id].to_s }
        else
          { segment: instrument.segment, security_id: instrument.security_id.to_s }
        end
      end

      # Convert to format expected by DhanHQ client: ExchangeSegment and SecurityId keys
      normalized_list = list.map do |item|
        {
          ExchangeSegment: item[:segment] || item['segment'],
          SecurityId: (item[:security_id] || item['security_id']).to_s
        }
      end

      @ws_client.unsubscribe_many(normalized_list)
      # Rails.logger.info("[MarketFeedHub] Batch unsubscribed from #{list.count} instruments")
      list
    end

    def on_tick(&block)
      raise ArgumentError, 'block required' unless block

      @callbacks << block
    end

    private

    def enabled?
      # Always enabled - just check for credentials
      # Support both naming conventions: CLIENT_ID/DHANHQ_CLIENT_ID and ACCESS_TOKEN/DHANHQ_ACCESS_TOKEN
      client_id = ENV['DHANHQ_CLIENT_ID'].presence || ENV['CLIENT_ID'].presence
      access    = ENV['DHANHQ_ACCESS_TOKEN'].presence || ENV['ACCESS_TOKEN'].presence
      client_id.present? && access.present?
    end

    def ensure_running!
      start! unless running?
      raise 'DhanHQ market feed is not running' unless running?
    end

    def handle_tick(tick)
      # Update connection health indicators
      @last_tick_at = Time.current
      @connection_state = :connected

      # Update FeedHealthService
      begin
        Live::FeedHealthService.instance.mark_success!(:ticks)
      rescue StandardError
        nil
      end

      # puts tick  # Uncomment only for debugging - very noisy!
      # Log every tick (segment:security_id and LTP) for verification during development
      # # Rails.logger.info("[WS tick] #{tick[:segment]}:#{tick[:security_id]} ltp=#{tick[:ltp]} kind=#{tick[:kind]}")

      # Store in in-memory cache (primary)
      # Always update in-memory TickCache
      Live::TickCache.put(tick) if tick[:ltp].to_f.positive?

      # # puts Live::TickCache.ltp(tick[:segment], tick[:security_id])
      # # Store in Redis for PnL tracking (secondary)
      # # Only store if we have valid segment, security_id, and LTP
      # if tick[:segment].present? && tick[:security_id].present? && tick[:ltp].present? && tick[:ltp].to_f.positive?
      #   begin
      #     if tick[:ltp].present? && tick[:ltp].to_f.positive?
      #       Live::RedisPnlCache.instance.store_tick(
      #         segment: tick[:segment],
      #         security_id: tick[:security_id].to_s,
      #         ltp: tick[:ltp],
      #         timestamp: Time.current
      #       )
      #     end
      #   rescue StandardError => e
      #     Rails.logger.debug { "[MarketFeedHub] Failed to store tick in Redis: #{e.message}" } if defined?(Rails.logger)
      #   end
      # end

      ActiveSupport::Notifications.instrument('dhanhq.tick', tick)

      @callbacks.each do |callback|
        safe_invoke(callback, tick)
      end
      # begin
      #   trackers = PositionTracker.active.where(security_id: tick[:security_id].to_s)
      #   trackers.each do |t|
      #     next unless t.entry_price && t.quantity
      #     pnl = (tick[:ltp].to_f - t.entry_price.to_f) * t.quantity
      #     pnl_pct = (tick[:ltp].to_f - t.entry_price.to_f) / t.entry_price.to_f
      #     Live::RedisPnlCache.instance.store_pnl(
      #       tracker_id: t.id,
      #       pnl: pnl,
      #       pnl_pct: pnl_pct,
      #       ltp: tick[:ltp],
      #       hwm: [t.high_water_mark_pnl.to_f, pnl].max,
      #       timestamp: Time.current
      #     )
      #   end
      # rescue => e
      #   Rails.logger.error("[MarketFeedHub] Failed to live-update Redis PnL: #{e.message}")
      # end
      # fast-path: drop empty/invalid ticks
      return unless tick[:ltp].to_f.positive? && tick[:security_id].present?

      # get in-memory trackers snapshot (array of metadata)
      trackers = Live::PositionIndex.instance.trackers_for(tick[:security_id].to_s)
      if trackers.empty?
        # nothing to do for this security
        return
      end

      # For each metadata push minimal payload (last-wins)
      trackers.each do |meta|
        # defensive checks
        next unless meta[:entry_price] && meta[:quantity] && meta[:quantity].to_i > 0

        Live::PnlUpdaterService.instance.cache_intermediate_pnl(
          tracker_id: meta[:id],
          ltp: tick[:ltp]
        )
      end
    end

    def safe_invoke(callback, payload)
      callback.call(payload)
    rescue StandardError => _e
      # Rails.logger.error("DhanHQ tick callback failed: #{_e.class} - #{_e.message}")
    end

    def subscribe_watchlist
      return if @watchlist.empty?

      # Use subscribe_many for efficient batch subscription (up to 100 instruments per message)
      # DhanHQ client expects ExchangeSegment and SecurityId keys (capitalized)
      normalized_list = @watchlist.map do |item|
        {
          ExchangeSegment: item[:segment] || item['segment'],
          SecurityId: (item[:security_id] || item['security_id']).to_s
        }
      end

      @ws_client.subscribe_many(normalized_list)
      # Rails.logger.info("[MarketFeedHub] Subscribed to #{@watchlist.count} instruments using subscribe_many")
    end

    def load_watchlist
      # Prefer DB watchlist if present; fall back to ENV for bootstrap-only
      if ActiveRecord::Base.connection.schema_cache.data_source_exists?('watchlist_items') &&
         WatchlistItem.exists?
        # Only load active watchlist items for subscription
        scope = WatchlistItem.active

        pairs = if scope.respond_to?(:order) && scope.respond_to?(:pluck)
                  scope.order(:segment, :security_id).pluck(:segment, :security_id)
                else
                  Array(scope).filter_map do |record|
                    seg = if record.respond_to?(:exchange_segment)
                            record.exchange_segment
                          elsif record.is_a?(Hash)
                            record[:exchange_segment] || record[:segment]
                          end
                    sid = if record.respond_to?(:security_id)
                            record.security_id
                          elsif record.is_a?(Hash)
                            record[:security_id]
                          end
                    next if seg.blank? || sid.blank?

                    [seg, sid]
                  end
                end

        return pairs.map { |seg, sid| { segment: seg, security_id: sid } }
      end

      raw = ENV.fetch('DHANHQ_WS_WATCHLIST', '')
               .split(/[;\n,]/)
               .map(&:strip)
               .compact_blank

      raw.filter_map do |entry|
        segment, security_id = entry.split(':', 2)
        next if segment.blank? || security_id.blank?

        { segment: segment, security_id: security_id }
      end
    end

    def build_client
      DhanHQ::WS::Client.new(mode: mode)
    end

    def mode
      allowed = %i[ticker quote full]
      selected = :full || config&.ws_mode || DEFAULT_MODE
      allowed.include?(selected) ? selected : DEFAULT_MODE
      :full
    end

    def setup_connection_handlers
      # DhanHQ WebSocket client only supports :tick events
      # Connection/disconnection monitoring is handled via tick activity tracking
      # and connection state is inferred from tick reception

      # NOTE: The DhanHQ client handles reconnection internally
      # We track connection state via:
      # - Tick reception (sets @connection_state = :connected)
      # - Time-based fallback (connected? checks if ticks received recently)
      # - Explicit stop! calls (sets @connection_state = :disconnected)

      # Connection will be marked as :connected when first tick is received
      # in handle_tick method

      # Rails.logger.debug('[MarketFeedHub] Connection handlers: Using tick-based connection monitoring')
    end

    def config
      return nil unless Rails.application.config.respond_to?(:x)

      x = Rails.application.config.x
      return nil unless x.respond_to?(:dhanhq)

      cfg = x.dhanhq
      cfg.is_a?(ActiveSupport::InheritableOptions) ? cfg : nil
    rescue StandardError
      nil
    end
  end
end


# File: app/services/live/mock_data_service.rb
# frozen_string_literal: true

module Live
  class MockDataService
    include Singleton

    def initialize
      @running = false
      @thread = nil
    end

    def start!
      return if @running

      @running = true
      @thread = Thread.new do
        # Rails.logger.info('[MockData] Starting mock data service')

        while @running
          begin
            # Mock data for the three indices
            mock_data = [
              { segment: 'IDX_I', security_id: '13', ltp: rand(25_200..25_399), name: 'NIFTY' },
              { segment: 'IDX_I', security_id: '25', ltp: rand(56_500..56_799), name: 'BANKNIFTY' },
              { segment: 'IDX_I', security_id: '51', ltp: rand(82_000..82_499), name: 'SENSEX' }
            ]

            mock_data.each do |data|
              tick_data = {
                segment: data[:segment],
                security_id: data[:security_id],
                ltp: data[:ltp],
                kind: :quote,
                ts: Time.current.to_i
              }

              # Populate TickCache (like real WebSocket does)
              Live::TickCache.put(tick_data)

              # Simulate notification flow
              ActiveSupport::Notifications.instrument('dhanhq.tick', tick_data)

              # Rails.logger.debug { "[MockData] Generated tick for #{data[:name]}: #{data[:ltp]}" }
            end

            sleep 2 # Update every 2 seconds
          rescue StandardError => e
            # Rails.logger.error("[MockData] Error: #{e.message}")
            sleep 5
          end
        end
      end
    end

    def stop!
      @running = false
      @thread&.join
      # Rails.logger.info('[MockData] Mock data service stopped')
    end

    def running?
      @running
    end
  end
end


# File: app/services/live/order_update_handler.rb
# frozen_string_literal: true

require 'bigdecimal'
require 'singleton'

module Live
  class OrderUpdateHandler
    include Singleton

    FILL_STATUSES = %w[TRADED COMPLETE].freeze
    CANCELLED_STATUSES = %w[CANCELLED REJECTED].freeze

    def initialize
      @subscribed = false
      @lock = Mutex.new
    end

    def start!
      return if @subscribed

      @lock.synchronize do
        return if @subscribed

        Live::OrderUpdateHub.instance.start!
        Live::OrderUpdateHub.instance.on_update { |payload| handle_update(payload) }
        @subscribed = true
      end
    end

    def stop!
      @lock.synchronize { @subscribed = false }
    end

    def process_update(payload)
      handle_update(payload)
    end

    def handle_order_update(payload)
      handle_update(payload)
    end

    def find_tracker_by_order_id(order_id)
      PositionTracker.find_by(order_no: order_id)
    end

    private

    def handle_update(payload)
      order_no = payload[:order_no] || payload[:order_id]
      return if order_no.blank?

      tracker = PositionTracker.find_by(order_no: order_no)
      return unless tracker

      status = payload[:order_status] || payload[:status]
      avg_price = safe_decimal(payload[:average_traded_price] || payload[:average_price])
      quantity = payload[:filled_quantity] || payload[:quantity]

      transaction_type = (payload[:transaction_type] || payload[:side] || payload[:transaction_side]).to_s.upcase

      if FILL_STATUSES.include?(status)
        if transaction_type == 'SELL'
          # Use avg_price from order update as exit_price
          tracker.mark_exited!(exit_price: avg_price)
        else
          tracker.mark_active!(avg_price: avg_price, quantity: quantity)
        end
      elsif CANCELLED_STATUSES.include?(status)
        tracker.mark_cancelled!
      end
    rescue StandardError => _e
      # Rails.logger.error("Failed to process Dhan order update: #{_e.class} - #{_e.message}")
    end

    def safe_decimal(value)
      return if value.nil?

      BigDecimal(value.to_s)
    rescue ArgumentError
      nil
    end
  end
end


# File: app/services/live/order_update_hub.rb
# frozen_string_literal: true

require 'singleton'
require 'concurrent/array'

module Live
  class OrderUpdateHub
    include Singleton

    def initialize
      @callbacks = Concurrent::Array.new
      @lock = Mutex.new
    end

    def start!
      return unless enabled?
      return if running?

      @lock.synchronize do
        return if running?

        @ws_client = DhanHQ::WS::Orders::Client.new
        @ws_client.on(:update) { |payload| handle_update(payload) }
        @ws_client.start
        @running = true
      end

      # Rails.logger.info('DhanHQ order update feed started.')
      true
    rescue StandardError => e
      # Rails.logger.error("Failed to start DhanHQ order update feed: #{e.class} - #{e.message}")
      stop!
      false
    end

    def stop!
      @lock.synchronize do
        @running = false
        return unless @ws_client

        begin
          @ws_client.stop
        rescue StandardError => e
          # Rails.logger.warn("Error while stopping DhanHQ order update feed: #{e.message}")
        ensure
          @ws_client = nil
        end
      end
    end

    def running?
      @running
    end

    def on_update(&block)
      raise ArgumentError, 'block required' unless block

      @callbacks << block
    end

    private

    def enabled?
      # Always enabled - just check for credentials
      # Support both naming conventions: CLIENT_ID/DHANHQ_CLIENT_ID and ACCESS_TOKEN/DHANHQ_ACCESS_TOKEN
      client_id = ENV['DHANHQ_CLIENT_ID'].presence || ENV['CLIENT_ID'].presence
      access    = ENV['DHANHQ_ACCESS_TOKEN'].presence || ENV['ACCESS_TOKEN'].presence
      client_id.present? && access.present?
    end

    def config
      Rails.application.config.x.dhanhq
    end

    def handle_update(payload)
      normalized = normalize(payload)
      ActiveSupport::Notifications.instrument('dhanhq.order_update', normalized)
      @callbacks.each { |callback| safe_invoke(callback, normalized) }
    end

    def normalize(payload)
      return payload unless payload.is_a?(Hash)

      payload.deep_transform_keys { |key| key.to_s.underscore.to_sym }
    end

    def safe_invoke(callback, payload)
      callback.call(payload)
    rescue StandardError => e
      # Rails.logger.error("DhanHQ order update callback failed: #{e.class} - #{e.message}")
    end
  end
end


# File: app/services/live/paper_pnl_refresher.rb
# frozen_string_literal: true

module Live
  class PaperPnlRefresher
    REFRESH_INTERVAL = 40 # seconds

    def initialize
      @thread = nil
      @running = false
      @lock = Mutex.new
    end

    def start
      @lock.synchronize do
        return if @running

        @running = true
        @thread = Thread.new { run_loop }
      end
    end

    def stop
      @lock.synchronize do
        @running = false
        @thread&.kill
        @thread&.join(1)
        @thread = nil
      end
    end

    private

    def run_loop
      Thread.current.name = "paper-pnl-refresher"

      loop do
        refresh_all
        sleep REFRESH_INTERVAL
      end
    rescue => e
      Rails.logger.error("[PaperPnlRefresher] ERROR: #{e.class} - #{e.message}")
      retry
    end

    def refresh_all
      trackers = PositionTracker.paper.active

      trackers.find_each do |t|
        refresh_tracker(t)
      end
    end

    def refresh_tracker(tracker)
      seg = tracker.segment || tracker.watchable&.exchange_segment
      sid = tracker.security_id

      return if seg.blank? || sid.blank?

      ltp = Live::TickCache.ltp(seg, sid)
      return unless ltp.present?

      entry = BigDecimal(tracker.entry_price.to_s)
      qty   = tracker.quantity.to_i
      pnl   = (ltp.to_d - entry) * qty.to_d
      pct   = entry.positive? ? ((ltp.to_d - entry) / entry * 100) : 0

      tracker.update!(
        last_pnl_rupees: pnl,
        last_pnl_pct: pct.round(2),
        high_water_mark_pnl: [tracker.high_water_mark_pnl.to_d, pnl].max
      )

      Live::RedisPnlCache.instance.store_pnl(
        tracker_id: tracker.id,
        pnl: pnl,
        pnl_pct: pct,
        ltp: ltp,
        hwm: tracker.high_water_mark_pnl,
        timestamp: Time.current
      )
    rescue => e
      Rails.logger.warn("[PaperPnlRefresher] Failed refresh for #{tracker.id}: #{e.message}")
    end
  end
end


# File: app/services/live/pnl_updater_service.rb
# frozen_string_literal: true

require 'singleton'
require 'monitor'
require 'bigdecimal'
require 'logger'

module Live
  class PnlUpdaterService
    include Singleton

    FLUSH_INTERVAL_SECONDS = 0.25
    MAX_BATCH = 200

    attr_reader :running

    def initialize
      @queue = {} # tracker_id => payload (last-wins)
      @mutex = Monitor.new
      @running = false
      @thread = nil
      @logger = defined?(Rails) ? Rails.logger : Logger.new($stdout)
    end

    # Accept arbitrary payload fields; last-wins for a tracker id
    # Ensure all numeric fields are stored as BigDecimal (or nil)
    def cache_intermediate_pnl(tracker_id:, pnl: nil, pnl_pct: nil, ltp: nil, hwm: nil)
      @mutex.synchronize do
        @queue[tracker_id.to_i] = {
          pnl: safe_decimal(pnl),
          pnl_pct: safe_decimal(pnl_pct),
          ltp: safe_decimal(ltp),
          hwm: safe_decimal(hwm),
          updated_at: Time.now.to_i
        }
      end

      start! unless running?
      true
    rescue StandardError => e
      @logger.error("[PnlUpdater] cache_intermediate_pnl error: #{e.class} - #{e.message}")
      false
    end

    def safe_decimal(value)
      return nil if value.nil?

      s = value.respond_to?(:to_s) ? value.to_s.strip : ''
      return nil if ['', ' '].include?(s)

      BigDecimal(s)
    rescue StandardError
      nil
    end

    def start!
      return true if running?

      @mutex.synchronize do
        return true if running?

        @running = true
        @thread = Thread.new { run_loop }
        begin
          @thread.name = 'pnl-updater-service'
        rescue StandardError
          # some Rubies don't allow thread name setting — ignore
        end
      end
      true
    end

    def stop!
      @mutex.synchronize do
        @running = false
        if @thread&.alive?
          begin
            @thread.wakeup
            @thread.join(1) # gently wait a bit
          rescue StandardError
            nil
          end
        end
        @thread = nil
      end
    end

    def running?
      @running
    end

    # For tests/dev: force flush synchronously
    def flush_now!
      flush!
    end

    private

    def run_loop
      @logger.info('[PnlUpdater] started') if @logger
      loop do
        break unless running?

        flush!
        sleep FLUSH_INTERVAL_SECONDS
      end
    rescue StandardError => e
      @logger.error("[PnlUpdater] crashed: #{e.class} - #{e.message}")
      @running = false
    ensure
      @logger.info('[PnlUpdater] stopped') if @logger
    end

    def flush!
      batch = nil

      @mutex.synchronize do
        return if @queue.empty?

        # Preserve insertion order, take first MAX_BATCH
        batch = @queue.first(MAX_BATCH).to_h

        # Remove processed keys
        batch.keys.each { |k| @queue.delete(k) }
      end

      return unless batch && batch.any?

      # Batch load all trackers in a single query to avoid N+1
      tracker_ids = batch.keys
      trackers_by_id = PositionTracker.includes(:watchable, :instrument).where(id: tracker_ids).index_by(&:id)

      batch.each do |tracker_id, payload|
        begin
          tracker = trackers_by_id[tracker_id]
        rescue StandardError => e
          @logger.error("[PnlUpdater] DB lookup failed for tracker #{tracker_id}: #{e.message}")
          begin
            Live::RedisPnlCache.instance.clear_tracker(tracker_id)
          rescue StandardError
            nil
          end
          next
        end

        unless tracker
          # No tracker => stale Redis entry must be cleared
          begin
            Live::RedisPnlCache.instance.clear_tracker(tracker_id)
          rescue StandardError
            nil
          end
          next
        end

        # Resolve segment reliably (match PositionTracker.subscribe logic)
        seg = (tracker.segment.presence ||
               tracker.watchable&.exchange_segment ||
               tracker.instrument&.exchange_segment ||
               tracker.instrument&.segment).to_s

        security_id = tracker.security_id.to_s

        if seg.blank? || security_id.blank?
          @logger.debug("[PnlUpdater] Skip #{tracker_id}: missing segment/security_id (seg=#{seg.inspect}, sid=#{security_id.inspect})")
          next
        end

        # 1) Try TickCache (memory)
        tick_ltp = nil
        begin
          tick_ltp = Live::TickCache.ltp(seg, security_id)
        rescue StandardError => e
          @logger.warn("[PnlUpdater] TickCache.ltp error for #{seg}:#{security_id} - #{e.message}")
          tick_ltp = nil
        end

        # 2) RedisTickCache fallback
        if tick_ltp.nil? || (tick_ltp.respond_to?(:to_f) && tick_ltp.to_f <= 0)
          begin
            redis_tick = Live::RedisTickCache.instance.fetch_tick(seg, security_id)
            tick_ltp = redis_tick[:ltp] if redis_tick && redis_tick[:ltp].to_f.positive?
          rescue StandardError => e
            @logger.warn("[PnlUpdater] RedisTickCache.fetch_tick error for #{seg}:#{security_id} - #{e.message}")
            tick_ltp = nil
          end
        end

        # 3) Payload fallback
        if (tick_ltp.nil? || (tick_ltp.respond_to?(:to_f) && tick_ltp.to_f <= 0)) && payload[:ltp] && payload[:ltp].to_f.positive?
          tick_ltp = payload[:ltp]
        end

        unless tick_ltp && tick_ltp.to_f.positive?
          @logger.debug { "[PnlUpdater] Skip #{tracker_id}: no valid LTP (seg=#{seg} sid=#{security_id})" }
          next
        end

        # Ensure entry_price & quantity exist and are numeric
        if tracker.entry_price.blank? || tracker.quantity.blank? || tracker.quantity.to_i <= 0
          @logger.warn("[PnlUpdater] Invalid tracker data for #{tracker_id} - entry_price=#{tracker.entry_price.inspect}, quantity=#{tracker.quantity.inspect}. Clearing redis key.")
          begin
            Live::RedisPnlCache.instance.clear_tracker(tracker_id)
          rescue StandardError
            nil
          end
          next
        end

        # Calculate with BigDecimal (all safe)
        ltp_bd = safe_decimal(tick_ltp) || BigDecimal(0)
        entry_bd = safe_decimal(tracker.entry_price) || BigDecimal(0)
        qty_bd = BigDecimal(tracker.quantity.to_i.to_s)

        # Compute PnL (fresh) — allow payload override when present (payload values are BigDecimal already)
        pnl_bd = payload[:pnl] || ((ltp_bd - entry_bd) * qty_bd)
        pnl_pct_bd = begin
          payload[:pnl_pct] || ((ltp_bd - entry_bd) / entry_bd)
        rescue StandardError
          BigDecimal(0)
        end

        hwm_bd = payload[:hwm] || (tracker.high_water_mark_pnl.present? ? safe_decimal(tracker.high_water_mark_pnl) : BigDecimal(0))
        hwm_bd = BigDecimal(0) if hwm_bd.nil?

        # Persist to Redis (use floats for storage to remain compatible)
        Live::RedisPnlCache.instance.store_pnl(
          tracker_id: tracker_id,
          pnl: pnl_bd.to_f,
          pnl_pct: pnl_pct_bd.to_f,
          ltp: ltp_bd.to_f,
          hwm: hwm_bd.to_f,
          timestamp: Time.now
        )

        # Update in-memory tracker object (but don't persist DB here)
        begin
          tracker.cache_live_pnl(pnl_bd, pnl_pct: pnl_pct_bd)
        rescue StandardError => e
          @logger.warn("[PnlUpdater] tracker.cache_live_pnl failed for #{tracker_id}: #{e.message}")
        end
      rescue StandardError => e
        @logger.error("[PnlUpdater] processing failed for tracker #{tracker_id}: #{e.class} - #{e.message}")
        next
      end

      true
    end
  end
end


# File: app/services/live/position_index.rb
# frozen_string_literal: true

require 'singleton'
require 'concurrent/map'
require 'concurrent/array'
require 'monitor'

module Live
  # In-memory index: security_id(string) => Concurrent::Array of tracker metadata
  # Metadata is a Hash with minimal fields used by PnL (id, entry_price, quantity)
  class PositionIndex
    include Singleton

    def initialize
      @index = Concurrent::Map.new # security_id => Concurrent::Array of metadata
      @lock = Monitor.new
    end

    def all_keys
      @index.keys
    end

    # metadata: { id:, entry_price:, quantity:, segment: }
    def add(metadata)
      sid = metadata[:security_id].to_s
      arr = (@index[sid] ||= Concurrent::Array.new)
      # de-dup by id (rare) and push metadata
      arr.reject! { |m| m[:id] == metadata[:id] }
      arr << metadata
      true
    end

    def remove(tracker_id, security_id)
      sid = security_id.to_s
      return unless @index.key?(sid)

      arr = @index[sid]
      arr.delete_if { |m| m[:id] == tracker_id.to_i }
      @index.delete(sid) if arr.empty?
      true
    end

    def update(metadata)
      # safe replace by id
      remove(metadata[:id], metadata[:security_id])
      add(metadata)
    end

    def trackers_for(security_id)
      arr = @index[security_id.to_s]
      return [] unless arr

      # Return a snapshot (dup) to avoid mutation issues
      arr.dup
    end

    def tracked?(segment, security_id)
      trackers = trackers_for(security_id)
      trackers.any? { |t| t[:segment] == segment.to_s }
    end

    delegate :clear, to: :@index

    def active_instrument_pairs
      @index.filter_map do |sid, arr|
        next if arr.empty?

        meta = arr.first
        { segment: meta[:segment], security_id: sid }
      end
    end

    # For boot: populate from DB once
    def bulk_load_active!
      @lock.synchronize do
        @index.clear
        PositionTracker.active.select(:id, :security_id, :entry_price, :quantity, :segment).find_each do |t|
          add(
            id: t.id,
            security_id: t.security_id,
            entry_price: t.entry_price.to_s,
            quantity: t.quantity.to_i,
            segment: t.segment
          )
        end
      end
    end
  end
end


# File: app/services/live/position_sync_service.rb
# frozen_string_literal: true

require 'singleton'

module Live
  class PositionSyncService
    include Singleton

    def initialize
      @last_sync = nil
      @sync_interval = 30.seconds
    end

    def sync_positions!
      return unless should_sync?

      if paper_trading_enabled?
        sync_paper_positions
      else
        sync_live_positions
      end

      PositionTracker.clear_orphaned_redis_pnl!
    end

    def force_sync!
      @last_sync = nil
      sync_positions!
    end

    private

    def should_sync?
      @last_sync.nil? || (Time.current - @last_sync) >= @sync_interval
    end

    def sync_live_positions
      # Rails.logger.info('[PositionSync] Starting live position synchronization')

      # Fetch all active positions from DhanHQ
      dhan_positions = DhanHQ::Models::Position.active
      # Rails.logger.info("[PositionSync] Found #{dhan_positions.size} active positions in DhanHQ")

      # Get all tracked positions from database with proper preloading
      tracked_positions = PositionTracker.active.eager_load(:instrument).to_a
      tracked_security_ids = tracked_positions.map { |p| p.security_id.to_s }

      # Rails.logger.info("[PositionSync] Found #{tracked_positions.size} tracked positions in database")

      # Find positions that exist in DhanHQ but not in our database
      untracked_positions = find_untracked_positions(dhan_positions, tracked_security_ids)

      # Create PositionTracker records for untracked positions
      untracked_positions.each do |dhan_pos|
        create_tracker_for_position(dhan_pos)
      end

      # Check for live positions that exist in database but not in DhanHQ (should be marked as exited)
      mark_orphaned_live_positions(tracked_positions, dhan_positions)

      @last_sync = Time.current
      # Rails.logger.info("[PositionSync] Synchronization completed - created #{untracked_positions.size} trackers, marked #{orphaned_trackers.size} as exited")
    rescue StandardError
      # Rails.logger.error("[PositionSync] Failed to sync positions: #{e.class} - #{e.message}")
      # Rails.logger.error("[PositionSync] Backtrace: #{e.backtrace.first(5).join(', ')}")
    end

    def sync_paper_positions
      # Rails.logger.info('[PositionSync] Starting paper position synchronization')

      # In paper mode, we only work with PositionTracker records
      # No need to fetch from DhanHQ - paper positions don't exist there
      tracked_positions = PositionTracker.active.eager_load(:instrument).to_a
      paper_positions = tracked_positions.select(&:paper?)

      # Rails.logger.info("[PositionSync] Found #{paper_positions.size} paper positions in database")

      # Paper positions are managed entirely by our system
      # No sync needed - they're already tracked in PositionTracker
      # Just ensure they're subscribed to market feed
      paper_positions.each do |tracker|
        tracker.subscribe unless tracker.watchable.nil?
      rescue StandardError => e
        Rails.logger.warn("[PositionSync] Failed to subscribe paper position #{tracker.order_no}: #{e.message}")
      end

      @last_sync = Time.current
      # Rails.logger.info("[PositionSync] Paper position sync completed - ensured #{paper_positions.size} positions are subscribed")
    rescue StandardError => e
      Rails.logger.error("[PositionSync] Failed to sync paper positions: #{e.class} - #{e.message}")
    end

    def find_untracked_positions(dhan_positions, tracked_security_ids)
      untracked = []
      dhan_positions.each do |dhan_pos|
        security_id = extract_security_id(dhan_pos)
        next unless security_id

        unless tracked_security_ids.include?(security_id.to_s)
          untracked << dhan_pos
          # Rails.logger.warn("[PositionSync] Found untracked position: #{security_id} - #{extract_symbol(dhan_pos)}")
        end
      end
      untracked
    end

    def mark_orphaned_live_positions(tracked_positions, dhan_positions)
      # IMPORTANT: Only check live positions - paper positions don't exist in DhanHQ by design
      live_tracked_positions = tracked_positions.select(&:live?)
      orphaned_trackers = live_tracked_positions.reject do |tracker|
        dhan_positions.any? { |dp| extract_security_id(dp).to_s == tracker.security_id.to_s }
      end

      orphaned_trackers.each do |tracker|
        # Rails.logger.warn("[PositionSync] Found orphaned tracker: #{tracker.order_no} - marking as exited")
        tracker.mark_exited!
      end
    end

    def paper_trading_enabled?
      AlgoConfig.fetch.dig(:paper_trading, :enabled) == true
    end

    def extract_security_id(dhan_position)
      dhan_position.security_id
    end

    def extract_symbol(dhan_position)
      dhan_position.trading_symbol
    end

    def extract_exchange_segment(dhan_position)
      dhan_position.exchange_segment
    end

    def extract_quantity(dhan_position)
      dhan_position.net_qty || 0
    end

    def extract_average_price(dhan_position)
      # Use buy_avg as the average price
      dhan_position.buy_avg
    end

    def parse_exchange_segment(exchange_segment)
      # Parse exchange_segment like "NSE_FNO" into ["nse", "derivatives"]
      # DhanHQ uses "NSE_FNO" but our database uses "nse" and "derivatives"
      case exchange_segment
      when 'NSE_FNO'
        %w[nse derivatives]
      when 'BSE_FNO'
        %w[bse derivatives]
      when 'NSE_EQ'
        %w[nse equity]
      when 'BSE_EQ'
        %w[bse equity]
      else
        # Fallback - try to parse as exchange_segment
        if exchange_segment&.include?('_')
          parts = exchange_segment.split('_', 2)
          [parts[0].downcase, parts[1].downcase]
        else
          ['nse', exchange_segment&.downcase]
        end
      end
    end

    def create_tracker_for_position(dhan_position)
      security_id = extract_security_id(dhan_position)
      symbol = extract_symbol(dhan_position)
      exchange_segment = extract_exchange_segment(dhan_position)
      quantity = extract_quantity(dhan_position)
      average_price = extract_average_price(dhan_position)

      # Find the derivative (for options) or instrument (for indices)
      # Parse exchange_segment (e.g., "NSE_FNO" -> exchange: "NSE", segment: "FNO")
      exchange, segment = parse_exchange_segment(exchange_segment)

      # For options (derivatives), look up derivatives
      if segment == 'derivatives'
        derivative = Derivative.find_by(
          security_id: security_id,
          exchange: exchange,
          segment: segment
        )

        unless derivative
          # Rails.logger.error("[PositionSync] Could not find derivative for #{security_id} (#{exchange_segment})")
          return
        end

        instrument = derivative.instrument
      else
        # For indices, look up instruments directly
        instrument = Instrument.find_by(
          security_id: security_id,
          exchange: exchange,
          segment: segment
        )

        unless instrument
          # Rails.logger.error("[PositionSync] Could not find instrument for #{security_id} (#{exchange_segment})")
          return
        end
      end

      # Generate a synthetic order number for untracked positions
      synthetic_order_no = "SYNC-#{security_id}-#{Time.current.to_i}"

      # Determine watchable: derivative for options, instrument for indices
      watchable = if segment == 'derivatives' && derivative
                    derivative
                  else
                    instrument
                  end

      # Create PositionTracker
      tracker = PositionTracker.create!(
        watchable: watchable,
        instrument: watchable.is_a?(Derivative) ? watchable.instrument : watchable, # Backward compatibility
        order_no: synthetic_order_no,
        security_id: security_id.to_s,
        symbol: symbol,
        segment: exchange_segment,
        side: 'long', # Default assumption - could be enhanced to detect actual side
        status: 'active',
        quantity: quantity,
        avg_price: average_price,
        entry_price: average_price,
        meta: {
          synced_from_dhan: true,
          sync_timestamp: Time.current,
          original_position_data: begin
            dhan_position.to_h
          rescue StandardError
            {}
          end
        }
      )

      # Subscribe to market feed
      tracker.subscribe

      # Rails.logger.info("[PositionSync] Created tracker #{tracker.id} for untracked position #{security_id}")
    rescue StandardError
      # Rails.logger.error("[PositionSync] Failed to create tracker for position #{security_id}: #{e.class} - #{e.message}")
    end

    def calculate_paper_pnl_before_exit(tracker)
      return unless tracker.paper? && tracker.entry_price.present? && tracker.quantity.present?

      # Try to get current LTP using the same method as RiskManagerService
      ltp = get_paper_ltp(tracker)
      return unless ltp

      exit_price = BigDecimal(ltp.to_s)
      entry = BigDecimal(tracker.entry_price.to_s)
      qty = tracker.quantity.to_i
      pnl = (exit_price - entry) * qty
      pnl_pct = ((exit_price - entry) / entry * 100).round(2)

      hwm = tracker.high_water_mark_pnl || BigDecimal(0)
      hwm = [hwm, pnl].max

      tracker.update!(
        last_pnl_rupees: pnl,
        last_pnl_pct: pnl_pct,
        high_water_mark_pnl: hwm,
        avg_price: exit_price,
        meta: (tracker.meta || {}).merge(
          'exit_price' => exit_price.to_f,
          'exited_at' => Time.current,
          'exit_reason' => 'position_sync_orphaned'
        )
      )

      Rails.logger.info("[PositionSync] Paper exit PnL calculated for #{tracker.order_no}: exit_price=₹#{exit_price}, pnl=₹#{pnl}, pnl_pct=#{pnl_pct}%")
    rescue StandardError => e
      Rails.logger.error("[PositionSync] Failed to calculate PnL for paper position #{tracker.order_no}: #{e.message}")
    end

    def get_paper_ltp(tracker)
      segment = tracker.segment.presence || tracker.watchable&.exchange_segment || tracker.instrument&.exchange_segment
      security_id = tracker.security_id
      return nil unless segment.present? && security_id.present?

      # Try WebSocket cache first
      cached = Live::TickCache.ltp(segment, security_id)
      return BigDecimal(cached.to_s) if cached

      # Try Redis PnL cache
      tick_data = Live::TickCache.fetch(segment, security_id)
      return BigDecimal(tick_data[:ltp].to_s) if tick_data&.dig(:ltp)

      # Try tradable's fetch method (derivative or instrument)
      tradable = tracker.tradable
      if tradable
        ltp = tradable.fetch_ltp_from_api_for_segment(segment: segment, security_id: security_id)
        return BigDecimal(ltp.to_s) if ltp
      end

      # Fallback: Direct API call
      begin
        response = DhanHQ::Models::MarketFeed.ltp({ segment => [security_id.to_i] })
        if response['status'] == 'success'
          option_data = response.dig('data', segment, security_id.to_s)
          return BigDecimal(option_data['last_price'].to_s) if option_data && option_data['last_price']
        end
      rescue StandardError => e
        Rails.logger.error("[PositionSync] Failed to fetch paper LTP for #{tracker.order_no}: #{e.message}")
      end
      nil
    end
  end
end


# File: app/services/live/position_tracker_pruner.rb
# frozen_string_literal: true

module Live
  class PositionTrackerPruner
    def self.call
      ids = PositionTracker.active.ids.map(&:to_s)
      Live::RedisPnlCache.instance.prune_except(ids)
      Live::RedisTickCache.instance.prune_stale
    end
  end
end


# File: app/services/live/redis_pnl_cache.rb
# frozen_string_literal: true

require 'singleton'

module Live
  class RedisPnlCache
    include Singleton

    REDIS_KEY_PREFIX = 'pnl:tracker'
    TTL_SECONDS = 6.hours.to_i

    def initialize
      @redis = Redis.new(url: ENV.fetch('REDIS_URL', 'redis://127.0.0.1:6379/0'))
    rescue StandardError => e
      Rails.logger.error("[RedisPnL] init error: #{e.message}") if defined?(Rails)
      @redis = nil
    end

    # store only computed PnL (strings stored to Redis)
    def store_pnl(tracker_id:, pnl:, ltp:, hwm:, pnl_pct: nil, timestamp: Time.current)
      return false unless @redis

      key = pnl_key(tracker_id)
      data = {
        'pnl' => pnl.to_f.to_s,
        'pnl_pct' => pnl_pct&.to_f.to_s,
        'ltp' => ltp.to_f.to_s,
        'hwm_pnl' => hwm.to_f.to_s,
        'timestamp' => timestamp.to_i.to_s,
        'updated_at' => Time.current.to_i.to_s
      }

      @redis.hset(key, **data)
      # ensure TTL
      ttl = @redis.ttl(key).to_i
      @redis.expire(key, TTL_SECONDS) if ttl < (TTL_SECONDS / 2)
      true
    rescue StandardError => e
      Rails.logger.error("[RedisPnL] store_pnl error: #{e.message}") if defined?(Rails)
      false
    end

    def fetch_pnl(tracker_id)
      return nil unless @redis

      key = pnl_key(tracker_id)
      raw = @redis.hgetall(key)
      return nil if raw.nil? || raw.empty?

      {
        pnl: raw['pnl']&.to_f,
        pnl_pct: raw['pnl_pct']&.to_f,
        ltp: raw['ltp']&.to_f,
        hwm_pnl: raw['hwm_pnl']&.to_f,
        timestamp: raw['timestamp']&.to_i,
        updated_at: raw['updated_at']&.to_i
      }
    rescue StandardError => e
      Rails.logger.error("[RedisPnL] fetch_pnl error: #{e.message}") if defined?(Rails)
      nil
    end

    # clear all pnl:* keys (dangerous but useful for tests/dev)
    def clear
      return false unless @redis

      pattern = "#{REDIS_KEY_PREFIX}:*"
      @redis.scan_each(match: pattern) { |k| @redis.del(k) }
      true
    rescue StandardError => e
      Rails.logger.error("[RedisPnL] clear error: #{e.message}") if defined?(Rails)
      false
    end

    def clear_tracker(tracker_id)
      return false unless @redis

      @redis.del(pnl_key(tracker_id))
      true
    rescue StandardError => e
      Rails.logger.error("[RedisPnL] clear_tracker error: #{e.message}") if defined?(Rails)
      false
    end

    # fetch everything: returns hash tracker_id => data
    def fetch_all
      return {} unless @redis

      out = {}
      pattern = "#{REDIS_KEY_PREFIX}:*"
      @redis.scan_each(match: pattern) do |key|
        id = key.split(':').last
        out[id.to_i] = fetch_pnl(id)
      end
      out
    rescue StandardError => e
      Rails.logger.error("[RedisPnL] fetch_all error: #{e.message}") if defined?(Rails)
      {}
    end

    def health_check
      return { status: :error, message: 'redis not init' } unless @redis

      @redis.ping
      { status: :ok, message: 'ok' }
    rescue StandardError => e
      { status: :error, message: e.message }
    end

    def each_tracker_key(&)
      pattern = "#{REDIS_KEY_PREFIX}:*"
      @redis.scan_each(match: pattern) do |key|
        tracker_id = key.split(':').last
        yield(key, tracker_id.to_s)
      end
    end

    def purge_exited!
      active_ids = PositionTracker.active.pluck(:id).map(&:to_s)

      keys = @redis.keys('pnl:tracker:*')
      keys.each do |key|
        tracker_id = key.split(':').last
        @redis.del(key) unless active_ids.include?(tracker_id)
      end
    end

    # Remove all pnl/tick entries except those for the given tracker IDs
    def prune_except(allowed_ids)
      allowed_set = allowed_ids.map(&:to_s).to_set

      # PnL cache keys
      each_tracker_key do |key, tracker_id|
        unless allowed_set.include?(tracker_id.to_s)
          Rails.logger.warn("[RedisPnlCache] Pruning orphaned tracker_id=#{tracker_id}")
          clear_tracker(tracker_id)
        end
      end

      true
    end

    private

    def pnl_key(id)
      "#{REDIS_KEY_PREFIX}:#{id}"
    end
  end
end


# File: app/services/live/redis_tick_cache.rb
# frozen_string_literal: true

require 'singleton'

module Live
  class RedisTickCache
    include Singleton

    PREFIX = 'tick'

    # Store a tick as a hash under tick:<SEG>:<SID>
    # data is a hash of symbol/string keys -> values
    def store_tick(segment:, security_id:, data:)
      key = redis_key(segment, security_id)

      existing = fetch_tick(segment, security_id) || {}

      # Normalize both hashes to string keys for consistent storage/merging
      existing_str = stringify_keys(existing)
      incoming_str = stringify_keys(data)

      merged = existing_str.merge(incoming_str) do |field, old, new|
        if field.to_s == 'ltp'
          # prefer a positive new LTP, otherwise keep old
          new_f = numeric_to_f(new)
          old_f = numeric_to_f(old)
          new_f.positive? ? new_f : old_f
        else
          new.nil? ? old : new
        end
      end

      # hmset expects a flat array: key1, val1, key2, val2...
      args = merged.flat_map { |k, v| [k.to_s, v.to_s] }
      redis.hmset(key, *args)

      # return symbolized/casted form for convenience
      symbolize_and_cast(merged)
    rescue StandardError => e
      Rails.logger.error("[RedisTickCache] store_tick ERROR: #{e.class} - #{e.message}")
      {}
    end

    # Fetch a single tick as a hash with symbol keys and numeric casting
    def fetch_tick(segment, security_id)
      key = redis_key(segment, security_id)
      raw = redis.hgetall(key)
      return {} if raw.blank?

      symbolize_and_cast(raw)
    rescue StandardError => e
      Rails.logger.error("[RedisTickCache] fetch_tick ERROR: #{e.class} - #{e.message}")
      {}
    end

    # Fetch all tick keys: returns { "SEG:SID" => {..tick..} }
    def fetch_all
      out = {}
      redis.scan_each(match: "#{PREFIX}:*") do |key|
        raw = redis.hgetall(key)
        next if raw.blank?

        parts = key.split(':', 3) # ["tick", "SEG", "SID"]
        seg = parts[1]
        sid = parts[2]
        out["#{seg}:#{sid}"] = symbolize_and_cast(raw)
      end
      out
    rescue StandardError => e
      Rails.logger.error("[RedisTickCache] fetch_all ERROR: #{e.class} - #{e.message}")
      {}
    end

    # Clear all ticks
    def clear
      redis.scan_each(match: "#{PREFIX}:*") { |key| redis.del(key) }
      true
    rescue StandardError => e
      Rails.logger.error("[RedisTickCache] clear ERROR: #{e.class} - #{e.message}")
      false
    end

    def clear_tick(segment, security_id)
      redis.del(redis_key(segment, security_id))
      true
    rescue StandardError => e
      Rails.logger.error("[RedisTickCache] clear_tick ERROR: #{e.class} - #{e.message}")
      false
    end

    # Delete wrapper used elsewhere as class method
    def self.delete(segment, security_id)
      key = "tick:#{segment}:#{security_id}"
      Redis.new(url: ENV.fetch('REDIS_URL', 'redis://127.0.0.1:6379/0')).del(key)
      true
    rescue StandardError => e
      Rails.logger.error("[RedisTickCache] self.delete ERROR: #{e.class} - #{e.message}")
      false
    end

    # Prune stale ticks older than max_age seconds.
    # Keeps index feeds and protected keys (watchlist/active positions).
    def prune_stale(max_age: 60)
      cutoff = Time.current.to_i - max_age
      protected = protected_keys_set

      redis.scan_each(match: "#{PREFIX}:*") do |key|
        _, seg, sid = key.split(':', 3)
        composite = "#{seg}:#{sid}"

        # never prune index feeds
        if seg == 'IDX_I'
          # Skip silently - index feeds should never be pruned
          next
        end

        # keep tracked positions
        if Live::PositionIndex.instance.tracked?(seg, sid)
          # Skip silently - tracked positions should not be pruned
          next
        end

        # keep protected keys (watchlist/active)
        if protected.include?(composite)
          Rails.logger.debug { "[RedisTickCache] SKIP prune #{key} (protected)" }
          next
        end

        # check timestamp field if present
        data = redis.hgetall(key)
        ts_str = data['timestamp'] || data[:timestamp]
        if ts_str.nil? || ts_str.to_s.strip.empty?
          # no timestamp => treat as stale and remove
          Rails.logger.warn("[RedisTickCache] Pruning #{key} (missing timestamp)")
          redis.del(key)
          next
        end

        ts = ts_str.to_i
        age = Time.current.to_i - ts
        if ts < cutoff
          Rails.logger.warn("[RedisTickCache] Pruning #{key} (stale; age=#{age}s > #{max_age}s)")
          redis.del(key)
          next
        end

        Rails.logger.debug { "[RedisTickCache] KEEP #{key} (fresh; age=#{age}s)" }
      rescue StandardError => e
        Rails.logger.error("[RedisTickCache] prune_stale loop ERROR key=#{key} - #{e.class}: #{e.message}")
        next
      end

      true
    rescue StandardError => e
      Rails.logger.error("[RedisTickCache] prune_stale ERROR: #{e.class} - #{e.message}")
      false
    end

    # Build set of protected keys: index, watchlist, active positions
    def protected_keys_set
      set = Set.new

      # 1. Index feeds (existing tick keys per segment)
      redis.scan_each(match: 'tick:IDX_I:*') do |key|
        _, s, sid = key.split(':', 3)
        set << "#{s}:#{sid}" if s && sid
      end

      # 2. Watchlist items (AlgoConfig may be nil or not an array)
      begin
        watchlist = Array(AlgoConfig.fetch[:watchlist])
        watchlist.each do |item|
          seg = item && (item[:segment] || item['segment'])
          sid = item && (item[:security_id] || item['security_id'])
          set << "#{seg}:#{sid}" if seg && sid
        end
      rescue StandardError
        # ignore config errors
      end

      # 3. Active positions (PositionIndex returns "SEG:SID" strings)
      begin
        Live::PositionIndex.instance.all_keys.each do |k|
          set << k.to_s
        end
      rescue StandardError
        # if PositionIndex not available, ignore
      end

      set
    end

    private

    def symbolize_and_cast(raw)
      # raw is a hash with string keys and string values
      raw.each_with_object({}) do |(k, v), acc|
        key = k.to_s.strip
        val = v
        acc[key.to_sym] = numeric?(val) ? numeric_to_f(val) : val
      end
    end

    def numeric?(value)
      value.to_s =~ /\A-?\d+(\.\d+)?\z/
    end

    def numeric_to_f(value)
      Float(value)
    rescue StandardError
      0.0
    end

    def stringify_keys(hash)
      hash.transform_keys(&:to_s)
    end

    def redis_key(segment, security_id)
      "#{PREFIX}:#{segment}:#{security_id}"
    end

    def redis
      @redis ||= Redis.new(url: ENV.fetch('REDIS_URL', 'redis://127.0.0.1:6379/0'))
    end
  end
end


# File: app/services/live/risk_manager_service.rb
# frozen_string_literal: true

require 'bigdecimal'
require 'singleton'
require 'ostruct'

module Live
  # Responsible for monitoring active PositionTracker entries, keeping PnL up-to-date in Redis,
  # and enforcing exits according to configured risk rules.
  #
  # Behaviour:
  # - If an external ExitEngine is provided (recommended), RiskManagerService will NOT place exits itself.
  #   Instead ExitEngine calls the enforcement methods and RiskManagerService supplies helper functions.
  # - If no external ExitEngine is provided, RiskManagerService will execute exits itself (backwards compatibility).
  class RiskManagerService
    LOOP_INTERVAL = 5
    API_CALL_STAGGER_SECONDS = 1.0

    def initialize(exit_engine: nil)
      @exit_engine = exit_engine
      @mutex = Mutex.new
      @running = false
      @thread = nil

      # Watchdog ensures service thread is restarted if it dies (lightweight)
      @watchdog_thread = Thread.new do
        loop do
          unless @thread&.alive?
            Rails.logger.warn('[RiskManagerService] Watchdog detected dead thread — restarting...')
            start
          end
          sleep 10
        end
      end
    end

    # Start monitoring loop (non-blocking)
    def start
      return if @running

      @running = true

      @thread = Thread.new do
        Thread.current.name = 'risk-manager'
        last_paper_pnl_update = Time.current

        loop do
          break unless @running

          begin
            monitor_loop(last_paper_pnl_update)
            # update timestamp after paper update occurred inside monitor_loop
            last_paper_pnl_update = Time.current
          rescue StandardError => e
            Rails.logger.error("[RiskManagerService] monitor_loop crashed: #{e.class} - #{e.message}\n#{e.backtrace.first(8).join("\n")}")
          end
          sleep LOOP_INTERVAL
        end
      end
    end

    def stop
      @running = false
      @thread&.kill
      @thread = nil
    end

    def running?
      @running
    end

    # Lightweight risk evaluation helper (unchanged semantics)
    def evaluate_signal_risk(signal_data)
      confidence = signal_data[:confidence] || 0.0
      entry_price = signal_data[:entry_price]
      stop_loss = signal_data[:stop_loss]

      risk_level =
        case confidence
        when 0.8..1.0 then :low
        when 0.6...0.8 then :medium
        else :high
        end

      max_position_size =
        case risk_level
        when :low then 100
        when :medium then 50
        else 25
        end

      recommended_stop_loss = stop_loss || (entry_price * 0.98)

      { risk_level: risk_level, max_position_size: max_position_size, recommended_stop_loss: recommended_stop_loss }
    end

    private

    # Central monitoring loop: keep PnL and caches fresh.
    # DO NOT perform exit dispatching here when an external ExitEngine exists — ExitEngine will call enforcement methods.
    def monitor_loop(last_paper_pnl_update)
      # Keep Redis/DB PnL fresh
      update_paper_positions_pnl_if_due(last_paper_pnl_update)
      ensure_all_positions_in_redis

      # Backwards-compatible enforcement: if there is no external ExitEngine, run enforcement here
      return unless @exit_engine.nil?

      enforce_hard_limits(exit_engine: self)
      enforce_trailing_stops(exit_engine: self)
      enforce_time_based_exit(exit_engine: self)
    end

    # Called by external ExitEngine or internally (when used standalone).
    # Exits triggered by enforcement logic call this method on the supplied exit_engine.
    # This method implements legacy behaviour for self-managed exits.
    def execute_exit(tracker, reason)
      # This method implements the fallback exit path when RiskManagerService is self-executing.
      # Prefer using external ExitEngine with Orders::OrderRouter for real deployments.
      Rails.logger.info("[RiskManager] execute_exit invoked for #{tracker.order_no} reason=#{reason}")

      begin
        store_exit_reason(tracker, reason)
        exit_result = exit_position(nil, tracker)
        exit_successful = exit_result.is_a?(Hash) ? exit_result[:success] : exit_result
        exit_price = exit_result.is_a?(Hash) ? exit_result[:exit_price] : nil

        if exit_successful
          tracker.mark_exited!(exit_price: exit_price, exit_reason: reason)
          Rails.logger.info("[RiskManager] Successfully exited #{tracker.order_no} (#{tracker.id}) via internal executor")
          true
        else
          Rails.logger.error("[RiskManager] Failed to exit #{tracker.order_no} via internal executor")
          false
        end
      rescue StandardError => e
        Rails.logger.error("[RiskManager] execute_exit failed for #{tracker.order_no}: #{e.class} - #{e.message}")
        false
      end
    end

    # Enforcement methods always accept an exit_engine keyword. They do not fetch positions from caller.
    # If exit_engine is provided, they will delegate the actual exit to it. Otherwise they call internal execute_exit.
    public

    def enforce_trailing_stops(exit_engine:)
      risk = risk_config
      drop_threshold = begin
        BigDecimal(risk[:exit_drop_pct].to_s)
      rescue StandardError
        BigDecimal(0)
      end

      PositionTracker.active.find_each do |tracker|
        snap = pnl_snapshot(tracker)
        next unless snap

        pnl = snap[:pnl]
        hwm = snap[:hwm_pnl]
        next if hwm.nil? || hwm.zero?

        drop_pct = (hwm - pnl) / hwm
        if drop_pct >= drop_threshold
          reason = "TRAILING STOP drop=#{drop_pct.round(3)}"
          dispatch_exit(exit_engine, tracker, reason)
        end
      rescue StandardError => e
        Rails.logger.error("[RiskManager] enforce_trailing_stops error for tracker=#{tracker.id}: #{e.class} - #{e.message}")
      end
    end

    def enforce_hard_limits(exit_engine:)
      risk = risk_config
      sl_pct = begin
        BigDecimal(risk[:sl_pct].to_s)
      rescue StandardError
        BigDecimal(0)
      end
      tp_pct = begin
        BigDecimal(risk[:tp_pct].to_s)
      rescue StandardError
        BigDecimal(0)
      end

      PositionTracker.active.find_each do |tracker|
        snapshot = pnl_snapshot(tracker)
        next unless snapshot

        pnl_pct = snapshot[:pnl_pct]
        next if pnl_pct.nil?

        if pnl_pct <= -sl_pct
          reason = "SL HIT #{(pnl_pct * 100).round(2)}%"
          dispatch_exit(exit_engine, tracker, reason)
          next
        end

        if pnl_pct >= tp_pct
          reason = "TP HIT #{(pnl_pct * 100).round(2)}%"
          dispatch_exit(exit_engine, tracker, reason)
          next
        end
      rescue StandardError => e
        Rails.logger.error("[RiskManager] enforce_hard_limits error for tracker=#{tracker.id}: #{e.class} - #{e.message}")
      end
    end

    def enforce_time_based_exit(exit_engine:)
      risk = risk_config
      exit_time = parse_time_hhmm(risk[:time_exit_hhmm] || '15:20')
      return unless exit_time

      now = Time.current
      return unless now >= exit_time

      market_close_time = parse_time_hhmm(risk[:market_close_hhmm] || '15:30')
      return if market_close_time && now >= market_close_time

      PositionTracker.active.find_each do |tracker|
        tracker.hydrate_pnl_from_cache!
        if tracker.last_pnl_rupees.present? && tracker.last_pnl_rupees.positive?
          min_profit = begin
            BigDecimal((risk[:min_profit_rupees] || 0).to_s)
          rescue StandardError
            BigDecimal(0)
          end
          if min_profit.positive? && tracker.last_pnl_rupees < min_profit
            Rails.logger.info("[RiskManager] Time-based exit skipped for #{tracker.order_no} - PnL < min_profit")
            next
          end
        end

        reason = "time-based exit (#{exit_time.strftime('%H:%M')})"
        dispatch_exit(exit_engine, tracker, reason)
      rescue StandardError => e
        Rails.logger.error("[RiskManager] enforce_time_based_exit error for tracker=#{tracker.id}: #{e.class} - #{e.message}")
      end
    end

    private

    # Helper that centralizes exit dispatching logic.
    # If exit_engine is an object responding to execute_exit, delegate to it.
    # If exit_engine == self (or nil) we fallback to internal execute_exit implementation.
    def dispatch_exit(exit_engine, tracker, reason)
      if exit_engine && exit_engine.respond_to?(:execute_exit) && !exit_engine.equal?(self)
        begin
          exit_engine.execute_exit(tracker, reason)
        rescue StandardError => e
          Rails.logger.error("[RiskManager] external exit_engine failed for #{tracker.order_no}: #{e.class} - #{e.message}")
        end
      else
        # self-managed execution (backwards compatibility)
        execute_exit(tracker, reason)
      end
    end

    # --- Position/market helpers ---

    # Fetch live broker positions keyed by security_id (string). Returns {} on paper mode or failure.
    def fetch_positions_indexed
      return {} if paper_trading_enabled?

      positions = DhanHQ::Models::Position.active.each_with_object({}) do |position, map|
        security_id = position.respond_to?(:security_id) ? position.security_id : position[:security_id]
        map[security_id.to_s] = position if security_id
      end
      begin
        Live::FeedHealthService.instance.mark_success!(:positions)
      rescue StandardError
        nil
      end
      positions
    rescue StandardError => e
      Rails.logger.error("[RiskManager] fetch_positions_indexed failed: #{e.class} - #{e.message}")
      begin
        Live::FeedHealthService.instance.mark_failure!(:positions, error: e)
      rescue StandardError
        nil
      end
      {}
    end

    def paper_trading_enabled?
      AlgoConfig.fetch.dig(:paper_trading, :enabled) == true
    rescue StandardError
      false
    end

    # Returns a cached pnl snapshot for tracker (expects Redis cache to be maintained elsewhere)
    def pnl_snapshot(tracker)
      Live::RedisPnlCache.instance.fetch_pnl(tracker.id)
    rescue StandardError => e
      Rails.logger.error("[RiskManager] pnl_snapshot error for #{tracker.id}: #{e.class} - #{e.message}")
      nil
    end

    def update_paper_positions_pnl_if_due(last_update_time)
      # if last_update_time is nil or stale, update now
      return unless Time.current - (last_update_time || Time.zone.at(0)) >= 1.minute

      update_paper_positions_pnl
    rescue StandardError => e
      Rails.logger.error("[RiskManager] update_paper_positions_pnl_if_due failed: #{e.class} - #{e.message}")
    end

    # Update PnL for all paper trackers and cache in Redis (same semantics as before)
    def update_paper_positions_pnl
      paper_trackers = PositionTracker.paper.active.includes(:instrument).to_a
      return if paper_trackers.empty?

      paper_trackers.each do |tracker|
        next unless tracker.entry_price.present? && tracker.quantity.present?

        ltp = get_paper_ltp(tracker)
        unless ltp
          Rails.logger.debug { "[RiskManager] No LTP for paper tracker #{tracker.order_no}" }
          next
        end

        entry = BigDecimal(tracker.entry_price.to_s)
        exit_price = BigDecimal(ltp.to_s)
        qty = tracker.quantity.to_i
        pnl = (exit_price - entry) * qty
        pnl_pct = entry.positive? ? ((exit_price - entry) / entry) : nil

        hwm = tracker.high_water_mark_pnl || BigDecimal(0)
        hwm = [hwm, pnl].max

        tracker.update!(
          last_pnl_rupees: pnl,
          last_pnl_pct: pnl_pct ? (pnl_pct * 100).round(2) : nil,
          high_water_mark_pnl: hwm
        )

        update_pnl_in_redis(tracker, pnl, pnl_pct, ltp)
      rescue StandardError => e
        Rails.logger.error("[RiskManager] update_paper_positions_pnl failed for #{tracker.order_no}: #{e.class} - #{e.message}")
      end

      Rails.logger.info('[RiskManager] Paper PnL update completed')
    end

    # Ensure every active PositionTracker has an entry in Redis PnL cache (best-effort)
    # Throttled to avoid excessive queries - only runs every 5 seconds
    def ensure_all_positions_in_redis
      @last_ensure_all ||= Time.zone.at(0)
      return if Time.current - @last_ensure_all < 5.seconds

      trackers = PositionTracker.active.includes(:instrument).to_a
      return if trackers.empty?

      @last_ensure_all = Time.current

      positions = fetch_positions_indexed

      trackers.each do |tracker|
        redis_pnl = Live::RedisPnlCache.instance.fetch_pnl(tracker.id)
        next if redis_pnl && (Time.current.to_i - (redis_pnl[:timestamp] || 0)) < 10

        position = positions[tracker.security_id.to_s]
        tracker.hydrate_pnl_from_cache!

        ltp = if tracker.paper?
                get_paper_ltp(tracker)
              else
                current_ltp(tracker, position)
              end

        next unless ltp

        pnl = compute_pnl(tracker, position, ltp)
        next unless pnl

        pnl_pct = compute_pnl_pct(tracker, ltp, position)
        update_pnl_in_redis(tracker, pnl, pnl_pct, ltp)
      rescue StandardError => e
        Rails.logger.error("[RiskManager] ensure_all_positions_in_redis failed for #{tracker.order_no}: #{e.class} - #{e.message}")
      end
    end

    # Compute current LTP (will try cache, API, tradable, etc.)
    def current_ltp(tracker, position = nil)
      return get_paper_ltp(tracker) if tracker.paper?

      if position.respond_to?(:exchange_segment) && position.exchange_segment == 'NSE_FNO'
        begin
          response = DhanHQ::Models::MarketFeed.ltp({ 'NSE_FNO' => [tracker.security_id.to_i] })
          if response['status'] == 'success'
            option_data = response.dig('data', 'NSE_FNO', tracker.security_id.to_s)
            if option_data && option_data['last_price']
              ltp = BigDecimal(option_data['last_price'].to_s)
              begin
                Live::RedisPnlCache.instance.store_tick(segment: 'NSE_FNO', security_id: tracker.security_id, ltp: ltp,
                                                        timestamp: Time.current)
              rescue StandardError
                nil
              end
              return ltp
            end
          end
        rescue StandardError => e
          Rails.logger.error("[RiskManager] current_ltp(fetch option) failed for #{tracker.order_no}: #{e.class} - #{e.message}")
        end
      end

      tradable = tracker.tradable
      return tradable.ltp if tradable && tradable.ltp

      segment = tracker.segment.presence || tracker.instrument&.exchange_segment
      cached = Live::TickCache.ltp(segment, tracker.security_id)
      return BigDecimal(cached.to_s) if cached

      fetch_ltp(position, tracker)
    end

    def get_paper_ltp(tracker)
      segment = tracker.segment.presence || tracker.watchable&.exchange_segment || tracker.instrument&.exchange_segment
      security_id = tracker.security_id
      return nil unless segment.present? && security_id.present?

      cached = Live::TickCache.ltp(segment, security_id)
      return BigDecimal(cached.to_s) if cached

      tick_data = begin
        Live::TickCache.fetch(segment, security_id)
      rescue StandardError
        nil
      end
      return BigDecimal(tick_data[:ltp].to_s) if tick_data&.dig(:ltp)

      tradable = tracker.tradable
      if tradable
        ltp = begin
          tradable.fetch_ltp_from_api_for_segment(segment: segment, security_id: security_id)
        rescue StandardError
          nil
        end
        return BigDecimal(ltp.to_s) if ltp
      end

      begin
        response = DhanHQ::Models::MarketFeed.ltp({ segment => [security_id.to_i] })
        if response['status'] == 'success'
          option_data = response.dig('data', segment, security_id.to_s)
          return BigDecimal(option_data['last_price'].to_s) if option_data && option_data['last_price']
        end
      rescue StandardError => e
        Rails.logger.error("[RiskManager] get_paper_ltp API error for #{tracker.order_no}: #{e.class} - #{e.message}")
      end

      nil
    end

    def fetch_ltp(position, tracker)
      segment = if position.respond_to?(:exchange_segment) then position.exchange_segment
                elsif position.is_a?(Hash) then position[:exchange_segment]
                end
      segment ||= tracker.instrument&.exchange_segment
      cached = begin
        Live::TickCache.ltp(segment, tracker.security_id)
      rescue StandardError
        nil
      end
      return BigDecimal(cached.to_s) if cached

      nil
    end

    def compute_pnl(tracker, position, ltp)
      if position.respond_to?(:net_qty) && position.respond_to?(:cost_price)
        quantity = position.net_qty.to_i
        cost_price = position.cost_price.to_f
        return nil if quantity.zero? || cost_price.zero?

        (ltp - BigDecimal(cost_price.to_s)) * quantity
      else
        quantity = tracker.quantity.to_i
        if quantity.zero? && position
          quantity = position.respond_to?(:quantity) ? position.quantity.to_i : (position[:quantity] || 0).to_i
        end
        return nil if quantity.zero?

        entry_price = tracker.entry_price || tracker.avg_price
        return nil if entry_price.blank?

        (ltp - BigDecimal(entry_price.to_s)) * quantity
      end
    rescue StandardError => e
      Rails.logger.error("[RiskManager] compute_pnl failed for #{tracker.id}: #{e.class} - #{e.message}")
      nil
    end

    def compute_pnl_pct(tracker, ltp, position = nil)
      if position&.respond_to?(:cost_price)
        cost_price = position.cost_price.to_f
        return nil if cost_price.zero?

        (ltp - BigDecimal(cost_price.to_s)) / BigDecimal(cost_price.to_s)
      else
        entry_price = tracker.entry_price || tracker.avg_price
        return nil if entry_price.blank?

        (ltp - BigDecimal(entry_price.to_s)) / BigDecimal(entry_price.to_s)
      end
    rescue StandardError
      nil
    end

    def update_pnl_in_redis(tracker, pnl, pnl_pct, ltp)
      return unless pnl && ltp && ltp.to_f.positive?

      Live::PnlUpdaterService.instance.cache_intermediate_pnl(
        tracker_id: tracker.id,
        pnl: pnl,
        pnl_pct: pnl_pct,
        ltp: ltp,
        hwm: tracker.high_water_mark_pnl
      )
    rescue StandardError => e
      Rails.logger.error("[RiskManager] update_pnl_in_redis failed for #{tracker.order_no}: #{e.class} - #{e.message}")
    end

    # --- Internal exit logic (fallback when no external ExitEngine provided) ---
    # Attempts to exit a tracker:
    # - For paper: update DB fields and return success
    # - For live: try Orders gateway (Orders.config.flat_position) or DhanHQ position methods
    def exit_position(_position, tracker)
      if tracker.paper?
        current_ltp_value = get_paper_ltp(tracker)
        unless current_ltp_value
          Rails.logger.warn("[RiskManager] Cannot get LTP for paper exit #{tracker.order_no}")
          return { success: false, exit_price: nil }
        end

        exit_price = BigDecimal(current_ltp_value.to_s)
        entry = begin
          BigDecimal(tracker.entry_price.to_s)
        rescue StandardError
          nil
        end
        qty = tracker.quantity.to_i
        pnl = entry ? (exit_price - entry) * qty : nil
        pnl_pct = entry ? ((exit_price - entry) / entry) * 100 : nil

        hwm = tracker.high_water_mark_pnl || BigDecimal(0)
        hwm = [hwm, pnl].max if pnl

        tracker.update!(
          last_pnl_rupees: pnl,
          last_pnl_pct: pnl_pct,
          high_water_mark_pnl: hwm,
          avg_price: exit_price
        )

        Rails.logger.info("[RiskManager] Paper exit simulated for #{tracker.order_no}: exit_price=#{exit_price}")
        return { success: true, exit_price: exit_price }
      end

      # Live exit flow: try Orders.config flat_position (recommended) -> DhanHQ SDK fallbacks
      begin
        segment = tracker.segment.presence || tracker.tradable&.exchange_segment || tracker.instrument&.exchange_segment
        unless segment.present?
          Rails.logger.error("[RiskManager] Cannot exit #{tracker.order_no}: no segment available")
          return { success: false, exit_price: nil }
        end

        if defined?(Orders) && Orders.respond_to?(:config) && Orders.config.respond_to?(:flat_position)
          order = Orders.config.flat_position(segment: segment, security_id: tracker.security_id)
          if order
            exit_price = current_ltp(tracker)
            exit_price = BigDecimal(exit_price.to_s) if exit_price
            return { success: true, exit_price: exit_price }
          end
        end

        # Fallback: try DhanHQ position convenience methods
        positions = fetch_positions_indexed
        position = positions[tracker.security_id.to_s]
        if position && position.respond_to?(:exit!)
          ok = position.exit!
          exit_price = begin
            current_ltp(tracker)
          rescue StandardError
            nil
          end
          return { success: ok, exit_price: exit_price }
        end

        Rails.logger.error("[RiskManager] Live exit failed for #{tracker.order_no} - no exit mechanism worked")
        { success: false, exit_price: nil }
      rescue StandardError => e
        Rails.logger.error("[RiskManager] exit_position error for #{tracker.order_no}: #{e.class} - #{e.message}")
        { success: false, exit_price: nil }
      end
    end

    # Persist reason metadata
    def store_exit_reason(tracker, reason)
      metadata = tracker.meta.is_a?(Hash) ? tracker.meta : {}
      tracker.update!(meta: metadata.merge('exit_reason' => reason, 'exit_triggered_at' => Time.current))
    rescue StandardError => e
      Rails.logger.warn("[RiskManager] store_exit_reason failed for #{tracker.order_no}: #{e.class} - #{e.message}")
    end

    def parse_time_hhmm(value)
      return nil if value.blank?

      Time.zone.parse(value.to_s)
    rescue StandardError
      Rails.logger.warn("[RiskManager] Invalid time format provided: #{value}")
      nil
    end

    def risk_config
      raw = begin
        AlgoConfig.fetch[:risk]
      rescue StandardError
        {}
      end
      return {} if raw.blank?

      cfg = raw.dup
      cfg[:stop_loss_pct] = raw[:stop_loss_pct] || raw[:sl_pct]
      cfg[:take_profit_pct] = raw[:take_profit_pct] || raw[:tp_pct]
      cfg[:sl_pct] = cfg[:stop_loss_pct]
      cfg[:tp_pct] = cfg[:take_profit_pct]
      cfg[:breakeven_after_gain] = raw.key?(:breakeven_after_gain) ? raw[:breakeven_after_gain] : 0
      cfg[:trail_step_pct] = raw[:trail_step_pct] if raw.key?(:trail_step_pct)
      cfg[:exit_drop_pct] = raw[:exit_drop_pct] if raw.key?(:exit_drop_pct)
      cfg[:time_exit_hhmm] = raw[:time_exit_hhmm] if raw.key?(:time_exit_hhmm)
      cfg[:market_close_hhmm] = raw[:market_close_hhmm] if raw.key?(:market_close_hhmm)
      cfg[:min_profit_rupees] = raw[:min_profit_rupees] if raw.key?(:min_profit_rupees)
      cfg
    rescue StandardError => e
      Rails.logger.error("[RiskManager] risk_config error: #{e.class} - #{e.message}")
      {}
    end

    def cancel_remote_order(order_id)
      order = DhanHQ::Models::Order.find(order_id)
      order.cancel
    rescue DhanHQ::Error => e
      Rails.logger.error("[RiskManager] cancel_remote_order DhanHQ error: #{e.message}")
      raise
    rescue StandardError => e
      Rails.logger.error("[RiskManager] cancel_remote_order unexpected error: #{e.class} - #{e.message}")
      raise
    end

    def pct_value(value)
      BigDecimal(value.to_s)
    rescue StandardError
      BigDecimal(0)
    end
  end
end


# File: app/services/live/tick_cache.rb
# frozen_string_literal: true

module Live
  class TickCache
    def self.put(tick)
      ::TickCache.instance.put(tick)
    end

    def self.get(segment, security_id)
      ::TickCache.instance.fetch(segment, security_id)
    end

    def self.fetch(segment, security_id)
      get(segment, security_id)
    end

    def self.ltp(segment, security_id)
      ::TickCache.instance.ltp(segment, security_id)
    end

    def self.all
      ::TickCache.instance.all
    end

    def self.delete(segment, security_id)
      ::TickCache.instance.delete(segment, security_id)
    end
  end
end


# File: app/services/live/ws_hub.rb
# frozen_string_literal: true

require 'singleton'

module Live
  class WsHub
    include Singleton

    def subscribe(seg:, sid:)
      delegate.subscribe(segment: seg, security_id: sid)
    end

    def unsubscribe(seg:, sid:)
      return true unless delegate.running?

      delegate.unsubscribe(segment: seg, security_id: sid)
    end

    delegate :running?, to: :delegate

    private

    def delegate
      Live::MarketFeedHub.instance
    end
  end
end


# File: app/services/options/chain_analyzer.rb
# frozen_string_literal: true

require 'bigdecimal'
require 'active_support/core_ext/hash'
require 'active_support/core_ext/object/blank'

module Options
  class ChainAnalyzer
    DEFAULT_DIRECTION = :bullish

    def initialize(index:, data_provider:, config: {})
      @index_cfg = normalize_index(index)
      @provider = data_provider
      @config = config || {}
    end

    def select_candidates(limit: 2, direction: DEFAULT_DIRECTION)
      picks = self.class.pick_strikes(
        index_cfg: @index_cfg,
        direction: direction.presence&.to_sym || DEFAULT_DIRECTION
      )
      return [] unless picks.present?

      picks.first([limit.to_i, 1].max).map { |pick| decorate_pick(pick) }
    rescue StandardError => e
      Rails.logger.error("[Options::ChainAnalyzer] select_candidates failed: #{e.class} - #{e.message}")
      []
    end

    private

    def normalize_index(index)
      return index.deep_symbolize_keys if index.respond_to?(:deep_symbolize_keys)

      Array(index).each_with_object({}) do |(k, v), acc|
        acc[k.to_sym] = v
      end
    end

    def decorate_pick(pick)
      pick.merge(
        index_key: @index_cfg[:key],
        underlying_spot: fetch_spot,
        analyzer_config: @config.presence
      ).compact
    end

    def fetch_spot
      return unless @provider.respond_to?(:underlying_spot)

      @provider.underlying_spot(@index_cfg[:key])
    rescue StandardError => e
      Rails.logger.debug("[Options::ChainAnalyzer] Spot fetch failed: #{e.class} - #{e.message}")
      nil
    end

    class << self
      def pick_strikes(index_cfg:, direction:)
        # Rails.logger.info("[Options] Starting strike selection for #{index_cfg[:key]} #{direction}")

        # Get cached index instrument
        instrument = IndexInstrumentCache.instance.get_or_fetch(index_cfg)
        unless instrument
          # Rails.logger.warn("[Options] No instrument found for #{index_cfg[:key]}")
          return []
        end

        # Rails.logger.debug { "[Options] Using instrument: #{instrument.symbol_name}" }

        # Use instrument's existing methods to get expiry list and option chain
        expiry_list = instrument.expiry_list
        unless expiry_list&.any?
          # Rails.logger.warn("[Options] No expiry list available for #{index_cfg[:key]}")
          return []
        end

        # Rails.logger.debug { "[Options] Available expiries: #{expiry_list}" }

        # Get the next upcoming expiry
        expiry_date = find_next_expiry(expiry_list)
        unless expiry_date
          # Rails.logger.warn("[Options] Could not determine next expiry for #{index_cfg[:key]}")
          return []
        end

        # Rails.logger.info("[Options] Using expiry: #{expiry_date}")

        # Fetch option chain using instrument's method
        chain_data = begin
          instrument.fetch_option_chain(expiry_date)
        rescue StandardError
          # Rails.logger.warn("[Options] Could not determine next expiry for #{index_cfg[:key]} #{expiry_date}: #{e.message}")
          nil
        end
        unless chain_data
          # Rails.logger.warn("[Options] No option chain data for #{index_cfg[:key]} #{expiry_date}")
          return []
        end

        # Rails.logger.debug { "[Options] Chain data structure: #{chain_data.keys}" }
        # Rails.logger.debug { "[Options] OC data size: #{chain_data[:oc]&.size || 'nil'}" }

        # Debug: Show sample of raw option data
        if chain_data[:oc]&.any?
          sample_strike = chain_data[:oc].keys.first
          chain_data[:oc][sample_strike]
          # Rails.logger.debug { "[Options] Sample strike #{sample_strike} data: #{sample_data}" }
          # Rails.logger.debug { "[Options] Sample PE data: #{sample_data['pe']}" } if sample_data['pe']
        end

        atm_price = chain_data[:last_price]
        unless atm_price
          # Rails.logger.warn("[Options] No ATM price available for #{index_cfg[:key]}")
          return []
        end

        # Rails.logger.info("[Options] ATM price: #{atm_price}")

        side = direction == :bullish ? :ce : :pe
        # For buying options, focus on ATM and ATM+1 strikes only
        # This prevents selecting expensive ITM options
        # Rails.logger.debug { "[Options] Looking for #{side} options at ATM and ATM#{[:ce, 'ce'].include?(side) ? '+1' : '-1'} strikes only" }

        legs = filter_and_rank_from_instrument_data(chain_data[:oc], atm: atm_price, side: side, index_cfg: index_cfg,
                                                                     expiry_date: expiry_date, instrument: instrument)
        # Rails.logger.info("[Options] Found #{legs.size} qualifying #{side} options for #{index_cfg[:key]}")

        if legs.any?
          # Rails.logger.info("[Options] Top picks: #{legs.first(2).map { |l| "#{l[:symbol]}@#{l[:strike]} (Score:#{l[:score]&.round(1)}, IV:#{l[:iv]}, OI:#{l[:oi]})" }.join(', ')}")
        end

        legs.first(2).map do |leg|
          leg.slice(:segment, :security_id, :symbol, :ltp, :iv, :oi, :spread, :lot_size, :derivative_id)
        end
      end

      def find_next_expiry(expiry_list)
        return nil unless expiry_list.respond_to?(:each)

        today = Time.zone.today

        parsed = expiry_list.compact.filter_map do |raw|
          case raw
          when Date
            raw
          when Time, DateTime, ActiveSupport::TimeWithZone
            raw.to_date
          when String
            begin
              Date.parse(raw)
            rescue ArgumentError
              nil
            end
          end
        end

        next_expiry = parsed.select { |date| date >= today }.min
        next_expiry&.strftime('%Y-%m-%d')
      end

      def filter_and_rank_from_instrument_data(option_chain_data, atm:, side:, index_cfg:, expiry_date:, instrument:)
        # Force reload - debugging index_cfg scope issue
        return [] unless option_chain_data

        # Rails.logger.debug { "[Options] Method called with index_cfg: #{index_cfg[:key]}, expiry_date: #{expiry_date}" }

        # Rails.logger.debug { "[Options] Processing #{option_chain_data.size} strikes for #{side} options" }

        # Calculate strike interval dynamically from available strikes
        strikes = option_chain_data.keys.map(&:to_f).sort
        oc_strikes = strikes # Make strikes available for ATM range calculation

        strike_interval = if strikes.size >= 2
                            strikes[1] - strikes[0]
                          else
                            50 # fallback
                          end

        atm_strike = (atm / strike_interval).round * strike_interval

        # Calculate dynamic ATM range based on volatility
        # For now, we'll use a default IV rank of 0.5 (medium volatility)
        # TODO: Integrate with actual IV rank calculation
        iv_rank = 0.5 # Default to medium volatility
        atm_range_percent = atm_range_pct(iv_rank)

        # Rails.logger.debug { "[Options] SPOT: #{atm}, Strike interval: #{strike_interval}, ATM strike: #{atm_strike}" }
        # Rails.logger.debug { "[Options] IV Rank: #{iv_rank}, ATM range: #{atm_range_percent * 100}% (#{atm_range_points.round(2)} points)" }

        # For buying options, focus on ATM and nearby strikes only (+-1,2,3 steps)
        # This prevents selecting expensive ITM options or far OTM options
        target_strikes = if [:ce, 'ce'].include?(side)
                           # CE: ATM, ATM+1, ATM+2, ATM+3 (OTM calls)
                           [atm_strike, atm_strike + strike_interval, atm_strike + (2 * strike_interval),
                            atm_strike + (3 * strike_interval)]
                             .select do |s|
                             oc_strikes.include?(s)
                           end
                             .first(3) # Limit to top 3 strikes
                         else
                           # PE: ATM, ATM-1, ATM-2, ATM-3 (OTM puts)
                           [atm_strike, atm_strike - strike_interval, atm_strike - (2 * strike_interval),
                            atm_strike - (3 * strike_interval)]
                             .select do |s|
                             oc_strikes.include?(s)
                           end
                             .first(3) # Limit to top 3 strikes
                         end

        # Rails.logger.debug { "[Options] Target strikes for #{side}: #{target_strikes}" }

        # Log strike selection guidance
        log_strike_selection_guidance(side, atm, atm_strike, target_strikes, iv_rank, atm_range_percent,
                                      strike_interval)

        min_iv = AlgoConfig.fetch.dig(:option_chain, :min_iv).to_f
        max_iv = AlgoConfig.fetch.dig(:option_chain, :max_iv).to_f
        min_oi = AlgoConfig.fetch.dig(:option_chain, :min_oi).to_i
        max_spread_pct = AlgoConfig.fetch.dig(:option_chain, :max_spread_pct).to_f

        min_delta = min_delta_now
        # Rails.logger.debug { "[Options] Filter criteria: IV(#{min_iv}-#{max_iv}), OI(>=#{min_oi}), Spread(<=#{max_spread_pct}%), Delta(>=#{min_delta})" }

        legs = []
        rejected_count = 0

        option_chain_data.each do |strike_str, strike_data|
          strike = strike_str.to_f

          # For buying options, only consider target strikes (ATM±1 based on direction)
          # This prevents selecting expensive ITM options
          unless target_strikes.include?(strike)
            rejected_count += 1
            next
          end

          option_data = strike_data[side.to_s]
          unless option_data
            rejected_count += 1
            next
          end

          # Debug: Show available fields for first few strikes
          # Rails.logger.debug { "[Options] Available fields for #{side}: #{option_data.keys}" } if rejected_count < 3

          ltp = option_data['last_price']&.to_f
          iv = option_data['implied_volatility']&.to_f
          oi = option_data['oi']&.to_i
          bid = option_data['top_bid_price']&.to_f
          ask = option_data['top_ask_price']&.to_f

          if strike == atm_strike
            'ATM'
          elsif [:ce, 'ce'].include?(side)
            strike_diff = (strike - atm_strike) / strike_interval
            case strike_diff
            when 1
              'ATM+1'
            when 2
              'ATM+2'
            else
              strike_diff == 3 ? 'ATM+3' : 'OTHER'
            end
          else
            strike_diff = (atm_strike - strike) / strike_interval
            case strike_diff
            when 1
              'ATM-1'
            when 2
              'ATM-2'
            else
              strike_diff == 3 ? 'ATM-3' : 'OTHER'
            end
          end
          # Rails.logger.debug { "[Options] Strike #{strike} (#{strike_type}): LTP=#{ltp}, IV=#{iv}, OI=#{oi}, Bid=#{bid}, Ask=#{ask}" }

          # Check LTP
          unless ltp&.positive?
            rejected_count += 1
            # Rails.logger.debug { "[Options] Rejected #{strike}: Invalid LTP" }
            next
          end

          # Check IV with relaxed thresholds for ATM and ATM-1 strikes
          # ATM strikes often have lower IV but are critical for trade entry
          iv_threshold = if strike == atm_strike
                           # ATM: Allow lower IV (minimum 5% instead of default min_iv)
                           [5.0, min_iv * 0.6].max
                         elsif (strike - atm_strike).abs <= strike_interval
                           # ATM±1: Slightly relaxed IV threshold (80% of min_iv)
                           [7.0, min_iv * 0.8].max
                         else
                           # ATM-2 and beyond: Use strict IV threshold
                           min_iv
                         end

          unless iv && iv >= iv_threshold && iv <= max_iv
            rejected_count += 1
            # Rails.logger.debug { "[Options] Rejected #{strike}: IV #{iv} not in range #{iv_threshold.round(2)}-#{max_iv} (relaxed for #{strike_type}: #{iv_threshold.round(2)})" }
            next
          end

          # Check OI
          unless oi && oi >= min_oi
            rejected_count += 1
            # Rails.logger.debug { "[Options] Rejected #{strike}: OI #{oi} < #{min_oi}" }
            next
          end

          # Calculate spread percentage
          spread_ratio = nil
          if bid && ask && bid.positive?
            spread_ratio = (ask - bid) / bid
            spread_pct = spread_ratio * 100
            if spread_pct > max_spread_pct
              rejected_count += 1
              # Rails.logger.debug { "[Options] Rejected #{strike}: Spread #{spread_pct}% > #{max_spread_pct}%" }
              next
            end
          end

          # Check Delta (time-based thresholds)
          delta = option_data.dig('greeks', 'delta')&.to_f&.abs
          unless delta && delta >= min_delta
            rejected_count += 1
            # Rails.logger.debug { "[Options] Rejected #{strike}: Delta #{delta} < #{min_delta}" }
            next
          end

          # Find the derivative security ID using instrument.derivatives association
          # Filter by strike, expiry date, and option type
          expiry_date_obj = Date.parse(expiry_date)
          option_type = side.to_s.upcase # CE or PE

          # Use BigDecimal for accurate float comparison
          strike_bd = BigDecimal(strike.to_s)

          derivative = if instrument.persisted?
                         # If instrument is persisted, use association
                         instrument.derivatives.detect do |d|
                           d.expiry_date == expiry_date_obj &&
                             d.option_type == option_type &&
                             BigDecimal(d.strike_price.to_s) == strike_bd
                         end
                       else
                         # If instrument is not persisted, query Derivative directly
                         # Use underlying_symbol or underlying_security_id to match
                         Derivative.where(
                           underlying_symbol: instrument.symbol_name,
                           exchange: instrument.exchange,
                           segment: instrument.segment,
                           expiry_date: expiry_date_obj,
                           option_type: option_type
                         ).detect do |d|
                           BigDecimal(d.strike_price.to_s) == strike_bd
                         end
                       end

          if derivative
            # Rails.logger.debug { "[Options] Found derivative for #{index_cfg[:key]} #{strike} #{side}: security_id=#{derivative.security_id}, lot_size=#{derivative.lot_size}" }
            security_id = derivative.security_id
          else
            # Rails.logger.warn("[Options] No derivative found for #{index_cfg[:key]} #{strike} #{side} #{expiry_date}")
            security_id = nil
          end

          derivative_segment = if derivative.respond_to?(:exchange_segment) && derivative.exchange_segment.present?
                                 derivative.exchange_segment
                               elsif derivative.is_a?(Hash)
                                 derivative[:exchange_segment]
                               end
          derivative_segment ||= instrument.exchange_segment if instrument.respond_to?(:exchange_segment)
          derivative_segment ||= index_cfg[:segment]

          legs << {
            segment: derivative_segment,
            security_id: security_id,
            symbol: "#{index_cfg[:key]}-#{expiry_date_obj.strftime('%b%Y')}-#{strike.to_i}-#{side.to_s.upcase}",
            strike: strike,
            ltp: ltp,
            iv: iv,
            oi: oi,
            spread: spread_ratio,
            delta: delta,
            distance_from_atm: (strike - atm).abs,
            lot_size: derivative&.lot_size || index_cfg[:lot].to_i,
            derivative_id: derivative&.id
          }

          # Rails.logger.debug { "[Options] Accepted #{strike}: #{legs.last[:symbol]}" }
        end

        # Rails.logger.info("[Options] Filter results: #{legs.size} accepted, #{rejected_count} rejected")

        # Log detailed filtering summary
        log_filtering_summary(side, legs.size, rejected_count, min_iv, max_iv, min_oi, max_spread_pct, min_delta)

        # Apply sophisticated scoring system
        scored_legs = legs.map do |leg|
          score = calculate_strike_score(leg, side, atm_strike, atm_range_percent)
          leg.merge(score: score)
        end

        # Sort by score (descending), then by distance from ATM
        scored_legs.sort_by { |leg| [-leg[:score], leg[:distance_from_atm]] }
      end

      def filter_and_rank(legs, atm:, side:, window:)
        return [] unless legs

        min_iv = AlgoConfig.fetch.dig(:option_chain, :min_iv).to_f
        max_iv = AlgoConfig.fetch.dig(:option_chain, :max_iv).to_f
        min_oi = AlgoConfig.fetch.dig(:option_chain, :min_oi).to_i
        max_spread_pct = AlgoConfig.fetch.dig(:option_chain, :max_spread_pct).to_f

        legs.select do |leg|
          leg[:type] == side &&
            (leg[:strike].to_f - atm.to_f).abs <= window &&
            leg[:iv].to_f.between?(min_iv, max_iv) &&
            leg[:oi].to_i >= min_oi &&
            leg.fetch(:spread_pct, 0.0).to_f <= max_spread_pct
        end.sort_by { |leg| [-leg[:oi].to_i, leg.fetch(:spread_pct, 0.0).to_f] }
      end

      # Dynamic minimum delta thresholds depending on time of day
      # More realistic delta requirements for OTM options
      def min_delta_now
        h = Time.zone.now.hour
        return 0.15 if h >= 14  # After 2 PM - moderate delta for OTM options
        return 0.12 if h >= 13  # After 1 PM - lower delta acceptable
        return 0.10 if h >= 11  # After 11 AM - even lower delta

        0.08                    # Before 11 AM - very low delta acceptable for OTM
      end

      # Dynamic ATM range based on volatility (IV rank)
      # Low volatility = tight range, High volatility = wider range
      def atm_range_pct(iv_rank = 0.5)
        case iv_rank
        when 0.0..0.2 then 0.01 # Low volatility - tight range (1%)
        when 0.2..0.5 then 0.015 # Medium volatility - medium range (1.5%)
        else 0.025               # High volatility - wider range (2.5%)
        end
      end

      # Log comprehensive strike selection guidance
      def log_strike_selection_guidance(side, spot, atm_strike, target_strikes, iv_rank, _atm_range_percent,
                                        strike_interval)
        case iv_rank
        when 0.0..0.2 then 'Low'
        when 0.2..0.5 then 'Medium'
        else 'High'
        end

        if [:ce, 'ce'].include?(side)
          'CE strikes: ATM, ATM+1, ATM+2, ATM+3 (OTM calls only)'
        else
          'PE strikes: ATM, ATM-1, ATM-2, ATM-3 (OTM puts only)'
        end

        # Rails.logger.info('[Options] Strike Selection Guidance:')
        # Rails.logger.info("  - Current SPOT: #{spot}")
        # Rails.logger.info("  - ATM Strike: #{atm_strike}")
        # Rails.logger.info("  - Volatility Regime: #{volatility_regime} (IV Rank: #{iv_rank})")
        # Rails.logger.info("  - ATM Range: #{atm_range_percent * 100}%")
        # Rails.logger.info("  - Target Strikes: #{target_strikes}")
        # Rails.logger.info("  - Strategy: #{explanation}")

        # Log strike analysis
        target_strikes.each_with_index do |strike, _index|
          (strike - atm_strike).abs
          (strike - spot).abs
          if strike == atm_strike
            'ATM'
          elsif [:ce, 'ce'].include?(side)
            strike_diff = (strike - atm_strike) / strike_interval
            case strike_diff
            when 1
              'ATM+1'
            when 2
              'ATM+2'
            else
              strike_diff == 3 ? 'ATM+3' : 'OTHER'
            end
          else
            strike_diff = (atm_strike - strike) / strike_interval
            case strike_diff
            when 1
              'ATM-1'
            when 2
              'ATM-2'
            else
              strike_diff == 3 ? 'ATM-3' : 'OTHER'
            end
          end

          # Rails.logger.info("  - Strike #{index + 1}: #{strike} (#{strike_step}) - #{distance_from_atm} points from ATM, #{distance_from_spot.round(2)} points from spot")
        end
      end

      # Calculate sophisticated strike score based on multiple factors
      def calculate_strike_score(leg, side, atm_strike, atm_range_percent)
        strike_price = leg[:strike]
        ltp = leg[:ltp]
        iv = leg[:iv]
        oi = leg[:oi]

        # Calculate spread percentage from spread and LTP
        spread_pct = if leg[:spread]
                       leg[:spread] * 100
                     else
                       0.0 # Default to 0% spread if not available
                     end

        delta = leg[:delta] || 0.5 # Default delta if not available

        # 1. ATM Preference Score (0-100)
        distance_from_atm = (strike_price - atm_strike).abs
        atm_range_points = atm_strike * atm_range_percent

        atm_preference_score = if distance_from_atm <= (atm_range_points * 0.1)
                                 100 # Perfect ATM
                               elsif distance_from_atm <= (atm_range_points * 0.3)
                                 80  # Near ATM
                               elsif distance_from_atm <= (atm_range_points * 0.6)
                                 50  # Slightly away
                               else
                                 20  # Far from ATM
                               end

        # Penalty for ITM strikes (30% reduction)
        atm_preference_score *= 0.7 if itm_strike?(strike_price, side, atm_strike)

        # 2. Liquidity Score (0-50)
        # Based on OI and spread
        liquidity_score = if oi >= 1_000_000
                            50 # Excellent liquidity
                          elsif oi >= 500_000
                            40  # Good liquidity
                          elsif oi >= 100_000
                            30  # Decent liquidity
                          else
                            20  # Poor liquidity
                          end

        # Spread penalty
        if spread_pct > 2.0
          liquidity_score *= 0.8  # 20% penalty for wide spreads
        elsif spread_pct > 1.0
          liquidity_score *= 0.9  # 10% penalty for moderate spreads
        end

        # 3. Delta Score (0-30)
        # Higher delta is better for options buying
        delta_score = if delta >= 0.5
                        30 # Excellent delta
                      elsif delta >= 0.4
                        25  # Good delta
                      elsif delta >= 0.3
                        20  # Decent delta
                      else
                        10  # Poor delta
                      end

        # 4. IV Score (0-20)
        # Moderate IV is preferred (not too high, not too low)
        # ATM strikes get bonus for proximity even with lower IV
        # Use distance_from_atm to determine if it's ATM or ATM±1 (typically 50-100 points for NIFTY)
        is_atm_or_near = distance_from_atm <= (atm_strike * 0.005) # Within 0.5% of ATM (~125 points for NIFTY)

        iv_score = if iv.between?(15, 25)
                     20 # Sweet spot
                   elsif iv.between?(10, 30)
                     15  # Acceptable range
                   elsif iv.between?(5, 40)
                     10  # Marginal
                   else
                     5 # Poor IV
                   end
        # Bonus for ATM strikes with acceptable IV (even if lower)
        if is_atm_or_near && iv >= 5 && iv < 10
          iv_score += 5 # Boost score for ATM strikes with low but acceptable IV
        end

        # 5. Price Efficiency Score (0-10)
        # Lower price per point of delta is better
        price_efficiency = delta.positive? ? (ltp / delta) : ltp
        price_efficiency_score = if price_efficiency <= 200
                                   10 # Excellent efficiency
                                 elsif price_efficiency <= 300
                                   8   # Good efficiency
                                 elsif price_efficiency <= 500
                                   6   # Decent efficiency
                                 else
                                   4   # Poor efficiency
                                 end

        # Calculate total score
        atm_preference_score + liquidity_score + delta_score + iv_score + price_efficiency_score

        # Log scoring breakdown for debugging
        # Rails.logger.debug { "[Options] Strike #{strike_price} scoring:" }
        # Rails.logger.debug { "  - ATM Preference: #{atm_preference_score.round(1)} (distance: #{distance_from_atm.round(1)})" }
        # Rails.logger.debug { "  - Liquidity: #{liquidity_score.round(1)} (OI: #{oi}, Spread: #{spread_pct.round(2)}%)" }
        # Rails.logger.debug { "  - Delta: #{delta_score.round(1)} (delta: #{delta.round(3)})" }
        # Rails.logger.debug { "  - IV: #{iv_score.round(1)} (IV: #{iv.round(2)}%)" }
        # Rails.logger.debug { "  - Price Efficiency: #{price_efficiency_score.round(1)} (price/delta: #{price_efficiency.round(1)})" }
        # Rails.logger.debug { "  - Total Score: #{total_score.round(1)}" }
      end

      # Check if a strike is ITM (In-The-Money)
      def itm_strike?(strike_price, side, atm_strike)
        case side.to_sym
        when :ce, 'ce'
          # For calls: strike < ATM is ITM
          strike_price < atm_strike
        when :pe, 'pe'
          # For puts: strike > ATM is ITM
          strike_price > atm_strike
        else
          false
        end
      end

      # Log detailed filtering summary with explanations
      def log_filtering_summary(_side, accepted_count, rejected_count, _min_iv, _max_iv, _min_oi, _max_spread_pct,
                                _min_delta)
        total_processed = accepted_count + rejected_count
        total_processed.positive? ? (accepted_count.to_f / total_processed * 100).round(1) : 0

        # Rails.logger.info('[Options] Filtering Summary:')
        # Rails.logger.info("  - Total strikes processed: #{total_processed}")
        # Rails.logger.info("  - Accepted: #{accepted_count} (#{acceptance_rate}%)")
        # Rails.logger.info("  - Rejected: #{rejected_count} (#{100 - acceptance_rate}%)")
        # Rails.logger.info('  - Filter criteria applied:')
        # Rails.logger.info("    * IV Range: #{min_iv}-#{max_iv}%")
        # Rails.logger.info("    * Minimum OI: #{min_oi}")
        # Rails.logger.info("    * Maximum Spread: #{max_spread_pct}%")
        # Rails.logger.info("    * Minimum Delta: #{min_delta} (time-based)")

        if accepted_count.zero?
          # Rails.logger.warn('  - ⚠️  No strikes passed all filters - consider adjusting criteria')
        elsif accepted_count < 3
          # Rails.logger.info("  - ℹ️  Limited strikes available - #{accepted_count} option(s) found")
        else
          # Rails.logger.info("  - ✅ Good strike selection - #{accepted_count} options available")
        end
      end
    end
  end
end


# File: app/services/options/derivative_chain_analyzer.rb
# frozen_string_literal: true

module Options
  # Enhanced ChainAnalyzer that uses Derivative records and integrates with existing infrastructure
  # This replaces the need for raw option chain APIs by leveraging existing Derivative models
  # rubocop:disable Metrics/ClassLength
  class DerivativeChainAnalyzer
    def initialize(index_key:, expiry: nil, config: {})
      @index_key = index_key.to_s.upcase
      @config = config || {}
      @expiry = expiry
      @index_cfg = AlgoConfig.fetch[:indices]&.find { |idx| idx[:key].to_s.upcase == @index_key }
      raise "unknown_index:#{@index_key}" unless @index_cfg
    end

    # Select best option candidates using Derivative records
    # @param limit [Integer] Maximum number of candidates to return
    # @param direction [Symbol] :bullish (CE) or :bearish (PE)
    # @return [Array<Hash>] Array of candidate hashes with derivative records
    def select_candidates(limit: 5, direction: :bullish)
      spot = spot_ltp
      return [] unless spot&.positive?

      expiry_date = @expiry || find_nearest_expiry
      return [] unless expiry_date

      chain = load_chain_for_expiry(expiry_date)
      return [] if chain.empty?

      atm = find_atm_strike(chain, spot)
      scored = score_chain(chain, atm, spot, direction)
      scored.sort_by { |c| -c[:score] }.first(limit)
    rescue StandardError => e
      Rails.logger.error("[Options::DerivativeChainAnalyzer] select_candidates failed: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
      []
    end

    private

    # Get spot LTP from tick cache
    def spot_ltp
      seg = @index_cfg[:segment]
      sid = @index_cfg[:sid]
      Live::TickCache.ltp(seg, sid) || Live::RedisTickCache.instance.fetch_tick(seg, sid)&.dig(:ltp)&.to_f
    end

    # Find nearest expiry from Instrument's expiry list
    def find_nearest_expiry
      instrument = IndexInstrumentCache.instance.get_or_fetch(@index_cfg)
      return nil unless instrument

      expiry_list = instrument.expiry_list
      return nil unless expiry_list&.any?

      today = Time.zone.today
      parsed = expiry_list.compact.filter_map do |raw|
        case raw
        when Date then raw
        when Time, DateTime, ActiveSupport::TimeWithZone then raw.to_date
        when String
          begin
            Date.parse(raw)
          rescue ArgumentError
            nil
          end
        end
      end

      next_expiry = parsed.select { |date| date >= today }.min
      next_expiry&.strftime('%Y-%m-%d')
    end

    # Load chain using Derivative records and merge with live data
    def load_chain_for_expiry(expiry_date)
      expiry_obj = Date.parse(expiry_date)

      # Get all derivatives for this index and expiry
      derivatives = Derivative.where(
        underlying_symbol: @index_key,
        expiry_date: expiry_obj
      ).where.not(option_type: [nil, ''])

      return [] if derivatives.empty?

      # Fetch option chain data from API for OI/IV/Greeks
      api_chain = fetch_api_chain(expiry_date)
      return [] unless api_chain

      # Merge Derivative records with API data and live ticks
      derivatives.filter_map do |derivative|
        strike_str = derivative.strike_price.to_s
        option_type_lower = derivative.option_type.to_s.downcase
        api_data = api_chain.dig(strike_str, option_type_lower)

        # Get live tick data
        tick = Live::RedisTickCache.instance.fetch_tick(derivative.segment, derivative.security_id)

        build_option_data(derivative, api_data, tick)
      end
    end

    # Fetch option chain from DhanHQ API
    def fetch_api_chain(expiry_date)
      instrument = IndexInstrumentCache.instance.get_or_fetch(@index_cfg)
      return nil unless instrument

      chain_data = instrument.fetch_option_chain(expiry_date)
      return nil unless chain_data

      # Transform to strike -> { ce: {...}, pe: {...} } format
      oc = chain_data[:oc] || {}
      oc.transform_keys(&:to_s)
    rescue StandardError => e
      Rails.logger.warn("[Options::DerivativeChainAnalyzer] API chain fetch failed: #{e.message}")
      nil
    end

    # Build option data hash from Derivative, API data, and tick
    # rubocop:disable Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity
    def build_option_data(derivative, api_data, tick)
      {
        derivative: derivative,
        strike: derivative.strike_price.to_f,
        type: derivative.option_type,
        expiry: derivative.expiry_date,
        segment: derivative.segment,
        security_id: derivative.security_id,
        lot_size: derivative.lot_size.to_i,
        ltp: tick&.dig(:ltp)&.to_f || api_data&.dig('last_price')&.to_f,
        oi: tick&.dig(:oi)&.to_i || api_data&.dig('oi')&.to_i,
        oi_change: tick&.dig(:oi_change)&.to_i,
        bid: tick&.dig(:bid)&.to_f || api_data&.dig('top_bid_price')&.to_f,
        ask: tick&.dig(:ask)&.to_f || api_data&.dig('top_ask_price')&.to_f,
        iv: api_data&.dig('implied_volatility')&.to_f,
        volume: tick&.dig(:volume)&.to_i || api_data&.dig('volume')&.to_i,
        prev_close: api_data&.dig('previous_close_price')&.to_f,
        delta: api_data&.dig('greeks', 'delta')&.to_f,
        gamma: api_data&.dig('greeks', 'gamma')&.to_f,
        theta: api_data&.dig('greeks', 'theta')&.to_f,
        vega: api_data&.dig('greeks', 'vega')&.to_f
      }
    end
    # rubocop:enable Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity

    # Find ATM strike from chain
    def find_atm_strike(chain, spot)
      return nil if chain.empty?

      chain.min_by { |o| (o[:strike] - spot).abs }[:strike]
    end

    # Score chain options based on multiple factors
    # rubocop:disable Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity
    def score_chain(chain, atm, spot, direction)
      @direction = direction # Store for use in reason_for
      option_type = direction == :bullish ? 'CE' : 'PE'
      max_distance_pct = (@config[:strike_distance_pct] || 0.02).to_f
      max_distance = spot * max_distance_pct

      min_oi = (@config[:min_oi] || 10_000).to_i
      min_iv = (@config[:min_iv] || 5.0).to_f
      max_iv = (@config[:max_iv] || 60.0).to_f
      max_spread_pct = (@config[:max_spread_pct] || 0.03).to_f

      chain.select { |o| o[:type] == option_type }.filter_map do |option|
        # Filter criteria
        next if (option[:strike] - spot).abs > max_distance * 2
        next if option[:oi].to_i < min_oi
        next if option[:iv].to_f < min_iv || option[:iv].to_f > max_iv

        spread = calc_spread(option[:bid], option[:ask], option[:ltp])
        next if spread.nil? || spread > max_spread_pct

        # Calculate combined score
        score = combined_score(option, atm, spot, direction)

        {
          derivative: option[:derivative],
          strike: option[:strike],
          type: option[:type],
          score: score,
          ltp: option[:ltp],
          iv: option[:iv],
          oi: option[:oi],
          oi_change: option[:oi_change],
          spread: spread,
          delta: option[:delta],
          segment: option[:segment],
          security_id: option[:security_id],
          lot_size: option[:lot_size],
          symbol: build_symbol(option[:derivative], option[:strike], option[:type], option[:expiry]),
          derivative_id: option[:derivative]&.id,
          reason: reason_for(option, score, atm, spot)
        }
      end
    end
    # rubocop:enable Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity

    # Calculate bid-ask spread percentage
    def calc_spread(bid, ask, _ltp)
      return nil unless bid && ask && bid.positive?

      mid = (bid + ask) / 2.0
      return nil if mid <= 0

      (ask - bid) / mid
    end

    # Combined scoring function (heuristic - must be backtested)
    # rubocop:disable Metrics/AbcSize
    def combined_score(option, atm, spot, _direction)
      weights = @config[:scoring_weights] || {
        oi: 0.4,
        spread: 0.25,
        iv: 0.2,
        volume: 0.15
      }

      # Normalize OI (log scale, max ~1M = 6.0)
      oi_norm = Math.log10([option[:oi].to_i, 1].max) / 6.0
      oi_norm = [oi_norm, 1.0].min

      # Normalize spread (lower is better, inverted)
      spread = calc_spread(option[:bid], option[:ask], option[:ltp]) || 0.05
      spread_norm = 1.0 - [spread, 1.0].min

      # Normalize IV (prefer moderate IV around 20-25%)
      iv = option[:iv].to_f
      iv_norm = if iv.between?(15, 25)
                  1.0
                elsif iv.between?(10, 30)
                  0.8
                elsif iv.between?(5, 40)
                  0.6
                else
                  0.3
                end

      # Normalize volume (log scale)
      vol_norm = Math.log10([option[:volume].to_i, 1].max) / 6.0
      vol_norm = [vol_norm, 1.0].min

      # ATM preference bonus
      distance_from_atm = (option[:strike] - atm).abs
      atm_bonus = if distance_from_atm <= (spot * 0.005)
                    0.2 # Within 0.5% of ATM
                  elsif distance_from_atm <= (spot * 0.01)
                    0.1 # Within 1% of ATM
                  else
                    0.0
                  end

      base_score = (oi_norm * weights[:oi]) +
                   (spread_norm * weights[:spread]) +
                   (iv_norm * weights[:iv]) +
                   (vol_norm * weights[:volume])

      base_score + atm_bonus
    end
    # rubocop:enable Metrics/AbcSize

    # Build symbol string for candidate (compatible with BaseEngine)
    def build_symbol(derivative, strike, type, _expiry)
      return nil unless derivative

      expiry_str = derivative.expiry_date.strftime('%b%Y')
      "#{@index_key}-#{expiry_str}-#{strike.to_i}-#{type}"
    end

    # Generate human-readable reason for selection
    def reason_for(option, score, atm, spot)
      distance = (option[:strike] - spot).abs
      distance_pct = (distance / spot * 100).round(2)
      strike_type = if option[:strike] == atm
                      'ATM'
                    elsif option[:strike] > spot
                      direction == :bullish ? 'OTM' : 'ITM'
                    else
                      direction == :bullish ? 'ITM' : 'OTM'
                    end

      spread_pct = calc_spread(option[:bid], option[:ask], option[:ltp])
      spread_str = spread_pct ? "#{(spread_pct * 100).round(2)}%" : 'N/A'

      "Score:#{score.round(3)} IV:#{option[:iv]&.round(2)}% OI:#{option[:oi]} " \
        "Spread:#{spread_str} Strike:#{option[:strike]} (#{strike_type}, #{distance_pct}% from spot)"
    end
  end
  # rubocop:enable Metrics/ClassLength
end


# File: app/services/options/expired_fetcher.rb
# frozen_string_literal: true
# app/services/options/expired_fetcher.rb
class Options::ExpiredFetcher < ApplicationService
  def initialize(symbol:, expiry_flag: 'WEEK', date: Date.today)
    @symbol = symbol
    @expiry_flag = normalize_expiry_flag(symbol, expiry_flag)
    @date = date
  end

  # Fetches CE and PE OHLC arrays
  # def call
  #   date_str = normalize_date_string(@date)
  #   pp date_str
  #   { ce: 'CALL', pe: 'PUT' }.to_h do |side_key, opt_type|
  #     data = DhanHQ::Models::ExpiredOptionsData.fetch(
  #       exchange_segment: segment_for(@symbol),
  #       interval: '5',
  #       security_id: security_id_for(@symbol),
  #       instrument: 'OPTIDX',
  #       expiry_flag: @expiry_flag,
  #       expiry_code: 1,
  #       strike: 'ATM',
  #       drv_option_type: opt_type,
  #       required_data: %w[open high low close volume oi spot strike],
  #       from_date: date_str,
  #       to_date: date_str
  #     )
  #     [side_key, parse_data(data, side_key)]
  #   end
  # rescue StandardError => e
  #   Rails.logger.error("[ExpiredFetcher] Failed: #{e.message}")
  #   { ce: [], pe: [] }
  # end

  def call
    cache_key = "expired_option_data:#{@symbol}:#{@date}:#{@expiry_flag}"

    cached_data = Rails.cache.read(cache_key)
    return cached_data if cached_data.present?

    date_str = normalize_date_string(@date)
    pp date_str
    result = { ce: 'CALL', pe: 'PUT' }.to_h do |side_key, opt_type|
      data = DhanHQ::Models::ExpiredOptionsData.fetch(
        exchange_segment: segment_for(@symbol),
        interval: '5',
        security_id: security_id_for(@symbol),
        instrument: 'OPTIDX',
        expiry_flag: @expiry_flag,
        expiry_code: 1,
        strike: 'ATM',
        drv_option_type: opt_type,
        required_data: %w[open high low close volume oi spot strike],
        from_date: date_str,
        to_date: date_str
      )
      [side_key, parse_data(data, side_key)]
    end

    Rails.cache.write(cache_key, result, expires_in: 24.hours)
    result
  rescue StandardError => e
    Rails.logger.error("[ExpiredFetcher] Failed: #{e.message}")
    { ce: [], pe: [] }
  end


  private

  def normalize_date_string(value)
    return value.strftime('%Y-%m-%d') if value.is_a?(Date)
    return value.to_date.strftime('%Y-%m-%d') if value.respond_to?(:to_date)
    Date.parse(value.to_s).strftime('%Y-%m-%d')
  rescue StandardError
    Time.zone.today.strftime('%Y-%m-%d')
  end

  def normalize_expiry_flag(symbol, requested_flag)
    return requested_flag if requested_flag.to_s.upcase == 'MONTH'

    sym = symbol.to_s.upcase
    # Only NIFTY and SENSEX support weekly expiries; BANKNIFTY is monthly-only
    if %w[NIFTY SENSEX].include?(sym)
      'WEEK'
    else
      'MONTH'
    end
  end

  def security_id_for(symbol)
    Instrument.segment_index.find_by(symbol_name: symbol)&.security_id
  end

  def segment_for(symbol)
    sym = symbol.to_s.upcase
    case sym
    when 'SENSEX'
      'BSE_FNO'
    else
      'NSE_FNO'
    end
  end

  def parse_data(data, side_key)
    # Map :ce/:pe to API keys 'ce'/'pe'
    side = side_key == :ce ? 'ce' : 'pe'
    d = data&.data&.[](side)
    return [] unless d && d['timestamp']

    d['timestamp'].map.with_index do |ts, i|
      {
        timestamp: Time.at(ts).in_time_zone('Asia/Kolkata'),
        open: d['open'][i].to_f,
        high: d['high'][i].to_f,
        low: d['low'][i].to_f,
        close: d['close'][i].to_f,
        volume: d['volume'][i].to_i,
        oi: d['oi'][i].to_i,
        spot: d['spot'][i].to_f,
        strike: d['strike'][i].to_f
      }
    end
  end
end


# File: app/services/options/index_rules/banknifty.rb
# frozen_string_literal: true

module Options
  module IndexRules
    # Index-specific rules for BANKNIFTY
    class Banknifty
      MIN_VOLUME = 50_000
      MIN_PREMIUM = 40.0
      MAX_SPREAD_PCT = 0.005 # 0.5%

      def multiplier
        1
      end

      def lot_size
        15
      end

      def atm(spot)
        (spot.to_f / 100).round * 100
      end

      def candidate_strikes(atm_strike, _strength = nil)
        [atm_strike]
      end

      def option_type(direction)
        direction == :bullish ? 'CE' : 'PE'
      end

      def valid_liquidity?(candidate)
        volume = candidate[:volume] || candidate['volume'] || 0
        volume.to_i >= MIN_VOLUME
      end

      def valid_spread?(candidate)
        bid = (candidate[:bid] || candidate['bid'] || 0).to_f
        ask = (candidate[:ask] || candidate['ask'] || 0).to_f
        return false if bid <= 0 || ask <= 0

        spread_pct = ((ask - bid) / ask.to_f)
        spread_pct <= MAX_SPREAD_PCT
      end

      def valid_premium?(candidate)
        premium = (candidate[:ltp] || candidate['ltp'] || 0).to_f
        premium >= MIN_PREMIUM
      end
    end
  end
end


# File: app/services/options/index_rules/nifty.rb
# frozen_string_literal: true

module Options
  module IndexRules
    # Index-specific rules for NIFTY
    class Nifty
      MIN_VOLUME = 30_000
      MIN_PREMIUM = 25.0
      MAX_SPREAD_PCT = 0.003 # 0.3%

      def multiplier
        1
      end

      def lot_size
        75
      end

      def atm(spot)
        (spot.to_f / 50).round * 50
      end

      def candidate_strikes(atm_strike, _strength = nil)
        [atm_strike, atm_strike + 50]
      end

      def option_type(direction)
        direction == :bullish ? 'CE' : 'PE'
      end

      def valid_liquidity?(candidate)
        volume = candidate[:volume] || candidate['volume'] || 0
        volume.to_i >= MIN_VOLUME
      end

      def valid_spread?(candidate)
        bid = (candidate[:bid] || candidate['bid'] || 0).to_f
        ask = (candidate[:ask] || candidate['ask'] || 0).to_f
        return false if bid <= 0 || ask <= 0

        spread_pct = ((ask - bid) / ask.to_f)
        spread_pct <= MAX_SPREAD_PCT
      end

      def valid_premium?(candidate)
        premium = (candidate[:ltp] || candidate['ltp'] || candidate[:last_price] || 0).to_f
        premium >= MIN_PREMIUM
      end
    end
  end
end


# File: app/services/options/index_rules/sensex.rb
# frozen_string_literal: true

module Options
  module IndexRules
    # Index-specific rules for SENSEX
    class Sensex
      MIN_VOLUME = 20_000
      MIN_PREMIUM = 30.0
      MAX_SPREAD_PCT = 0.003 # 0.3%

      def multiplier
        1
      end

      def lot_size
        10
      end

      def atm(spot)
        (spot.to_f / 100).round * 100
      end

      def candidate_strikes(atm_strike, _strength = nil)
        [atm_strike]
      end

      def option_type(direction)
        direction == :bullish ? 'CE' : 'PE'
      end

      def valid_liquidity?(candidate)
        volume = candidate[:volume] || candidate['volume'] || 0
        volume.to_i >= MIN_VOLUME
      end

      def valid_spread?(candidate)
        bid = (candidate[:bid] || candidate['bid'] || 0).to_f
        ask = (candidate[:ask] || candidate['ask'] || 0).to_f
        return false if bid <= 0 || ask <= 0

        spread_pct = ((ask - bid) / ask.to_f)
        spread_pct <= MAX_SPREAD_PCT
      end

      def valid_premium?(candidate)
        premium = (candidate[:ltp] || candidate['ltp'] || 0).to_f
        premium >= MIN_PREMIUM
      end
    end
  end
end


# File: app/services/options/strike_selector.rb
# frozen_string_literal: true

module Options
  # StrikeSelector for NEMESIS V3 architecture
  # Uses existing DerivativeChainAnalyzer and applies index-specific rules
  # Returns normalized instrument hash for EntryManager/Orders::Placer
  class StrikeSelector
    class SelectionError < StandardError; end

    def initialize(tick_cache: nil)
      @tick_cache = tick_cache || Live::TickCache
    end

    # Select best strike for given index & direction
    # @param index_key [String, Symbol] Index key (NIFTY, BANKNIFTY, SENSEX)
    # @param direction [Symbol] :bullish (CE) or :bearish (PE)
    # @param expiry [String, Date, nil] Expiry date (nil = auto-select nearest)
    # @param config [Hash] Additional config for DerivativeChainAnalyzer
    # @return [Hash, nil] Normalized instrument hash or nil if no valid strike
    def select(index_key:, direction:, expiry: nil, config: {})
      index_key = normalize_index(index_key)
      rules = load_rules_for(index_key)

      # Use existing DerivativeChainAnalyzer
      analyzer = DerivativeChainAnalyzer.new(
        index_key: index_key,
        expiry: expiry,
        config: config
      )

      # Get candidates (already scored and sorted)
      candidates = analyzer.select_candidates(limit: 5, direction: direction)

      if candidates.empty?
        Rails.logger.warn("[Options::StrikeSelector] No candidates from DerivativeChainAnalyzer for #{index_key}")
        return nil
      end

      # Apply index-specific rules to candidates
      candidates.each do |candidate|
        next unless candidate_valid?(candidate, rules)

        # Resolve LTP from tick cache or candidate
        ltp = resolve_ltp(candidate)
        next unless ltp&.positive?

        # Return normalized instrument hash
        return build_instrument_hash(candidate, index_key, ltp, rules)
      end

      Rails.logger.warn("[Options::StrikeSelector] No valid strike passed index rules for #{index_key}")
      nil
    rescue SelectionError => e
      Rails.logger.error("[Options::StrikeSelector] Selection error: #{e.message}")
      nil
    rescue StandardError => e
      Rails.logger.error("[Options::StrikeSelector] Unexpected error: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
      nil
    end

    private

    def normalize_index(index)
      index.to_s.strip.upcase
    end

    def load_rules_for(index_key)
      case index_key.to_s.upcase
      when 'NIFTY' then IndexRules::Nifty.new
      when 'BANKNIFTY' then IndexRules::Banknifty.new
      when 'SENSEX' then IndexRules::Sensex.new
      else
        raise SelectionError, "Unknown index: #{index_key}"
      end
    end

    def candidate_valid?(candidate, rules)
      # Validate liquidity
      return false unless rules.valid_liquidity?(candidate)

      # Validate spread
      return false unless rules.valid_spread?(candidate)

      # Validate premium
      return false unless rules.valid_premium?(candidate)

      true
    end

    def resolve_ltp(candidate)
      # Try tick cache first
      segment = candidate[:segment]
      security_id = candidate[:security_id]

      if segment.present? && security_id.present?
        cached_ltp = @tick_cache.ltp(segment, security_id)
        return cached_ltp if cached_ltp&.positive?
      end

      # Fallback to candidate LTP
      candidate[:ltp]&.to_f
    end

    def build_instrument_hash(candidate, index_key, ltp, rules)
      {
        index: index_key,
        exchange_segment: candidate[:segment],
        security_id: candidate[:security_id].to_s,
        strike: candidate[:strike].to_i,
        option_type: candidate[:type],
        ltp: ltp.to_f,
        lot_size: candidate[:lot_size] || rules.lot_size,
        spot: nil, # Can be fetched separately if needed
        multiplier: rules.multiplier,
        derivative: candidate[:derivative],
        derivative_id: candidate[:derivative_id],
        symbol: candidate[:symbol],
        iv: candidate[:iv],
        oi: candidate[:oi],
        score: candidate[:score],
        reason: candidate[:reason]
      }
    end
  end
end


# File: app/services/orders/bracket_placer.rb
# frozen_string_literal: true

module Orders
  # BracketPlacer for NEMESIS V3 architecture
  # Places and manages SL/TP bracket orders for positions
  # Supports initial bracket placement and dynamic adjustments
  # rubocop:disable Metrics/ClassLength
  class BracketPlacer
    def initialize(event_bus: Core::EventBus.instance, active_cache: Positions::ActiveCache.instance)
      @event_bus = event_bus
      @active_cache = active_cache
      @stats = {
        brackets_placed: 0,
        brackets_modified: 0,
        brackets_failed: 0,
        sl_orders_placed: 0,
        tp_orders_placed: 0
      }
    end

    # Place bracket orders (SL/TP) for a position
    # Note: DhanHQ bracket orders are placed WITH the entry order (boProfitValue, boStopLossValue)
    # This method is for cases where bracket orders need to be placed separately or modified
    # @param tracker [PositionTracker] PositionTracker instance
    # @param sl_price [Float] Stop loss price
    # @param tp_price [Float] Take profit price
    # @param reason [String] Reason for bracket placement
    # @return [Hash] Result hash with :success, :sl_order, :tp_order, :error
    def place_bracket(tracker:, sl_price:, tp_price:, reason: nil)
      return failure_result('Tracker not found') unless tracker
      return failure_result('Tracker not active') unless tracker.active?
      return failure_result('Invalid SL/TP prices') unless sl_price&.positive? && tp_price&.positive?

      # For NEMESIS V3, bracket orders are typically placed WITH the entry order
      # This method is primarily for adjustments or separate placement scenarios
      # DhanHQ doesn't support modifying bracket orders - we'd need to cancel and replace
      # For now, we'll update ActiveCache and log the bracket levels

      # Update ActiveCache with SL/TP
      @active_cache.update_position(
        tracker.id,
        sl_price: sl_price,
        tp_price: tp_price
      )

      # Emit bracket placed event
      emit_bracket_placed_event(tracker, sl_price, tp_price, reason)

      @stats[:brackets_placed] += 1
      @stats[:sl_orders_placed] += 1
      @stats[:tp_orders_placed] += 1

      success_result(sl_price: sl_price, tp_price: tp_price, reason: reason)
    rescue StandardError => e
      @stats[:brackets_failed] += 1
      Rails.logger.error("[Orders::BracketPlacer] place_bracket failed: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
      failure_result(e.message)
    end

    # Update bracket orders (modify SL/TP)
    # Since DhanHQ doesn't support modifying bracket orders, this updates ActiveCache
    # The actual order modification would require canceling and replacing (not implemented here)
    # @param tracker [PositionTracker] PositionTracker instance
    # @param sl_price [Float, nil] New stop loss price (nil to keep existing)
    # @param tp_price [Float, nil] New take profit price (nil to keep existing)
    # @param reason [String] Reason for modification
    # @return [Hash] Result hash with :success, :sl_price, :tp_price, :error
    # rubocop:disable Metrics/AbcSize
    def update_bracket(tracker:, sl_price: nil, tp_price: nil, reason: nil)
      return failure_result('Tracker not found') unless tracker
      return failure_result('Tracker not active') unless tracker.active?

      # Get current bracket levels from ActiveCache
      position = @active_cache.get_by_tracker_id(tracker.id)
      return failure_result('Position not found in ActiveCache') unless position

      new_sl = sl_price || position.sl_price
      new_tp = tp_price || position.tp_price

      return failure_result('Invalid SL/TP prices') unless new_sl&.positive? && new_tp&.positive?

      # Update ActiveCache
      updates = {}
      updates[:sl_price] = new_sl if sl_price
      updates[:tp_price] = new_tp if tp_price

      @active_cache.update_position(tracker.id, **updates)

      # Emit bracket modified event
      emit_bracket_modified_event(tracker, new_sl, new_tp, reason)

      @stats[:brackets_modified] += 1

      success_result(sl_price: new_sl, tp_price: new_tp, reason: reason)
    rescue StandardError => e
      @stats[:brackets_failed] += 1
      Rails.logger.error("[Orders::BracketPlacer] update_bracket failed: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
      failure_result(e.message)
    end
    # rubocop:enable Metrics/AbcSize

    # Move SL to breakeven (entry price)
    # @param tracker [PositionTracker] PositionTracker instance
    # @param reason [String] Reason for breakeven move
    # @return [Hash] Result hash
    def move_to_breakeven(tracker:, reason: 'breakeven_lock')
      return failure_result('Tracker not found') unless tracker
      return failure_result('Tracker not active') unless tracker.active?

      entry_price = tracker.entry_price.to_f
      return failure_result('Invalid entry price') unless entry_price.positive?

      # Update SL to entry price (breakeven)
      update_bracket(tracker: tracker, sl_price: entry_price, reason: reason)
    end

    # Move SL to trailing stop price
    # @param tracker [PositionTracker] PositionTracker instance
    # @param trailing_price [Float] Trailing stop price
    # @param reason [String] Reason for trailing move
    # @return [Hash] Result hash
    def move_to_trailing(tracker:, trailing_price:, reason: 'trailing_stop')
      return failure_result('Tracker not found') unless tracker
      return failure_result('Tracker not active') unless tracker.active?

      return failure_result('Invalid trailing price') unless trailing_price&.positive?

      # Update SL to trailing price
      update_bracket(tracker: tracker, sl_price: trailing_price, reason: reason)
    end

    # Get statistics
    # @return [Hash]
    def stats
      @stats.dup
    end

    private

    # Emit bracket placed event via EventBus
    # @param tracker [PositionTracker] PositionTracker instance
    # @param sl_price [Float] Stop loss price
    # @param tp_price [Float] Take profit price
    # @param reason [String] Reason
    def emit_bracket_placed_event(tracker, sl_price, tp_price, reason)
      event_data = {
        tracker_id: tracker.id,
        order_no: tracker.order_no,
        segment: tracker.segment,
        security_id: tracker.security_id,
        sl_price: sl_price,
        tp_price: tp_price,
        reason: reason,
        timestamp: Time.current
      }

      @event_bus.publish(Core::EventBus::EVENTS[:bracket_placed] || :bracket_placed, event_data)
      Rails.logger.info("[Orders::BracketPlacer] Emitted bracket_placed event for #{tracker.order_no}")
    rescue StandardError => e
      Rails.logger.error("[Orders::BracketPlacer] Failed to emit bracket_placed event: #{e.class} - #{e.message}")
    end

    # Emit bracket modified event via EventBus
    # @param tracker [PositionTracker] PositionTracker instance
    # @param sl_price [Float] New stop loss price
    # @param tp_price [Float] New take profit price
    # @param reason [String] Reason
    def emit_bracket_modified_event(tracker, sl_price, tp_price, reason)
      event_data = {
        tracker_id: tracker.id,
        order_no: tracker.order_no,
        segment: tracker.segment,
        security_id: tracker.security_id,
        sl_price: sl_price,
        tp_price: tp_price,
        reason: reason,
        timestamp: Time.current
      }

      @event_bus.publish(Core::EventBus::EVENTS[:bracket_modified] || :bracket_modified, event_data)
      Rails.logger.info("[Orders::BracketPlacer] Emitted bracket_modified event for #{tracker.order_no}")
    rescue StandardError => e
      Rails.logger.error("[Orders::BracketPlacer] Failed to emit bracket_modified event: #{e.class} - #{e.message}")
    end

    # Build success result hash
    # @param sl_price [Float] Stop loss price
    # @param tp_price [Float] Take profit price
    # @param reason [String] Reason
    # @return [Hash]
    def success_result(sl_price:, tp_price:, reason: nil)
      {
        success: true,
        sl_price: sl_price,
        tp_price: tp_price,
        reason: reason
      }
    end

    # Build failure result hash
    # @param error [String] Error message
    # @return [Hash]
    def failure_result(error)
      {
        success: false,
        error: error,
        sl_price: nil,
        tp_price: nil
      }
    end
  end
  # rubocop:enable Metrics/ClassLength
end


# File: app/services/orders/entry_manager.rb
# frozen_string_literal: true

module Orders
  # EntryManager for NEMESIS V3 architecture
  # Orchestrates entry order placement, validation, and position tracking
  # Integrates with Capital::Allocator, EntryGuard, Orders::Placer, and ActiveCache
  # rubocop:disable Metrics/ClassLength
  class EntryManager
    def initialize(event_bus: Core::EventBus.instance, active_cache: Positions::ActiveCache.instance)
      @event_bus = event_bus
      @active_cache = active_cache
      @stats = {
        entries_attempted: 0,
        entries_successful: 0,
        entries_failed: 0,
        validation_failures: 0,
        allocation_failures: 0
      }
    end

    # Process entry signal and place order
    # @param signal_result [Hash] Signal result with pick/candidate data
    # @param index_cfg [Hash] Index configuration
    # @param direction [Symbol] :bullish or :bearish
    # @param scale_multiplier [Integer] Scale multiplier for position sizing
    # @return [Hash] Result hash with :success, :tracker, :order_no, :error
    # rubocop:disable Metrics/AbcSize
    def process_entry(signal_result:, index_cfg:, direction:, scale_multiplier: 1)
      @stats[:entries_attempted] += 1

      # Extract pick/candidate from signal result
      pick = extract_pick(signal_result)
      return failure_result('No pick/candidate found in signal result') unless pick

      # Validate entry using EntryGuard
      unless Entries::EntryGuard.try_enter(
        index_cfg: index_cfg,
        pick: pick,
        direction: direction,
        scale_multiplier: scale_multiplier
      )
        @stats[:validation_failures] += 1
        return failure_result('Entry validation failed')
      end

      # EntryGuard already placed the order and created PositionTracker
      # We need to find the tracker and add it to ActiveCache
      tracker = find_tracker_for_pick(pick, index_cfg)
      unless tracker
        @stats[:entries_failed] += 1
        return failure_result('PositionTracker not found after entry')
      end

      # Calculate SL/TP prices
      sl_price, tp_price = calculate_sl_tp(tracker.entry_price, direction)

      # Add to ActiveCache
      position_data = @active_cache.add_position(
        tracker: tracker,
        sl_price: sl_price,
        tp_price: tp_price
      )

      unless position_data
        Rails.logger.warn("[Orders::EntryManager] Failed to add position to ActiveCache: #{tracker.id}")
      end

      # Emit entry_filled event
      emit_entry_filled_event(tracker, pick, index_cfg, direction, sl_price, tp_price)

      @stats[:entries_successful] += 1
      success_result(tracker: tracker, position_data: position_data, sl_price: sl_price, tp_price: tp_price)
    rescue StandardError => e
      @stats[:entries_failed] += 1
      Rails.logger.error("[Orders::EntryManager] process_entry failed: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
      failure_result(e.message)
    end
    # rubocop:enable Metrics/AbcSize

    # Get statistics
    # @return [Hash]
    def stats
      @stats.dup
    end

    private

    # Extract pick/candidate from signal result
    # Handles both old format (pick) and new format (candidate from DerivativeChainAnalyzer)
    # @param signal_result [Hash] Signal result
    # @return [Hash, nil] Pick/candidate hash
    def extract_pick(signal_result)
      # Try new format first (candidate from DerivativeChainAnalyzer)
      return signal_result[:candidate] if signal_result[:candidate]

      # Try old format (pick)
      return signal_result[:pick] if signal_result[:pick]

      # Try direct hash (signal_result itself might be the pick)
      return signal_result if signal_result.is_a?(Hash) && signal_result[:security_id].present?

      nil
    end

    # Find PositionTracker for a pick
    # @param pick [Hash] Pick/candidate data
    # @param index_cfg [Hash] Index configuration
    # @return [PositionTracker, nil]
    def find_tracker_for_pick(pick, index_cfg)
      segment = pick[:segment] || index_cfg[:segment]
      security_id = pick[:security_id]

      return nil unless segment.present? && security_id.present?

      # Try to find by security_id (most recent active)
      tracker = PositionTracker.active
                               .where(segment: segment, security_id: security_id.to_s)
                               .order(created_at: :desc)
                               .first

      return tracker if tracker

      # If not found, might be paper trading - check paper trackers
      PositionTracker.paper.active
                     .where(segment: segment, security_id: security_id.to_s)
                     .order(created_at: :desc)
                     .first
    end

    # Calculate SL/TP prices based on entry price and direction
    # @param entry_price [BigDecimal, Float] Entry price
    # @param direction [Symbol] :bullish or :bearish
    # @return [Array<Float, Float>] [sl_price, tp_price]
    def calculate_sl_tp(entry_price, direction)
      entry = entry_price.to_f
      return [nil, nil] unless entry.positive?

      # Default NEMESIS V3 values: SL = 30% below, TP = 60% above for long positions
      if direction == :bullish
        sl = entry * 0.70  # 30% below entry
        tp = entry * 1.60  # 60% above entry
      else
        # For bearish (PE), SL is above entry, TP is below entry
        sl = entry * 1.30  # 30% above entry
        tp = entry * 0.50  # 50% below entry (more conservative for PE)
      end

      [sl.round(2), tp.round(2)]
    end

    # Emit entry_filled event via EventBus
    # @param tracker [PositionTracker] PositionTracker instance
    # @param pick [Hash] Pick/candidate data
    # @param index_cfg [Hash] Index configuration
    # @param direction [Symbol] Direction
    # @param sl_price [Float] Stop loss price
    # @param tp_price [Float] Take profit price
    # rubocop:disable Metrics/ParameterLists
    def emit_entry_filled_event(tracker, pick, index_cfg, direction, sl_price, tp_price)
      event_data = {
        tracker_id: tracker.id,
        order_no: tracker.order_no,
        segment: tracker.segment,
        security_id: tracker.security_id,
        symbol: pick[:symbol] || tracker.symbol,
        entry_price: tracker.entry_price.to_f,
        quantity: tracker.quantity.to_i,
        direction: direction,
        index_key: index_cfg[:key],
        sl_price: sl_price,
        tp_price: tp_price,
        timestamp: Time.current
      }

      @event_bus.publish(Core::EventBus::EVENTS[:entry_filled], event_data)
      Rails.logger.info("[Orders::EntryManager] Emitted entry_filled event for #{tracker.order_no}")
    rescue StandardError => e
      Rails.logger.error("[Orders::EntryManager] Failed to emit entry_filled event: #{e.class} - #{e.message}")
    end
    # rubocop:enable Metrics/ParameterLists

    # Build success result hash
    # @param tracker [PositionTracker] PositionTracker instance
    # @param position_data [PositionData] ActiveCache position data
    # @param sl_price [Float] Stop loss price
    # @param tp_price [Float] Take profit price
    # @return [Hash]
    def success_result(tracker:, position_data:, sl_price:, tp_price:)
      {
        success: true,
        tracker: tracker,
        tracker_id: tracker.id,
        order_no: tracker.order_no,
        position_data: position_data,
        sl_price: sl_price,
        tp_price: tp_price
      }
    end

    # Build failure result hash
    # @param error [String] Error message
    # @return [Hash]
    def failure_result(error)
      {
        success: false,
        error: error,
        tracker: nil,
        tracker_id: nil,
        order_no: nil
      }
    end
  end
  # rubocop:enable Metrics/ClassLength
end


# File: app/services/orders/gateway.rb
# frozen_string_literal: true

module Orders
  class Gateway
    # ----------- PRIMARY EXIT METHOD ----------
    def exit_market(tracker)
      raise NotImplementedError, "#{self.class} must implement exit_market"
    end

    # ----------- ENTRY (BUY/SELL) -------------
    def place_market(side:, segment:, security_id:, qty:, meta: {})
      raise NotImplementedError, "#{self.class} must implement place_market"
    end

    # ----------- POSITION SNAPSHOT -------------
    def position(segment:, security_id:)
      raise NotImplementedError, "#{self.class} must implement position"
    end

    # ----------- WALLET ------------------------
    def wallet_snapshot
      raise NotImplementedError, "#{self.class} must implement wallet_snapshot"
    end

    # optional
    def on_tick(segment:, security_id:, ltp:)
      nil
    end
  end
end


# File: app/services/orders/gateway_live.rb
# frozen_string_literal: true

class Orders::GatewayLive < Orders::Gateway
  RETRY_COUNT   = 3
  RETRY_BACKOFF = 0.25
  API_TIMEOUT   = 8

  # ------------ EXIT -----------------
  def exit_market(tracker)
    coid = "AS-EXIT-#{tracker.security_id}-#{Time.now.to_i}"

    order = Orders::Placer.exit_position!(
      seg: tracker.segment,
      sid: tracker.security_id,
      client_order_id: coid
    )

    return { success: true } if order

    { success: false, error: 'exit failed' }
  end

  # ------------ ENTRY (BUY/SELL) -----
  def place_market(side:, segment:, security_id:, qty:, meta: {})
    validate_side!(side)
    coid = meta[:client_order_id] || generate_client_order_id(side, security_id)

    with_retries do
      if side.to_s.downcase == 'buy'
        Orders::Placer.buy_market!(
          seg: segment,
          sid: security_id,
          qty: qty,
          client_order_id: coid,
          price: meta[:price],
          target_price: meta[:target_price],
          stop_loss_price: meta[:stop_loss_price],
          product_type: meta[:product_type]
        )
      else
        Orders::Placer.sell_market!(
          seg: segment,
          sid: security_id,
          qty: qty,
          client_order_id: coid,
          product_type: meta[:product_type]
        )
      end
    end
  end

  # ------------ POSITION SNAPSHOT ----
  def position(segment:, security_id:)
    positions = fetch_positions
    pos = positions.find do |p|
      p.security_id.to_s == security_id.to_s &&
        p.exchange_segment.to_s == segment.to_s
    end

    return nil unless pos

    {
      qty: pos.net_qty.to_i,
      avg_price: BigDecimal(pos.cost_price.to_s),
      product_type: pos.product_type,
      exchange_segment: pos.exchange_segment,
      position_type: pos.position_type,
      trading_symbol: pos.trading_symbol
    }
  end

  # ------------ WALLET ---------------
  def wallet_snapshot
    funds = DhanHQ::Models::FundLimit.fetch
    { cash: funds.available, utilized: funds.utilized, margin: funds.margin }
  rescue StandardError => e
    Rails.logger.error("[GatewayLive] wallet snapshot failed: #{e.message}")
    {}
  end

  private

  def validate_side!(side)
    raise 'invalid side' unless %w[buy sell].include?(side.to_s)
  end

  def with_retries
    attempts = 0
    begin
      attempts += 1
      Timeout.timeout(API_TIMEOUT) { return yield }
    rescue StandardError => e
      Rails.logger.warn("[GatewayLive] attempt #{attempts} failed #{e.class}: #{e.message}")
      raise if attempts >= RETRY_COUNT

      sleep RETRY_BACKOFF * attempts
      retry
    end
  end

  def fetch_positions
    DhanHQ::Models::Position.active
  rescue StandardError => e
    Rails.logger.error("[GatewayLive] fetch_positions error: #{e.message}")
    []
  end

  def generate_client_order_id(prefix, sid)
    "AS-#{prefix}-#{sid}-#{Time.now.to_i}"
  end
end


# File: app/services/orders/gateway_paper.rb
# frozen_string_literal: true

class Orders::GatewayPaper < Orders::Gateway
  def exit_market(tracker)
    ltp = Live::TickCache.ltp(tracker.segment, tracker.security_id) ||
          tracker.entry_price

    exit_price = BigDecimal(ltp.to_s)

    tracker.mark_exited!(
      exit_price: exit_price,
      exit_reason: 'paper exit'
    )

    { success: true, exit_price: exit_price }
  end

  def place_market(side:, segment:, security_id:, qty:, meta: {})
    tracker = PositionTracker.active_for(segment, security_id)
    tracker ||= PositionTracker.create!(
      instrument_id: nil,
      order_no: "PAPER-#{SecureRandom.hex(3)}",
      security_id: security_id.to_s,
      symbol: meta[:symbol] || security_id.to_s,
      segment: segment,
      side: side.to_s.upcase,
      status: 'active',
      quantity: qty,
      avg_price: meta[:price] || 0
    )

    { success: true, paper: true, tracker_id: tracker.id }
  end

  def position(segment:, security_id:)
    tracker = PositionTracker.active_for(segment, security_id)
    return nil unless tracker

    {
      qty: tracker.quantity,
      avg_price: tracker.avg_price,
      status: tracker.status
    }
  end

  def wallet_snapshot
    balance = AlgoConfig.fetch.dig(:paper_trading, :balance) || 100_000
    { cash: balance, equity: balance, mtm: 0, exposure: 0 }
  end
end


# File: app/services/orders/manager.rb
# frozen_string_literal: true

module Orders
  class Manager
    class << self
      def place_market_buy(segment:, security_id:, qty:, reason:, metadata: {})
        return unless segment.present? && security_id.present?

        client_order_id = build_client_order_id(segment, security_id, reason)
        Rails.logger.info(
          "[Orders::Manager] BUY #{segment}-#{security_id} qty=#{qty} reason=#{reason} metadata=#{metadata.inspect}"
        )

        Orders::Placer.buy_market!(
          seg: segment,
          sid: security_id,
          qty: qty,
          client_order_id: client_order_id
        )
      end

      private

      def build_client_order_id(segment, security_id, reason)
        normalized_reason = reason.to_s.parameterize.presence || 'signal'
        timestamp = Time.current.strftime('%H%M%S')
        "#{segment}-#{security_id}-#{normalized_reason}-#{timestamp}"
      end
    end
  end
end



# File: app/services/orders/placer.rb
# frozen_string_literal: true

require 'digest'

module Orders
  class Placer
    class << self
      def buy_market!(seg:, sid:, qty:, client_order_id:, product_type: 'INTRADAY', price: nil,
                      target_price: nil, stop_loss_price: nil, trailing_jump: nil)
        normalized_id = normalize_client_order_id(client_order_id)
        return nil if duplicate?(normalized_id)

        unless seg && sid && qty && normalized_id
          Rails.logger.error("[Orders::Placer] Missing required parameters for buy_market!: seg=#{seg}, sid=#{sid}, qty=#{qty}, client_order_id=#{client_order_id}")
          return nil
        end

        payload = {
          dhanClientId: DhanHQ.configuration.client_id || ENV['DHANHQ_CLIENT_ID'] || ENV.fetch('CLIENT_ID', nil),
          transactionType: 'BUY',
          exchangeSegment: seg,
          securityId: sid.to_s,
          quantity: qty.to_i,
          orderType: 'MARKET',
          productType: product_type,
          validity: 'DAY',
          correlationId: normalized_id,
          disclosedQuantity: 0
        }
        payload[:price] = price if price.present?
        payload[:boProfitValue] = target_price if target_price.present?
        payload[:boStopLossValue] = stop_loss_price if stop_loss_price.present?

        Rails.logger.info("[Orders::Placer] BUY payload: #{payload.inspect}")

        if order_placement_enabled?
          begin
            order = DhanHQ::Models::Order.create(payload)
            Rails.logger.info("[Orders::Placer] BUY response: #{order.inspect}")
          rescue StandardError => e
            Rails.logger.error("[Orders::Placer] BUY failed: #{e.class} - #{e.message}")
            order = nil
          end
        else
          Rails.logger.debug('[Orders::Placer] BUY dry-run disabled order placement')
          order = nil
        end

        remember(normalized_id)
        order
      end

      def sell_market!(seg:, sid:, qty:, client_order_id:, product_type: nil)
        normalized_id = normalize_client_order_id(client_order_id)
        return nil if duplicate?(normalized_id)

        unless seg && sid && normalized_id
          Rails.logger.error("[Orders::Placer] Missing required parameters for sell_market!: seg=#{seg}, sid=#{sid}, client_order_id=#{client_order_id}")
          return nil
        end

        position = fetch_position_details(sid)

        actual_qty = if position && position[:net_qty].to_i > 0
                       position[:net_qty]
                     else
                       qty
                     end

        payload = {
          dhanClientId: DhanHQ.configuration.client_id || ENV['DHANHQ_CLIENT_ID'] || ENV.fetch('CLIENT_ID', nil),
          transactionType: 'SELL',
          exchangeSegment: position ? position[:exchange_segment] : seg,
          securityId: sid.to_s,
          quantity: actual_qty.to_i,
          orderType: 'MARKET',
          productType: position ? position[:product_type] : product_type,
          validity: 'DAY',
          disclosedQuantity: 0,
          correlationId: normalized_id
        }

        Rails.logger.info("[Orders::Placer] SELL payload: #{payload.inspect}")

        if order_placement_enabled?
          begin
            order = DhanHQ::Models::Order.create(payload)
            Rails.logger.info("[Orders::Placer] SELL response: #{order.inspect}")
          rescue StandardError => e
            Rails.logger.error("[Orders::Placer] SELL failed: #{e.class} - #{e.message}")
            order = nil
          end
        else
          Rails.logger.debug('[Orders::Placer] SELL dry-run disabled order placement')
          order = nil
        end

        remember(normalized_id)
        order
      end

      def exit_position!(seg:, sid:, client_order_id:)
        normalized_id = normalize_client_order_id(client_order_id)
        return nil if duplicate?(normalized_id)

        unless sid && normalized_id
          Rails.logger.error("[Orders::Placer] Missing required parameters for exit_position!: sid=#{sid}, client_order_id=#{client_order_id}")
          return nil
        end

        position_details = fetch_position_details(sid)
        unless position_details
          Rails.logger.error("[Orders::Placer] Cannot find position to exit for sid=#{sid}")
          return nil
        end

        actual_qty = position_details[:net_qty]
        actual_segment = position_details[:exchange_segment]
        position_type = position_details[:position_type]

        transaction_type = case position_type
                           when 'LONG' then 'SELL'
                           when 'SHORT' then 'BUY'
                           else
                             Rails.logger.error("[Orders::Placer] Unknown position type #{position_type}")
                             return nil
                           end

        payload = {
          dhanClientId: DhanHQ.configuration.client_id || ENV['DHANHQ_CLIENT_ID'] || ENV.fetch('CLIENT_ID', nil),
          transactionType: transaction_type,
          exchangeSegment: actual_segment,
          securityId: sid.to_s,
          quantity: actual_qty.to_i,
          orderType: 'MARKET',
          productType: position_details[:product_type],
          validity: 'DAY',
          disclosedQuantity: 0,
          correlationId: normalized_id
        }

        Rails.logger.info("[Orders::Placer] EXIT payload: #{payload.inspect}")

        if order_placement_enabled?
          begin
            order = DhanHQ::Models::Order.create(payload)
            Rails.logger.info("[Orders::Placer] EXIT response: #{order.inspect}")
          rescue StandardError => e
            Rails.logger.error("[Orders::Placer] EXIT failed: #{e.class} - #{e.message}")
            order = nil
          end
        else
          Rails.logger.debug('[Orders::Placer] EXIT dry-run disabled order placement')
          order = nil
        end

        remember(normalized_id)
        order
      end

      private

      def fetch_position_details(security_id)
        positions = DhanHQ::Models::Position.active
        pos = positions.find { |p| p.security_id.to_s == security_id.to_s }
        return nil unless pos

        {
          product_type: pos.respond_to?(:product_type) ? pos.product_type : pos[:product_type],
          net_qty: pos.respond_to?(:net_qty) ? pos.net_qty.to_i : (pos[:net_qty] || pos[:quantity]).to_i,
          exchange_segment: pos.respond_to?(:exchange_segment) ? pos.exchange_segment : pos[:exchange_segment],
          position_type: pos.respond_to?(:position_type) ? pos.position_type : (pos[:position_type] || 'LONG'),
          buy_avg: pos.respond_to?(:buy_avg) ? pos.buy_avg : nil,
          trading_symbol: pos.respond_to?(:trading_symbol) ? pos.trading_symbol : pos[:trading_symbol]
        }
      rescue StandardError => e
        Rails.logger.error("[Orders::Placer] fetch_position_details error: #{e.class} - #{e.message}")
        nil
      end

      def order_placement_enabled?
        cfg = begin
          Rails.application.config.x.dhanhq
        rescue StandardError
          nil
        end
        (cfg && cfg.enable_order_logging == true) || AlgoConfig.fetch.dig(:dhanhq, :enable_orders) == true
      rescue StandardError
        false
      end

      def duplicate?(client_order_id)
        return false if client_order_id.blank?

        Rails.cache.read("coid:#{client_order_id}").present?
      end

      def remember(client_order_id)
        return if client_order_id.blank?

        Rails.cache.write("coid:#{client_order_id}", true, expires_in: 20.minutes)
      end

      def normalize_client_order_id(client_order_id)
        return if client_order_id.blank?

        value = client_order_id.to_s.strip
        return if value.blank?
        return value if value.length <= 30

        digest = Digest::SHA1.hexdigest(value)[0, 6]
        base = value[0, 23]
        "#{base}-#{digest}"
      end
    end
  end
end


# File: app/services/positions/active_cache.rb
# frozen_string_literal: true

require 'singleton'
require 'concurrent/map'

module Positions
  # Ultra-fast in-memory position cache for NEMESIS V3
  # Mirrors Redis PnL + RedisTickCache for sub-millisecond lookups
  # Subscribes to EventBus LTP events for real-time updates
  # rubocop:disable Metrics/ClassLength
  class ActiveCache
    include Singleton

    # Position data structure
    PositionData = Struct.new(
      :tracker_id,
      :security_id,
      :segment,
      :entry_price,
      :quantity,
      :sl_price,
      :tp_price,
      :high_water_mark,
      :current_ltp,
      :pnl,
      :pnl_pct,
      :trend,
      :time_in_position,
      :breakeven_locked,
      :trailing_stop_price,
      :last_updated_at,
      keyword_init: true
    ) do
      def composite_key
        "#{segment}:#{security_id}"
      end

      def valid?
        entry_price&.positive? && current_ltp&.positive?
      end

      def sl_hit?
        return false unless sl_price && current_ltp

        # For long positions (CE), SL is below entry
        current_ltp <= sl_price
      end

      def tp_hit?
        return false unless tp_price && current_ltp

        # For long positions (CE), TP is above entry
        current_ltp >= tp_price
      end

      def update_ltp(ltp, timestamp: Time.current)
        self.current_ltp = ltp.to_f
        self.last_updated_at = timestamp
        recalculate_pnl
      end

      def recalculate_pnl
        return unless entry_price&.positive? && current_ltp&.positive? && quantity&.positive?

        self.pnl = (current_ltp - entry_price) * quantity
        self.pnl_pct = ((current_ltp - entry_price) / entry_price * 100.0).round(4)

        # Update HWM
        self.high_water_mark = pnl if high_water_mark.nil? || pnl > high_water_mark
      end
    end

    def initialize
      @cache = Concurrent::Map.new # composite_key => PositionData
      @tracker_index = Concurrent::Map.new # tracker_id => composite_key
      @lock = Mutex.new
      @event_bus = Core::EventBus.instance
      @subscription_id = nil
      @stats = {
        positions_tracked: 0,
        updates_processed: 0,
        errors: 0
      }
    end

    # Start the cache (subscribe to EventBus)
    # @return [Boolean] True if started successfully
    def start!
      return true if @subscription_id

      @subscription_id = @event_bus.subscribe(:ltp) { |event| handle_ltp_event(event) }
      Rails.logger.info('[Positions::ActiveCache] Started and subscribed to LTP events')
      true
    rescue StandardError => e
      Rails.logger.error("[Positions::ActiveCache] Failed to start: #{e.class} - #{e.message}")
      false
    end

    # Stop the cache (unsubscribe from EventBus)
    # @return [Boolean] True if stopped successfully
    def stop!
      return false unless @subscription_id

      @event_bus.unsubscribe(@subscription_id)
      @subscription_id = nil
      Rails.logger.info('[Positions::ActiveCache] Stopped and unsubscribed from LTP events')
      true
    rescue StandardError => e
      Rails.logger.error("[Positions::ActiveCache] Failed to stop: #{e.class} - #{e.message}")
      false
    end

    # Add or update a position in the cache
    # @param tracker [PositionTracker] PositionTracker instance
    # @param sl_price [Float, nil] Stop loss price
    # @param tp_price [Float, nil] Take profit price
    # @return [PositionData] The cached position data
    # rubocop:disable Metrics/AbcSize
    def add_position(tracker:, sl_price: nil, tp_price: nil)
      return nil unless tracker.active?
      return nil unless tracker.entry_price&.positive?

      composite_key = "#{tracker.segment}:#{tracker.security_id}"

      position_data = PositionData.new(
        tracker_id: tracker.id,
        security_id: tracker.security_id.to_s,
        segment: tracker.segment.to_s,
        entry_price: tracker.entry_price.to_f,
        quantity: tracker.quantity.to_i,
        sl_price: sl_price&.to_f,
        tp_price: tp_price&.to_f,
        high_water_mark: tracker.high_water_mark_pnl.to_f,
        current_ltp: nil, # Will be updated on next LTP event
        pnl: 0.0,
        pnl_pct: 0.0,
        trend: :neutral, # Will be determined from price action
        time_in_position: Time.current - tracker.created_at,
        breakeven_locked: tracker.breakeven_locked?,
        trailing_stop_price: tracker.trailing_stop_price&.to_f,
        last_updated_at: Time.current
      )

      @cache[composite_key] = position_data
      @tracker_index[tracker.id] = composite_key
      @stats[:positions_tracked] = @cache.size

      # Try to get current LTP from cache
      ltp = Live::TickCache.ltp(tracker.segment, tracker.security_id)
      position_data.update_ltp(ltp) if ltp&.positive?

      Rails.logger.debug { "[Positions::ActiveCache] Added position #{tracker.id} (#{composite_key})" }
      position_data
    rescue StandardError => e
      @stats[:errors] += 1
      Rails.logger.error("[Positions::ActiveCache] Failed to add position #{tracker.id}: #{e.class} - #{e.message}")
      nil
    end
    # rubocop:enable Metrics/AbcSize

    # Remove a position from the cache
    # @param tracker_id [Integer] PositionTracker ID
    # @return [Boolean] True if removed
    def remove_position(tracker_id)
      composite_key = @tracker_index.delete(tracker_id)
      return false unless composite_key

      @cache.delete(composite_key)
      @stats[:positions_tracked] = @cache.size
      Rails.logger.debug { "[Positions::ActiveCache] Removed position #{tracker_id} (#{composite_key})" }
      true
    rescue StandardError => e
      @stats[:errors] += 1
      Rails.logger.error("[Positions::ActiveCache] Failed to remove position #{tracker_id}: #{e.class} - #{e.message}")
      false
    end

    # Get position data by composite key
    # @param segment [String] Exchange segment
    # @param security_id [String] Security ID
    # @return [PositionData, nil]
    def get(segment, security_id)
      composite_key = "#{segment}:#{security_id}"
      @cache[composite_key]
    end

    # Get position data by tracker ID
    # @param tracker_id [Integer] PositionTracker ID
    # @return [PositionData, nil]
    def get_by_tracker_id(tracker_id)
      composite_key = @tracker_index[tracker_id]
      return nil unless composite_key

      @cache[composite_key]
    end

    # Get all active positions
    # @return [Array<PositionData>]
    def all_positions
      @cache.values
    end

    # Get positions for a specific security
    # @param segment [String] Exchange segment
    # @param security_id [String] Security ID
    # @return [Array<PositionData>]
    def positions_for(segment, security_id)
      composite_key = "#{segment}:#{security_id}"
      position = @cache[composite_key]
      position ? [position] : []
    end

    # Update position metadata (SL, TP, breakeven, etc.)
    # @param tracker_id [Integer] PositionTracker ID
    # @param updates [Hash] Hash of updates (sl_price, tp_price, breakeven_locked, etc.)
    # @return [Boolean] True if updated
    def update_position(tracker_id, **updates)
      position = get_by_tracker_id(tracker_id)
      return false unless position

      updates.each do |key, value|
        position[key] = value if position.respond_to?("#{key}=")
      end

      position.last_updated_at = Time.current
      Rails.logger.debug { "[Positions::ActiveCache] Updated position #{tracker_id}: #{updates.keys.join(', ')}" }
      true
    rescue StandardError => e
      @stats[:errors] += 1
      Rails.logger.error("[Positions::ActiveCache] Failed to update position #{tracker_id}: #{e.class} - #{e.message}")
      false
    end

    # Bulk load positions from database
    # @return [Integer] Number of positions loaded
    def bulk_load!
      count = 0
      PositionTracker.active.find_each do |tracker|
        next unless tracker.entry_price&.positive?

        # Try to get SL/TP from meta or calculate defaults
        sl_price = calculate_default_sl(tracker)
        tp_price = calculate_default_tp(tracker)

        add_position(tracker: tracker, sl_price: sl_price, tp_price: tp_price)
        count += 1
      end

      Rails.logger.info("[Positions::ActiveCache] Bulk loaded #{count} positions")
      count
    rescue StandardError => e
      Rails.logger.error("[Positions::ActiveCache] Bulk load failed: #{e.class} - #{e.message}")
      0
    end

    # Clear all positions
    # @return [Boolean]
    def clear
      @cache.clear
      @tracker_index.clear
      @stats[:positions_tracked] = 0
      Rails.logger.info('[Positions::ActiveCache] Cleared all positions')
      true
    end

    # Get statistics
    # @return [Hash]
    def stats
      @stats.merge(positions_tracked: @cache.size)
    end

    private

    # Handle LTP event from EventBus
    # @param event [Live::LtpEvent] LTP event
    def handle_ltp_event(event)
      return unless event.valid?

      positions = positions_for(event.segment, event.security_id)
      return if positions.empty?

      positions.each do |position|
        position.update_ltp(event.ltp, timestamp: event.timestamp)
        @stats[:updates_processed] += 1

        # Check for SL/TP hits and emit events
        check_exit_triggers(position, event)
      end
    rescue StandardError => e
      @stats[:errors] += 1
      Rails.logger.error("[Positions::ActiveCache] Error handling LTP event: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
    end

    # Check for SL/TP hits and emit events
    # @param position [PositionData] Position data
    # @param event [Live::LtpEvent] LTP event
    def check_exit_triggers(position, event)
      if position.sl_hit?
        @event_bus.publish(Core::EventBus::EVENTS[:sl_hit], {
                             tracker_id: position.tracker_id,
                             position: position,
                             event: event
                           })
        return
      end

      return unless position.tp_hit?

      @event_bus.publish(Core::EventBus::EVENTS[:tp_hit], {
                           tracker_id: position.tracker_id,
                           position: position,
                           event: event
                         })
    end

    # Calculate default SL from tracker (30% below entry for CE)
    # @param tracker [PositionTracker] PositionTracker instance
    # @return [Float, nil]
    def calculate_default_sl(tracker)
      return nil unless tracker.entry_price&.positive?

      # Default: 30% below entry for long positions
      tracker.entry_price.to_f * 0.70
    end

    # Calculate default TP from tracker (60% above entry for CE)
    # @param tracker [PositionTracker] PositionTracker instance
    # @return [Float, nil]
    def calculate_default_tp(tracker)
      return nil unless tracker.entry_price&.positive?

      # Default: 60% above entry for long positions
      tracker.entry_price.to_f * 1.60
    end
  end
  # rubocop:enable Metrics/ClassLength
end


# File: app/services/positions/high_water_mark.rb
# frozen_string_literal: true

module Positions
  # High Water Mark (HWM) tracking and calculation helper
  # Provides utilities for trailing stop calculations and HWM-based exits
  class HighWaterMark
    # Calculate trailing stop threshold based on HWM
    # @param hwm [Float] High water mark PnL
    # @param drop_pct [Float] Percentage drop from HWM to trigger (e.g., 0.20 for 20%)
    # @return [Float] Trailing stop threshold
    def self.trailing_threshold(hwm, drop_pct)
      return 0.0 unless hwm&.positive? && drop_pct&.positive?

      hwm * (1.0 - drop_pct)
    end

    # Check if current PnL has dropped below trailing threshold
    # @param current_pnl [Float] Current PnL
    # @param hwm [Float] High water mark PnL
    # @param drop_pct [Float] Percentage drop from HWM to trigger
    # @return [Boolean] True if trailing stop should trigger
    def self.trailing_triggered?(current_pnl, hwm, drop_pct)
      return false unless hwm&.positive? && current_pnl

      threshold = trailing_threshold(hwm, drop_pct)
      current_pnl <= threshold
    end

    # Calculate HWM-based exit price for long positions
    # @param entry_price [Float] Entry price
    # @param hwm_pnl [Float] High water mark PnL (in rupees)
    # @param quantity [Integer] Position quantity
    # @return [Float] Exit price based on HWM
    def self.hwm_exit_price(entry_price, hwm_pnl, quantity)
      return nil unless entry_price&.positive? && hwm_pnl && quantity&.positive?

      hwm_price = entry_price + (hwm_pnl / quantity.to_f)
      hwm_price.round(2)
    end

    # Calculate percentage gain from entry to HWM
    # @param entry_price [Float] Entry price
    # @param hwm_price [Float] High water mark price
    # @return [Float] Percentage gain
    def self.hwm_gain_pct(entry_price, hwm_price)
      return 0.0 unless entry_price&.positive? && hwm_price&.positive?

      ((hwm_price - entry_price) / entry_price * 100.0).round(4)
    end

    # Calculate drawdown from HWM
    # @param current_pnl [Float] Current PnL
    # @param hwm [Float] High water mark PnL
    # @return [Float] Drawdown percentage (0.0 to 1.0)
    def self.drawdown_from_hwm(current_pnl, hwm)
      return 0.0 unless hwm&.positive? && current_pnl

      if current_pnl >= hwm
        0.0
      else
        ((hwm - current_pnl) / hwm).round(4)
      end
    end

    # Check if position should lock breakeven based on HWM
    # @param hwm_pnl [Float] High water mark PnL
    # @param min_profit_for_lock [Float] Minimum profit required to lock breakeven
    # @return [Boolean] True if breakeven should be locked
    def self.should_lock_breakeven?(hwm_pnl, min_profit_for_lock)
      return false unless hwm_pnl && min_profit_for_lock

      hwm_pnl >= min_profit_for_lock
    end

    # Calculate trailing stop price based on HWM
    # @param entry_price [Float] Entry price
    # @param hwm_price [Float] High water mark price
    # @param trail_pct [Float] Trailing percentage (e.g., 0.20 for 20% from HWM)
    # @return [Float] Trailing stop price
    def self.trailing_stop_price(entry_price, hwm_price, trail_pct)
      return nil unless entry_price&.positive? && hwm_price&.positive? && trail_pct&.positive?

      # Trailing stop is trail_pct below HWM price
      stop_price = hwm_price * (1.0 - trail_pct)
      # But never below entry (for long positions)
      [stop_price, entry_price].max.round(2)
    end
  end
end


# File: app/services/risk/circuit_breaker.rb
# frozen_string_literal: true

require 'singleton'

module Risk
  class CircuitBreaker
    include Singleton

    TRIP_CACHE_KEY = 'risk:circuit_breaker:tripped'

    def tripped?
      !!Rails.cache.read(TRIP_CACHE_KEY)
    end

    def trip!(reason: nil, ttl: 8.hours)
      payload = { at: Time.current, reason: reason }
      Rails.cache.write(TRIP_CACHE_KEY, payload, expires_in: ttl)
      payload
    end

    def reset!
      Rails.cache.delete(TRIP_CACHE_KEY)
      true
    end

    def status
      data = Rails.cache.read(TRIP_CACHE_KEY)
      return { tripped: false } unless data

      { tripped: true, at: data[:at], reason: data[:reason] }
    end
  end
end


# File: app/services/signal/engine.rb
# frozen_string_literal: true

module Signal
  class Engine
    class << self
      def run_for(index_cfg)
        Rails.logger.info("\n\n[Signal] ----------------------------------------------------- Starting analysis for #{index_cfg[:key]} (IDX_I) --------------------------------------------------------")

        signals_cfg = AlgoConfig.fetch[:signals] || {}
        primary_tf = (signals_cfg[:primary_timeframe] || signals_cfg[:timeframe] || '5m').to_s
        enable_confirmation = signals_cfg.fetch(:enable_confirmation_timeframe, true)
        confirmation_tf = (signals_cfg[:confirmation_timeframe].presence&.to_s if enable_confirmation)

        # Check if strategy-based recommendations are enabled
        use_strategy_recommendations = signals_cfg.fetch(:use_strategy_recommendations, false)

        # Rails.logger.debug { "[Signal] Primary timeframe: #{primary_tf}, confirmation timeframe: #{confirmation_tf || 'none'} (enabled: #{enable_confirmation})" }

        instrument = IndexInstrumentCache.instance.get_or_fetch(index_cfg)
        unless instrument
          Rails.logger.error("[Signal] Could not find instrument for #{index_cfg[:key]}")
          return
        end

        # Get strategy recommendation if enabled - use best strategy for this index
        strategy_recommendation = nil
        effective_timeframe = primary_tf
        if use_strategy_recommendations
          # Get best strategy for this index (across all timeframes)
          strategy_recommendation = StrategyRecommender.best_for_index(symbol: index_cfg[:key])
          if strategy_recommendation && strategy_recommendation[:recommended]
            # Use the recommended strategy's timeframe instead of config timeframe
            effective_timeframe = "#{strategy_recommendation[:interval]}m"
            Rails.logger.info("[Signal] Using recommended strategy for #{index_cfg[:key]}: #{strategy_recommendation[:strategy_name]} (#{strategy_recommendation[:interval]}min) - Expectancy: #{strategy_recommendation[:expectancy]}% | Switching timeframe from #{primary_tf} to #{effective_timeframe}")
          elsif strategy_recommendation
            Rails.logger.warn("[Signal] Strategy recommendation found for #{index_cfg[:key]} but not recommended (negative expectancy: #{strategy_recommendation[:expectancy]}%) - falling back to Supertrend+ADX")
            strategy_recommendation = nil
          else
            Rails.logger.warn("[Signal] No strategy recommendation found for #{index_cfg[:key]} - falling back to Supertrend+ADX")
          end
        end

        # Use strategy-based analysis if recommendation is available and enabled
        if use_strategy_recommendations && strategy_recommendation && strategy_recommendation[:recommended]
          primary_analysis = analyze_with_recommended_strategy(
            index_cfg: index_cfg,
            instrument: instrument,
            timeframe: effective_timeframe,
            strategy_recommendation: strategy_recommendation
          )
        else
          # Fallback to traditional Supertrend + ADX analysis
          supertrend_cfg = signals_cfg[:supertrend]
          unless supertrend_cfg
            Rails.logger.error("[Signal] Supertrend configuration missing for #{index_cfg[:key]}")
            return
          end

          adx_cfg = signals_cfg[:adx] || {}
          enable_adx_filter = signals_cfg.fetch(:enable_adx_filter, true)
          # Only apply ADX filter if enabled, otherwise use 0 to bypass filter
          adx_min_strength = enable_adx_filter ? adx_cfg[:min_strength] : 0

          primary_analysis = analyze_timeframe(
            index_cfg: index_cfg,
            instrument: instrument,
            timeframe: primary_tf,
            supertrend_cfg: supertrend_cfg,
            adx_min_strength: adx_min_strength
          )
        end

        unless primary_analysis[:status] == :ok
          Rails.logger.warn("[Signal] Primary timeframe analysis unavailable for #{index_cfg[:key]}: #{primary_analysis[:message]}")
          Signal::StateTracker.reset(index_cfg[:key])
          return
        end

        final_direction = primary_analysis[:direction]
        confirmation_analysis = nil

        # Skip confirmation timeframe when using strategy recommendations
        # (strategies were backtested as standalone systems)
        if confirmation_tf.present? && !(use_strategy_recommendations && strategy_recommendation && strategy_recommendation[:recommended])
          mode_config = get_validation_mode_config
          # Only apply ADX filter if enabled, otherwise use 0 to bypass filter
          confirmation_adx_min = if enable_adx_filter
                                   mode_config[:adx_confirmation_min_strength] || adx_cfg[:confirmation_min_strength] || adx_cfg[:min_strength]
                                 else
                                   0
                                 end

          confirmation_analysis = analyze_timeframe(
            index_cfg: index_cfg,
            instrument: instrument,
            timeframe: confirmation_tf,
            supertrend_cfg: supertrend_cfg,
            adx_min_strength: confirmation_adx_min
          )

          unless confirmation_analysis[:status] == :ok
            Rails.logger.warn("[Signal] Confirmation timeframe analysis unavailable for #{index_cfg[:key]}: #{confirmation_analysis[:message]}")
            Signal::StateTracker.reset(index_cfg[:key])
            return
          end

          final_direction = multi_timeframe_direction(primary_analysis[:direction], confirmation_analysis[:direction])
          # Rails.logger.info("[Signal] Multi-timeframe decision for #{index_cfg[:key]}: primary=#{primary_analysis[:direction]} confirmation=#{confirmation_analysis[:direction]} final=#{final_direction}")
        elsif confirmation_tf.present? && use_strategy_recommendations && strategy_recommendation && strategy_recommendation[:recommended]
          Rails.logger.info("[Signal] Skipping confirmation timeframe for #{index_cfg[:key]} (using strategy recommendation: #{strategy_recommendation[:strategy_name]})")
        end

        if final_direction == :avoid
          if use_strategy_recommendations && strategy_recommendation && strategy_recommendation[:recommended]
            Rails.logger.info("[Signal] NOT proceeding for #{index_cfg[:key]}: #{strategy_recommendation[:strategy_name]} did not generate a signal (conditions not met)")
          else
            Rails.logger.info("[Signal] NOT proceeding for #{index_cfg[:key]}: multi-timeframe bias mismatch or weak trend")
          end
          Signal::StateTracker.reset(index_cfg[:key])
          return
        end

        primary_series = primary_analysis[:series]
        validation_result = comprehensive_validation(index_cfg, final_direction, primary_series,
                                                     primary_analysis[:supertrend], { value: primary_analysis[:adx_value] })
        unless validation_result[:valid]
          Rails.logger.warn("[Signal] NOT proceeding for #{index_cfg[:key]}: #{validation_result[:reason]}")
          Signal::StateTracker.reset(index_cfg[:key])
          return
        end

        Rails.logger.info("[Signal] Proceeding with #{final_direction} signal for #{index_cfg[:key]}")

        # Get state snapshot first for signal persistence
        state_snapshot = Signal::StateTracker.record(
          index_key: index_cfg[:key],
          direction: final_direction,
          candle_timestamp: primary_analysis[:last_candle_timestamp],
          config: signals_cfg
        )

        # Persist signal with confidence score
        confidence_score = calculate_confidence_score(
          primary_analysis: primary_analysis,
          confirmation_analysis: confirmation_analysis,
          validation_result: validation_result
        )

        TradingSignal.create_from_analysis(
          index_key: index_cfg[:key],
          direction: final_direction.to_s,
          timeframe: effective_timeframe,
          supertrend_value: primary_analysis[:supertrend][:last_value],
          adx_value: primary_analysis[:adx_value],
          candle_timestamp: primary_analysis[:last_candle_timestamp],
          confidence_score: confidence_score,
          metadata: {
            confirmation_timeframe: confirmation_tf,
            confirmation_direction: confirmation_analysis&.dig(:direction),
            validation_passed: validation_result[:valid],
            state_count: state_snapshot[:count],
            state_multiplier: state_snapshot[:multiplier],
            strategy_used: strategy_recommendation&.dig(:strategy_name),
            original_timeframe: primary_tf
          }
        )

        # Rails.logger.info("[Signal] Signal state for #{index_cfg[:key]}: count=#{state_snapshot[:count]} multiplier=#{state_snapshot[:multiplier]}")

        picks = Options::ChainAnalyzer.pick_strikes(index_cfg: index_cfg, direction: final_direction)

        if picks.blank?
          Rails.logger.warn("[Signal] No suitable option strikes found for #{index_cfg[:key]} #{final_direction}")
          return
        end

        Rails.logger.info("[Signal] Found #{picks.size} option picks for #{index_cfg[:key]}: #{picks.pluck(:symbol).join(', ')}")

        picks.each_with_index do |pick, _index|
          # Rails.logger.info("[Signal] Attempting entry #{index + 1}/#{picks.size} for #{index_cfg[:key]}: #{pick[:symbol]} (scale x#{state_snapshot[:multiplier]})")
          result = Entries::EntryGuard.try_enter(
            index_cfg: index_cfg,
            pick: pick,
            direction: final_direction,
            scale_multiplier: state_snapshot[:multiplier]
          )

          if result
            # Rails.logger.info("[Signal] Entry successful for #{index_cfg[:key]}: #{pick[:symbol]}")
          else
            Rails.logger.debug("[Signal] Entry failed for #{index_cfg[:key]}: #{pick[:symbol]} #{result}")
          end
        end

        # Rails.logger.info("[Signal] Completed analysis for #{index_cfg[:key]}")
      rescue StandardError => e
        Rails.logger.error("[Signal] #{index_cfg[:key]} #{e.class} #{e.message}")
        Rails.logger.error("[Signal] Backtrace: #{e.backtrace.first(5).join(', ')}")
      end

      def analyze_timeframe(index_cfg:, instrument:, timeframe:, supertrend_cfg:, adx_min_strength:)
        interval = normalize_interval(timeframe)
        if interval.blank?
          message = "Invalid timeframe '#{timeframe}'"
          Rails.logger.error("[Signal] #{message} for #{index_cfg[:key]}")
          return { status: :error, message: message }
        end

        series = instrument.candle_series(interval: interval)
        unless series&.candles&.any?
          message = "No candle data (#{timeframe})"
          Rails.logger.warn("[Signal] #{message} for #{index_cfg[:key]}")
          return { status: :no_data, message: message }
        end

        # Rails.logger.info("[Signal] Fetched #{series.candles.size} candles for #{index_cfg[:key]} @ #{timeframe}")
        # Rails.logger.debug { "[Signal] Adaptive Supertrend config: #{supertrend_cfg}" }

        st_service = Indicators::Supertrend.new(series: series, **supertrend_cfg)
        st = st_service.call
        st[:adaptive_multipliers]&.compact&.last
        # Rails.logger.info(
        #   "[Signal] Supertrend(#{timeframe}) for #{index_cfg[:key]}: trend=#{st[:trend]} last_value=#{st[:last_value]} multiplier=#{last_multiplier}"
        # )

        adx_value = instrument.adx(14, interval: interval)
        # Rails.logger.info("[Signal] ADX(#{timeframe}) for #{index_cfg[:key]}: #{adx_value}")

        direction = decide_direction(
          st,
          adx_value,
          min_strength: adx_min_strength,
          timeframe_label: timeframe
        )

        {
          status: :ok,
          series: series,
          supertrend: st,
          adx_value: adx_value,
          direction: direction,
          last_candle_timestamp: series.candles.last&.timestamp
        }
      rescue StandardError => e
        Rails.logger.error("[Signal] Timeframe analysis failed for #{index_cfg[:key]} @ #{timeframe}: #{e.class} - #{e.message}")
        { status: :error, message: e.message }
      end

      def analyze_multi_timeframe(index_cfg:, instrument:)
        signals_cfg = AlgoConfig.fetch[:signals] || {}
        primary_tf = (signals_cfg[:primary_timeframe] || signals_cfg[:timeframe] || '5m').to_s
        enable_confirmation = signals_cfg.fetch(:enable_confirmation_timeframe, true)
        confirmation_tf = (signals_cfg[:confirmation_timeframe].presence&.to_s if enable_confirmation)

        supertrend_cfg = signals_cfg[:supertrend]
        unless supertrend_cfg
          Rails.logger.error("[Signal] Supertrend configuration missing for #{index_cfg[:key]}")
          return { status: :error, message: 'Supertrend configuration missing' }
        end

        adx_cfg = signals_cfg[:adx] || {}
        enable_adx_filter = signals_cfg.fetch(:enable_adx_filter, true)
        # Only apply ADX filter if enabled, otherwise use 0 to bypass filter
        adx_min_strength = enable_adx_filter ? adx_cfg[:min_strength] : 0

        # Analyze primary timeframe
        primary_analysis = analyze_timeframe(
          index_cfg: index_cfg,
          instrument: instrument,
          timeframe: primary_tf,
          supertrend_cfg: supertrend_cfg,
          adx_min_strength: adx_min_strength
        )

        unless primary_analysis[:status] == :ok
          return { status: :error, message: "Primary timeframe analysis failed: #{primary_analysis[:message]}" }
        end

        primary_direction = primary_analysis[:direction]
        confirmation_analysis = nil
        confirmation_direction = nil

        if confirmation_tf.present?
          # Only apply ADX filter if enabled, otherwise use 0 to bypass filter
          confirmation_adx_min = if enable_adx_filter
                                   adx_cfg[:confirmation_min_strength] || adx_cfg[:min_strength]
                                 else
                                   0
                                 end

          confirmation_analysis = analyze_timeframe(
            index_cfg: index_cfg,
            instrument: instrument,
            timeframe: confirmation_tf,
            supertrend_cfg: supertrend_cfg,
            adx_min_strength: confirmation_adx_min
          )

          confirmation_direction = confirmation_analysis[:direction] if confirmation_analysis[:status] == :ok
        end

        final_direction = multi_timeframe_direction(primary_direction, confirmation_direction)

        {
          status: :ok,
          primary_direction: primary_direction,
          confirmation_direction: confirmation_direction,
          final_direction: final_direction,
          timeframe_results: {
            primary: primary_analysis,
            confirmation: confirmation_analysis
          }
        }
      rescue StandardError => e
        Rails.logger.error("[Signal] Multi-timeframe analysis failed for #{index_cfg[:key]}: #{e.class} - #{e.message}")
        { status: :error, message: e.message }
      end

      def multi_timeframe_direction(primary_direction, confirmation_direction)
        # If no confirmation timeframe, use primary direction
        return primary_direction if confirmation_direction.nil?

        # If either is avoid, return avoid
        return :avoid if primary_direction == :avoid || confirmation_direction == :avoid

        # If both align, return that direction
        return primary_direction if primary_direction == confirmation_direction

        # Directions don't match
        :avoid
      end

      def normalize_interval(timeframe)
        return if timeframe.blank?

        cleaned = timeframe.to_s.strip.downcase
        digits = cleaned.gsub(/[^0-9]/, '')
        digits.presence
      end

      # Comprehensive validation checks before proceeding with trades
      def comprehensive_validation(index_cfg, direction, series, supertrend_result, adx)
        mode_config = get_validation_mode_config
        # Rails.logger.info("[Signal] Running comprehensive validation for #{index_cfg[:key]} #{direction} (mode: #{mode_config[:mode]})")

        validation_checks = []

        # 1. IV Rank Check - Avoid extreme volatility (if enabled)
        if mode_config[:require_iv_rank_check]
          iv_rank_result = validate_iv_rank(index_cfg, series, mode_config)
          validation_checks << iv_rank_result
        end

        # 2. Theta Risk Assessment - Avoid high theta decay (if enabled)
        if mode_config[:require_theta_risk_check]
          theta_risk_result = validate_theta_risk(index_cfg, direction, mode_config)
          validation_checks << theta_risk_result
        end

        # 3. Enhanced ADX Confirmation - Ensure strong trend (if enabled)
        signals_cfg = AlgoConfig.fetch[:signals] || {}
        enable_adx_filter = signals_cfg.fetch(:enable_adx_filter, true)
        if enable_adx_filter
          adx_result = validate_adx_strength(adx, supertrend_result, mode_config)
          validation_checks << adx_result
        else
          # Rails.logger.debug('[Signal] ADX validation skipped (filter disabled)')
          validation_checks << { valid: true, name: 'ADX Strength', message: 'ADX filter disabled' }
        end

        # 4. Trend Confirmation - Multiple signal validation (if enabled)
        if mode_config[:require_trend_confirmation]
          trend_result = validate_trend_confirmation(supertrend_result, series)
          validation_checks << trend_result
        end

        # 5. Market Timing Check - Avoid problematic times (always required)
        timing_result = validate_market_timing
        validation_checks << timing_result

        # Log all validation results
        # Rails.logger.info("[Signal] Validation Results (#{mode_config[:mode]} mode):")
        validation_checks.each do |check|
          check[:valid] ? '✅' : '❌'
          # Rails.logger.info("  #{status} #{check[:name]}: #{check[:message]}")
        end

        # Determine overall validation result
        failed_checks = validation_checks.reject { |check| check[:valid] }

        if failed_checks.empty?
          # Rails.logger.info("[Signal] All validation checks passed for #{index_cfg[:key]} (#{mode_config[:mode]} mode)")
          { valid: true, reason: 'All checks passed' }
        else
          failed_reasons = failed_checks.pluck(:name).join(', ')
          { valid: false, reason: "Failed checks: #{failed_reasons}" }
        end
      end

      # Get validation mode configuration
      def get_validation_mode_config
        signals_cfg = AlgoConfig.fetch[:signals] || {}
        mode = signals_cfg[:validation_mode] || 'balanced'
        mode_config = signals_cfg.dig(:validation_modes, mode.to_sym) || signals_cfg.dig(:validation_modes, :balanced)

        # Merge with mode name for logging
        mode_config.merge(mode: mode)
      end

      # Validate IV Rank - avoid extreme volatility conditions
      def validate_iv_rank(_index_cfg, series, mode_config = nil)
        mode_config ||= get_validation_mode_config

        # For now, we'll use a simple volatility check based on recent price movement
        # In a full implementation, you'd calculate actual IV rank from historical IV data

        candles = series.candles
        if candles.blank? || candles.size < 5
          return { valid: false, name: 'IV Rank', message: 'Insufficient data for volatility assessment' }
        end

        # Calculate recent volatility as a proxy for IV rank
        # series.candles is an array of Candle objects
        recent_candles = candles.last(5)
        return { valid: false, name: 'IV Rank', message: 'Insufficient recent candles' } if recent_candles.size < 2

        price_changes = recent_candles.each_cons(2).map { |c1, c2| (c2.close - c1.close).abs / c1.close }
        avg_volatility = price_changes.sum / price_changes.size

        # Normalize volatility (this is a simplified approach)
        iv_rank_proxy = [(avg_volatility * 1000), 1.0].min # Cap at 1.0

        max_threshold = mode_config[:iv_rank_max] || 0.8
        min_threshold = mode_config[:iv_rank_min] || 0.1

        if iv_rank_proxy > max_threshold
          { valid: false, name: 'IV Rank', message: "Extreme volatility detected (#{(iv_rank_proxy * 100).round(1)}% > #{(max_threshold * 100).round(1)}%)" }
        elsif iv_rank_proxy < min_threshold
          { valid: false, name: 'IV Rank', message: "Very low volatility (#{(iv_rank_proxy * 100).round(1)}% < #{(min_threshold * 100).round(1)}%)" }
        else
          { valid: true, name: 'IV Rank', message: "Volatility within acceptable range (#{(iv_rank_proxy * 100).round(1)}%)" }
        end
      end

      # Validate theta risk - avoid high theta decay situations
      def validate_theta_risk(_index_cfg, _direction, mode_config = nil)
        mode_config ||= get_validation_mode_config

        current_time = Time.zone.now
        hour = current_time.hour
        minute = current_time.min

        cutoff_hour = mode_config[:theta_risk_cutoff_hour] || 14
        cutoff_minute = mode_config[:theta_risk_cutoff_minute] || 30

        # High theta risk periods (configurable cutoff time)
        if hour > cutoff_hour || (hour == cutoff_hour && minute >= cutoff_minute)
          { valid: false, name: 'Theta Risk', message: "High theta decay risk - too close to market close (after #{cutoff_hour}:#{cutoff_minute.to_s.rjust(2, '0')})" }
        elsif hour >= 14 # After 2:00 PM
          { valid: true, name: 'Theta Risk', message: 'Moderate theta risk - afternoon trading' }
        else
          { valid: true, name: 'Theta Risk', message: 'Low theta risk - early/midday trading' }
        end
      end

      # Enhanced ADX validation with trend strength assessment
      def validate_adx_strength(adx, _supertrend_result, mode_config = nil)
        mode_config ||= get_validation_mode_config

        adx_value = adx[:value].to_f
        min_strength = mode_config[:adx_min_strength] || AlgoConfig.fetch.dig(:signals, :adx, :min_strength).to_f

        if adx_value < min_strength
          { valid: false, name: 'ADX Strength', message: "Weak trend strength (#{adx_value.round(1)} < #{min_strength})" }
        elsif adx_value >= 40
          { valid: true, name: 'ADX Strength', message: "Very strong trend (#{adx_value.round(1)})" }
        elsif adx_value >= 25
          { valid: true, name: 'ADX Strength', message: "Strong trend (#{adx_value.round(1)})" }
        else
          { valid: true, name: 'ADX Strength', message: "Moderate trend (#{adx_value.round(1)})" }
        end
      end

      # Validate trend confirmation with multiple signals
      def validate_trend_confirmation(supertrend_result, series)
        trend = supertrend_result[:trend]

        return { valid: false, name: 'Trend Confirmation', message: 'No trend signal from Supertrend' } if trend.nil?

        # Additional confirmation: check if recent price action supports the trend
        candles = series.candles
        if candles.blank? || candles.size < 3
          return { valid: false, name: 'Trend Confirmation', message: 'Insufficient data for trend confirmation' }
        end

        recent_candles = candles.last(3)

        # Check if recent closes are moving in trend direction
        case trend
        when :bullish
          if recent_candles.last.close > recent_candles.first.close
            { valid: true, name: 'Trend Confirmation', message: 'Bullish trend confirmed by price action' }
          else
            { valid: false, name: 'Trend Confirmation', message: 'Bullish signal not confirmed by recent price action' }
          end
        when :bearish
          if recent_candles.last.close < recent_candles.first.close
            { valid: true, name: 'Trend Confirmation', message: 'Bearish trend confirmed by price action' }
          else
            { valid: false, name: 'Trend Confirmation', message: 'Bearish signal not confirmed by recent price action' }
          end
        else
          { valid: false, name: 'Trend Confirmation', message: 'Unknown trend direction' }
        end
      end

      # Validate market timing - avoid problematic trading times
      def validate_market_timing
        return { valid: true, name: 'Market Timing', message: 'Normal trading hours' }
        current_time = Time.zone.now

        # First check if it's a trading day using Market::Calendar
        unless Market::Calendar.trading_day_today?
          return { valid: false, name: 'Market Timing', message: 'Not a trading day (weekend/holiday)' }
        end

        hour = current_time.hour
        minute = current_time.min

        # Market hours: 9:15 AM to 3:30 PM IST
        market_open = hour > 9 || (hour == 9 && minute >= 15)
        market_close = hour > 15 || (hour == 15 && minute >= 30)

        if !market_open
          { valid: false, name: 'Market Timing', message: 'Market not yet open' }
        elsif market_close
          { valid: false, name: 'Market Timing', message: 'Market closed' }
        elsif hour == 9 && minute < 30
          { valid: true, name: 'Market Timing', message: 'Early market - high volatility period' }
        elsif hour >= 14 && minute >= 30
          { valid: true, name: 'Market Timing', message: 'Late market - theta decay risk' }
        else
          { valid: true, name: 'Market Timing', message: 'Normal trading hours' }
        end
      end

      def calculate_confidence_score(primary_analysis:, confirmation_analysis:, validation_result:)
        base_confidence = 0.5

        # ADX strength factor (0-0.3)
        adx_factor = 0.0
        if primary_analysis[:adx_value]
          adx_value = primary_analysis[:adx_value].to_f
          if adx_value >= 30
            adx_factor = 0.3
          elsif adx_value >= 20
            adx_factor = 0.2
          elsif adx_value >= 15
            adx_factor = 0.1
          end
        end

        # Multi-timeframe confirmation factor (0-0.2)
        confirmation_factor = 0.0
        if confirmation_analysis && confirmation_analysis[:direction] == primary_analysis[:direction]
          confirmation_factor = 0.2
        end

        # Validation factor (0-0.1)
        validation_factor = validation_result[:valid] ? 0.1 : 0.0

        # Supertrend strength factor (0-0.1)
        supertrend_factor = 0.0
        if primary_analysis[:supertrend] && primary_analysis[:supertrend][:last_value]
          # Higher supertrend values indicate stronger trend
          st_value = primary_analysis[:supertrend][:last_value].to_f
          supertrend_factor = [st_value / 1000.0, 0.1].min # Cap at 0.1
        end

        total_confidence = base_confidence + adx_factor + confirmation_factor + validation_factor + supertrend_factor
        [total_confidence, 1.0].min # Cap at 1.0
      end

      def analyze_with_recommended_strategy(index_cfg:, instrument:, timeframe:, strategy_recommendation:)
        interval = normalize_interval(timeframe)
        if interval.blank?
          message = "Invalid timeframe '#{timeframe}'"
          Rails.logger.error("[Signal] #{message} for #{index_cfg[:key]}")
          return { status: :error, message: message }
        end

        series = instrument.candle_series(interval: interval)
        unless series&.candles&.any?
          message = "No candle data (#{timeframe})"
          Rails.logger.warn("[Signal] #{message} for #{index_cfg[:key]}")
          return { status: :no_data, message: message }
        end

        strategy_class = strategy_recommendation[:strategy_class]
        strategy_config = {}

        # Prepare strategy-specific configuration
        if strategy_class == SupertrendAdxStrategy
          signals_cfg = AlgoConfig.fetch[:signals] || {}
          strategy_config = {
            supertrend_cfg: signals_cfg[:supertrend] || { period: 7, multiplier: 3 },
            adx_min_strength: signals_cfg.dig(:adx, :min_strength) || 20
          }
        end

        # Use the last candle index for signal generation
        current_index = series.candles.size - 1

        Rails.logger.info("[Signal] Analyzing #{index_cfg[:key]} with #{strategy_recommendation[:strategy_name]} at index #{current_index} (#{series.candles.size} candles, timeframe: #{timeframe})")

        result = Signal::StrategyAdapter.analyze_with_strategy(
          strategy_class: strategy_class,
          series: series,
          index: current_index,
          strategy_config: strategy_config
        )

        pp series.candles.last
        pp series.candles.first
        if result[:status] == :ok && result[:direction] == :avoid
          Rails.logger.info("[Signal] #{strategy_recommendation[:strategy_name]} did not generate a signal for #{index_cfg[:key]} - checking conditions...")
          # Log why signal might not be generated
          last_candle = series.candles[current_index]
          if last_candle
            # Convert timestamp to IST timezone explicitly
            ist_time = last_candle.timestamp.in_time_zone('Asia/Kolkata')
            hour = ist_time.hour
            minute = ist_time.min
            # Market hours: 9:15 AM to 3:30 PM IST (checking up to 3:30 PM)
            in_trading_hours = (hour > 9 || (hour == 9 && minute >= 15)) && (hour < 15 || (hour == 15 && minute < 30))
            Rails.logger.info("[Signal] Last candle time: #{ist_time.strftime('%H:%M %Z')} | In trading hours: #{in_trading_hours} | Candles available: #{series.candles.size}")
          end
        end

        # Convert to standard format with supertrend and adx placeholders for compatibility
        if result[:status] == :ok
          {
            status: :ok,
            series: result[:series],
            supertrend: { trend: result[:direction] == :bullish ? :bullish : :bearish, last_value: nil },
            adx_value: result[:confidence] || 0,
            direction: result[:direction],
            last_candle_timestamp: result[:last_candle_timestamp],
            strategy_confidence: result[:confidence]
          }
        else
          result
        end
      rescue StandardError => e
        Rails.logger.error("[Signal] Strategy-based analysis failed for #{index_cfg[:key]} @ #{timeframe}: #{e.class} - #{e.message}")
        { status: :error, message: e.message }
      end

      def decide_direction(supertrend_result, adx_value, min_strength:, timeframe_label:)
        min_required = min_strength.to_f
        adx_numeric = adx_value.to_f

        # Rails.logger.debug { "[Signal] ADX check(#{timeframe_label}): value=#{adx_numeric}, min_required=#{min_required}" }

        # Only apply ADX filter if min_required is positive (i.e., ADX filter is enabled)
        if min_required.positive? && adx_numeric < min_required
          # Rails.logger.info("[Signal] ADX too weak on #{timeframe_label}: #{adx_numeric} < #{min_required}")
          return :avoid
        end

        if supertrend_result.blank? || supertrend_result[:trend].nil?
          Rails.logger.warn("[Signal] Supertrend result invalid on #{timeframe_label}: #{supertrend_result}")
          return :avoid
        end

        trend = supertrend_result[:trend]
        # Rails.logger.debug { "[Signal] Supertrend trend(#{timeframe_label}): #{trend}" }

        # Use the trend from Supertrend calculation
        case trend
        when :bullish
          # Rails.logger.info("[Signal] Bullish signal confirmed on #{timeframe_label}: ADX=#{adx_numeric}, Supertrend=#{trend}")
          :bullish
        when :bearish
          # Rails.logger.info("[Signal] Bearish signal confirmed on #{timeframe_label}: ADX=#{adx_numeric}, Supertrend=#{trend}")
          :bearish
        else
          # Rails.logger.info("[Signal] Neutral/unknown trend on #{timeframe_label}: #{trend}")
          :avoid
        end
      end
    end
  end
end


# File: app/services/signal/engines/base_engine.rb
# frozen_string_literal: true

require 'active_support/core_ext/hash'
require 'active_support/core_ext/object/blank'

module Signal
  module Engines
    class BaseEngine
      STATE_MUTEX = Mutex.new
      STATE = Hash.new { |hash, key| hash[key] = {} }

      def initialize(index:, config:, option_candidate:, tick_cache: Live::RedisTickCache.instance)
        @index = normalize_index(index)
        @config = config || {}
        @option_candidate = option_candidate&.deep_symbolize_keys
        @tick_cache = tick_cache
      end

      protected

      def tick_of(sid, segment: option_segment)
        return unless sid && segment

        @tick_cache.fetch_tick(segment, sid)
      end

      def option_tick
        sid = option_security_id
        return unless sid

        tick_of(sid)
      end

      def option_security_id
        @option_candidate&.[](:security_id) || @index.dig(:options, :atm_sid)
      end

      def option_segment
        @option_candidate&.[](:segment) || @index[:segment]
      end

      def create_signal(reason:, meta: {})
        sid = option_security_id
        return unless sid

        multiplier = strategy_threshold(:multiplier, 1).to_i
        multiplier = 1 unless multiplier.positive?

        {
          segment: option_segment,
          security_id: sid,
          reason: reason,
          meta: {
            index: @index[:key],
            candidate_symbol: @option_candidate&.[](:symbol),
            strategy: self.class.name,
            lot_size: option_lot_size,
            multiplier: multiplier
          }.merge(meta).compact
        }
      end

      def state_get(key, default = nil)
        STATE_MUTEX.synchronize { STATE[state_key][key] } || default
      end

      def state_set(key, value)
        STATE_MUTEX.synchronize { STATE[state_key][key] = value }
      end

      def strategy_threshold(key, default = nil)
        @config.fetch(key, default)
      end

      def option_lot_size
        lot = @option_candidate&.[](:lot_size) ||
              @index[:lot_size] ||
              @index[:lot]
        lot = lot.to_i
        lot.positive? ? lot : 1
      end

      def effective_lot_size(multiplier_key = :lot_multiplier, default_multiplier = 1)
        multiplier = strategy_threshold(multiplier_key, default_multiplier).to_i
        multiplier = default_multiplier unless multiplier.positive?
        option_lot_size * multiplier
      end

      private

      def normalize_index(index)
        return index.deep_symbolize_keys if index.respond_to?(:deep_symbolize_keys)

        Array(index).each_with_object({}) do |(k, v), acc|
          acc[k.to_sym] = v
        end
      end

      def state_key
        "#{@index[:key]}::#{self.class.name}"
      end
    end
  end
end


# File: app/services/signal/engines/btst_momentum_engine.rb
# frozen_string_literal: true

module Signal
  module Engines
    class BtstMomentumEngine < BaseEngine
      EOD_MIN = '15:10'
      EOD_MAX = '15:20'

      def evaluate
        return unless eod_window?

        tick = option_tick
        return unless tick

        ltp = tick[:ltp].to_f
        vwap = tick[:vwap].to_f
        volume = tick[:volume].to_i
        avg_volume = tick[:avg_volume].to_i

        return unless ltp.positive? && vwap.positive? && ltp > vwap
        return unless volume.positive? && avg_volume.positive? && volume > avg_volume

        create_signal(
          reason: 'BTST momentum',
          meta: {
            vwap_premium: ((ltp - vwap) / vwap * 100).round(2),
            volume_ratio: (volume.to_f / avg_volume).round(2)
          }
        )
      end

      private

      def eod_window?
        now = Time.current.in_time_zone('Asia/Kolkata').strftime('%H:%M')
        now >= EOD_MIN && now <= EOD_MAX
      end
    end
  end
end


# File: app/services/signal/engines/momentum_buying_engine.rb
# frozen_string_literal: true

module Signal
  module Engines
    class MomentumBuyingEngine < BaseEngine
      def evaluate
        tick = option_tick
        return unless tick

        day_high = tick[:day_high].to_f
        ltp = tick[:ltp].to_f
        return if day_high.zero? || ltp <= day_high

        min_rsi = strategy_threshold(:min_rsi, nil)
        if min_rsi
          rsi = tick[:rsi].to_f
          return unless rsi.positive? && rsi > min_rsi.to_i
        end

        create_signal(
          reason: 'Momentum breakout',
          meta: {
            breakout_above_high: true,
            rsi: tick[:rsi]&.to_f
          }
        )
      end
    end
  end
end


# File: app/services/signal/engines/open_interest_buying_engine.rb
# frozen_string_literal: true

module Signal
  module Engines
    class OpenInterestBuyingEngine < BaseEngine
      def evaluate
        tick = option_tick
        return unless tick

        current_oi = tick[:oi].to_i
        prev_close = tick[:prev_close].to_f
        price = tick[:ltp].to_f

        return if current_oi.zero? || prev_close.zero?

        last_oi = state_get(:last_oi, current_oi)
        state_set(:last_oi, current_oi)

        return unless current_oi > last_oi
        return unless price > prev_close

        create_signal(
          reason: 'OI buildup',
          meta: {
            oi_change: current_oi - last_oi,
            price_change_pct: ((price - prev_close) / prev_close * 100).round(2)
          }
        )
      end
    end
  end
end


# File: app/services/signal/engines/swing_option_buying_engine.rb
# frozen_string_literal: true

module Signal
  module Engines
    class SwingOptionBuyingEngine < BaseEngine
      def evaluate
        tick = option_tick
        return unless tick

        return unless tick[:htf_supertrend].to_s.casecmp('up').zero?

        ltp = tick[:ltp].to_f
        ema9 = tick[:ema9].to_f
        ema21 = tick[:ema21].to_f
        prev_high = tick[:prev_high].to_f

        return unless ema9.positive? && ema21.positive?
        return unless ltp < ema9 && ltp > ema21
        return unless prev_high.positive? && ltp > prev_high

        create_signal(
          reason: 'Swing trend continuation',
          meta: {
            ema_position: 'between_ema9_ema21',
            above_prev_high: true
          }
        )
      end
    end
  end
end


# File: app/services/signal/scheduler.rb
# frozen_string_literal: true

module Signal
  # rubocop:disable Metrics/ClassLength
  class Scheduler
    DEFAULT_PERIOD = 30 # seconds
    STRATEGY_MAP = {
      open_interest: Signal::Engines::OpenInterestBuyingEngine,
      momentum_buying: Signal::Engines::MomentumBuyingEngine,
      btst: Signal::Engines::BtstMomentumEngine,
      swing_buying: Signal::Engines::SwingOptionBuyingEngine
    }.freeze

    def initialize(period: DEFAULT_PERIOD, data_provider: nil)
      @period = period
      @running = false
      @thread  = nil
      @mutex   = Mutex.new
      @data_provider = data_provider || default_provider
    end

    def start
      return if @running

      @mutex.synchronize do
        return if @running

        @running = true
      end

      indices = Array(AlgoConfig.fetch[:indices])

      @thread = Thread.new do
        Thread.current.name = 'signal-scheduler'

        loop do
          break unless @running

          begin
            indices.each_with_index do |idx_cfg, idx|
              break unless @running

              sleep(idx.zero? ? 0 : 5)
              process_index(idx_cfg)
            end
          rescue StandardError => e
            Rails.logger.error("[SignalScheduler] #{e.class} - #{e.message}")
          end

          sleep @period
        end
      end
    end

    def stop
      @mutex.synchronize { @running = false }
      @thread&.kill
      @thread = nil
    end

    private

    def process_index(index_cfg)
      enabled_strategies = load_enabled_strategies(index_cfg)
      if enabled_strategies.empty?
        Signal::Engine.run_for(index_cfg)
        return
      end

      signal = evaluate_strategies_priority(index_cfg, enabled_strategies)
      return unless signal

      process_signal(index_cfg, signal)
    rescue StandardError => e
      Rails.logger.error("[SignalScheduler] process_index error #{index_cfg[:key]}: #{e.class} - #{e.message}")
      Rails.logger.debug { e.backtrace.first(5).join("\n") }
    end

    def load_enabled_strategies(index_cfg)
      strategies_cfg = index_cfg[:strategies] || AlgoConfig.fetch[:strategy] || {}
      enabled = []

      STRATEGY_MAP.each do |key, engine_class|
        strategy_cfg = strategies_cfg[key] || {}
        next unless strategy_cfg[:enabled] == true

        priority = strategy_cfg[:priority] || 999
        enabled << {
          key: key,
          engine_class: engine_class,
          config: strategy_cfg,
          priority: priority
        }
      end

      enabled.sort_by { |s| s[:priority] }
    end

    def evaluate_strategies_priority(index_cfg, enabled_strategies)
      chain_cfg = AlgoConfig.fetch[:chain_analyzer] || {}

      # Use DerivativeChainAnalyzer for better integration with Derivative records
      analyzer = Options::DerivativeChainAnalyzer.new(
        index_key: index_cfg[:key],
        expiry: nil, # Auto-select nearest expiry
        config: chain_cfg
      )

      direction = determine_direction(index_cfg)
      limit = chain_cfg[:max_candidates] || 1
      candidates = analyzer.select_candidates(limit: limit.to_i, direction: direction)

      return nil if candidates.empty?

      enabled_strategies.each do |strategy|
        candidate = candidates.first
        signal = evaluate_strategy(index_cfg, strategy, candidate)
        next unless signal

        Rails.logger.info(
          "[Scheduler] strategy:#{strategy[:key]} emitted signal:#{signal[:meta][:candidate_symbol]} " \
          "reason:#{signal[:reason]}"
        )
        return signal
      end

      nil
    end

    def evaluate_strategy(index_cfg, strategy, candidate)
      engine = strategy[:engine_class].new(
        index: index_cfg,
        config: strategy[:config],
        option_candidate: candidate
      )

      engine.evaluate
    rescue StandardError => e
      Rails.logger.error(
        "[SignalScheduler] Strategy #{strategy[:key]} evaluation failed: #{e.class} - #{e.message}"
      )
      nil
    end

    def determine_direction(index_cfg)
      direction = index_cfg[:direction] || AlgoConfig.fetch.dig(:strategy, :direction) || :bullish
      direction.to_s.downcase.to_sym
    end

    def process_signal(index_cfg, signal)
      pick = build_pick_from_signal(signal)
      direction = determine_direction(index_cfg)
      multiplier = signal[:meta][:multiplier] || 1

      result = Entries::EntryGuard.try_enter(
        index_cfg: index_cfg,
        pick: pick,
        direction: direction,
        scale_multiplier: multiplier
      )

      return if result

      Rails.logger.warn(
        "[Scheduler] EntryGuard rejected signal for #{index_cfg[:key]}: #{signal[:meta][:candidate_symbol]}"
      )
    end

    def build_pick_from_signal(signal)
      {
        segment: signal[:segment],
        security_id: signal[:security_id],
        symbol: signal[:meta][:candidate_symbol] || 'UNKNOWN',
        lot_size: signal[:meta][:lot_size] || 1,
        ltp: nil # Will be resolved by EntryGuard
      }
    end

    def default_provider
      Providers::DhanhqProvider.new
    rescue NameError
      nil
    end
  end
  # rubocop:enable Metrics/ClassLength
end


# File: app/services/signal/state_tracker.rb
# frozen_string_literal: true

module Signal
  class StateTracker
    CACHE_PREFIX = 'signal:state'

    class << self
      def record(index_key:, direction:, candle_timestamp:, config: {})
        scaling_cfg = config.fetch(:scaling, {})
        return default_response(direction) unless scaling_cfg.fetch(:enabled, false)

        key = cache_key(index_key)
        state = Rails.cache.read(key) || {}
        last_direction = state[:direction]&.to_sym
        last_timestamp = normalized_timestamp(state[:last_candle_timestamp])
        current_timestamp = normalized_timestamp(candle_timestamp)

        same_direction = last_direction == direction
        new_candle = current_timestamp.present? && current_timestamp != last_timestamp

        count =
          if same_direction && new_candle
            state[:count].to_i + 1
          elsif same_direction
            [state[:count].to_i, 1].max
          else
            1
          end

        updated_state = {
          direction: direction,
          count: count,
          last_candle_timestamp: current_timestamp,
          last_seen_at: Time.current
        }

        ttl = [scaling_cfg.fetch(:decay_seconds, 900).to_i, 0].max
        Rails.cache.write(key, updated_state, expires_in: ttl)

        multiplier = [
          [count, 1].max,
          [scaling_cfg.fetch(:max_multiplier, 1).to_i, 1].max
        ].min

        {
          count: count,
          multiplier: multiplier
        }
      end

      def reset(index_key)
        Rails.cache.delete(cache_key(index_key))
      end

      private

      def cache_key(index_key)
        "#{CACHE_PREFIX}:#{index_key}"
      end

      def normalized_timestamp(value)
        return if value.blank?

        case value
        when Time
          value.to_i
        when DateTime
          value.to_time.to_i
        else
          value.to_i
        end
      end

      def default_response(direction)
        {
          count: direction.nil? || direction == :avoid ? 0 : 1,
          multiplier: 1
        }
      end
    end
  end
end


# File: app/services/signal/strategy_adapter.rb
# frozen_string_literal: true

# Adapter to convert strategy signals to Signal::Engine format
module Signal
  class StrategyAdapter
    class << self
      # Convert strategy signal to direction format
      # @param strategy_signal [Hash, nil] Signal from strategy (e.g., { type: :ce, confidence: 70 })
      # @return [Symbol] :bullish, :bearish, or :avoid
      def strategy_to_direction(strategy_signal)
        return :avoid unless strategy_signal

        case strategy_signal[:type]
        when :ce
          :bullish
        when :pe
          :bearish
        else
          :avoid
        end
      end

      # Analyze using a strategy class
      # @param strategy_class [Class] Strategy class (e.g., SimpleMomentumStrategy)
      # @param series [CandleSeries] Candle series
      # @param index [Integer] Current candle index
      # @param strategy_config [Hash] Optional strategy configuration
      # @return [Hash] Analysis result in Signal::Engine format
      def analyze_with_strategy(strategy_class:, series:, index:, strategy_config: {})
        strategy = strategy_class.new(series: series, **strategy_config)
        signal = strategy.generate_signal(index)

        direction = strategy_to_direction(signal)
        confidence = signal ? signal[:confidence] : 0

        if signal.nil?
          Rails.logger.debug("[Signal::StrategyAdapter] No signal generated by #{strategy_class.name} at index #{index} (candles: #{series.candles.size})")
        else
          Rails.logger.debug("[Signal::StrategyAdapter] Signal generated: #{signal[:type]} with confidence #{confidence}%")
        end

        {
          status: :ok,
          series: series,
          direction: direction,
          confidence: confidence,
          strategy_signal: signal,
          last_candle_timestamp: series.candles.last&.timestamp
        }
      rescue StandardError => e
        Rails.logger.error("[Signal::StrategyAdapter] Strategy analysis failed: #{e.class} - #{e.message}")
        { status: :error, message: e.message }
      end
    end
  end
end


# File: app/services/signal/validator.rb
# frozen_string_literal: true

module Signal
  class Validator
    def validate(signal_data)
      confidence = signal_data[:confidence] || 0.0

      if confidence < 0.5
        { valid: false, reason: 'low confidence' }
      elsif confidence < 0.7
        { valid: true, reason: 'moderate confidence' }
      else
        { valid: true, reason: 'high confidence' }
      end
    end
  end
end


# File: app/services/strategy_recommender.rb
# frozen_string_literal: true

# Strategy Recommender Service
# Provides recommendations for best strategy/timeframe combinations based on backtest results
class StrategyRecommender
  # Backtest results data (should be updated after each comprehensive backtest)
  BACKTEST_RESULTS = {
    'NIFTY' => {
      '5' => {
        strategy: SimpleMomentumStrategy,
        strategy_name: 'SimpleMomentumStrategy',
        win_rate: 52.63,
        expectancy: 0.02,
        total_pnl: 0.98,
        trades: 57
      },
      '15' => {
        strategy: SupertrendAdxStrategy,
        strategy_name: 'SupertrendAdxStrategy',
        win_rate: 42.86,
        expectancy: -0.35,
        total_pnl: -2.47,
        trades: 7
      }
    },
    'BANKNIFTY' => {
      '5' => {
        strategy: SimpleMomentumStrategy,
        strategy_name: 'SimpleMomentumStrategy',
        win_rate: 55.77,
        expectancy: 0.04,
        total_pnl: 2.22,
        trades: 52
      },
      '15' => {
        strategy: InsideBarStrategy,
        strategy_name: 'InsideBarStrategy',
        win_rate: 57.14,
        expectancy: -0.27,
        total_pnl: -1.89,
        trades: 7
      }
    },
    'SENSEX' => {
      '5' => {
        strategy: SupertrendAdxStrategy,
        strategy_name: 'SupertrendAdxStrategy',
        win_rate: 52.54,
        expectancy: 0.03,
        total_pnl: 1.62,
        trades: 59
      },
      '15' => {
        strategy: SimpleMomentumStrategy,
        strategy_name: 'SimpleMomentumStrategy',
        win_rate: 71.43,
        expectancy: 0.18,
        total_pnl: 1.23,
        trades: 7
      }
    }
  }.freeze

  class << self
    # Get recommended strategy for a given index and timeframe
    # @param symbol [String] Index symbol (NIFTY, BANKNIFTY, SENSEX)
    # @param interval [String] Timeframe in minutes ('5', '15')
    # @return [Hash] Strategy recommendation with details
    def recommend(symbol:, interval: '5')
      symbol = symbol.to_s.upcase
      interval = interval.to_s

      result = BACKTEST_RESULTS.dig(symbol, interval)
      return default_recommendation(symbol, interval) unless result

      {
        symbol: symbol,
        interval: interval,
        strategy_class: result[:strategy],
        strategy_name: result[:strategy_name],
        win_rate: result[:win_rate],
        expectancy: result[:expectancy],
        total_pnl: result[:total_pnl],
        trades: result[:trades],
        recommended: result[:expectancy].positive?,
        confidence: calculate_confidence(result)
      }
    end

    # Get best strategy across all timeframes for an index
    # @param symbol [String] Index symbol
    # @return [Hash] Best strategy recommendation
    def best_for_index(symbol:)
      symbol = symbol.to_s.upcase
      results = BACKTEST_RESULTS[symbol] || {}

      return nil if results.empty?

      # Find best by expectancy
      best = results.max_by { |_interval, data| data[:expectancy] || -999 }
      return nil unless best

      interval, data = best
      {
        symbol: symbol,
        interval: interval,
        strategy_class: data[:strategy],
        strategy_name: data[:strategy_name],
        win_rate: data[:win_rate],
        expectancy: data[:expectancy],
        total_pnl: data[:total_pnl],
        trades: data[:trades],
        recommended: data[:expectancy].positive?,
        confidence: calculate_confidence(data)
      }
    end

    # Get all recommendations for an index
    # @param symbol [String] Index symbol
    # @return [Array<Hash>] All strategy recommendations sorted by expectancy
    def all_for_index(symbol:)
      symbol = symbol.to_s.upcase
      results = BACKTEST_RESULTS[symbol] || {}

      recommendations = results.map do |interval, data|
        {
          symbol: symbol,
          interval: interval,
          strategy_class: data[:strategy],
          strategy_name: data[:strategy_name],
          win_rate: data[:win_rate],
          expectancy: data[:expectancy],
          total_pnl: data[:total_pnl],
          trades: data[:trades],
          recommended: data[:expectancy].positive?,
          confidence: calculate_confidence(data)
        }
      end
      recommendations.sort_by { |r| -(r[:expectancy] || -999) }
    end

    # Get recommended configuration for live trading
    # @return [Hash] Recommended configuration for all indices
    def live_trading_config
      {
        'NIFTY' => recommend(symbol: 'NIFTY', interval: '5'),
        'BANKNIFTY' => recommend(symbol: 'BANKNIFTY', interval: '5'),
        'SENSEX' => recommend(symbol: 'SENSEX', interval: '5')
      }
    end

    private

    def default_recommendation(symbol, interval)
      {
        symbol: symbol,
        interval: interval,
        strategy_class: SimpleMomentumStrategy,
        strategy_name: 'SimpleMomentumStrategy',
        win_rate: nil,
        expectancy: nil,
        total_pnl: nil,
        trades: nil,
        recommended: false,
        confidence: :low,
        note: 'No backtest data available - using default strategy'
      }
    end

    def calculate_confidence(data)
      return :low if data[:trades] < 20
      return :low if data[:expectancy].negative?

      if data[:expectancy] > 0.03 && data[:trades] > 50
        :high
      elsif data[:expectancy].positive? && data[:trades] > 30
        :medium
      else
        :low
      end
    end
  end
end


# File: app/services/tick_cache.rb
# frozen_string_literal: true

require 'concurrent/map'
require 'singleton'

class TickCache
  include Singleton

  def initialize
    @map = Concurrent::Map.new
  end

  # ------------------------
  # MASTER TICK HANDLER
  # ------------------------
  def put(raw_tick)
    tick = normalize(raw_tick)
    return if tick.nil?

    seg = tick[:segment]
    sid = tick[:security_id]
    key = cache_key(seg, sid)

    merged = @map.compute(key) do |_, existing|
      existing ||= {}
      previous_ltp = existing[:ltp]

      new_hash = existing.dup

      tick.each do |k, v|
        next if v.nil?

        case k
        when :segment, :security_id
          new_hash[k] = v

        when :ltp
          # LTP only updates if > 0
          new_hash[:ltp] = v.to_f if v.to_f.positive?

        else
          new_hash[k] = v
        end
      end

      # Restore previous LTP if missing
      new_hash[:ltp] = previous_ltp if new_hash[:ltp].nil? && previous_ltp

      new_hash
    end

    # Also update Redis TickCache for HA + PnL consumers
    Live::RedisTickCache.instance.store_tick(
      segment: seg,
      security_id: sid,
      data: merged
    )

    merged
  end

  # ------------------------
  # FETCH WITH REDIS FALLBACK
  # ------------------------
  def fetch(segment, security_id)
    key = cache_key(segment, security_id)

    # Try memory first
    # mem = @map[key]
    # return mem if mem.present?

    # Then fallback to Redis
    redis_tick = Live::RedisTickCache.instance.fetch_tick(segment, security_id)

    return nil if redis_tick.empty?

    # Hydrate memory so next calls are fast
    @map[key] = redis_tick

    redis_tick
  end

  # alias for compatibility
  def get(segment, security_id)
    fetch(segment, security_id)
  end

  # ------------------------
  # LTP WITH REDIS FALLBACK
  # ------------------------
  def ltp(segment, security_id)
    tick = fetch(segment, security_id)
    val = tick && tick[:ltp]
    val&.to_f
  end

  # ------------------------
  # Delete in-memory entry (used when unsubscribing / cleanup)
  # ------------------------
  def delete(segment, security_id)
    key = cache_key(segment, security_id)

    # Delete in-memory cache
    @map.delete(key)

    # Delete Redis tick key
    Live::RedisTickCache.instance.clear_tick(segment, security_id)

    true
  end

  def all
    mem = {}
    @map.each_pair { |k, v| mem[k] = v }

    redis = Live::RedisTickCache.instance.fetch_all

    # merge redis into memory snapshot (memory overrides for live session)
    redis.merge(mem)
  end

  delegate :clear, to: :@map

  private

  # ------------------------
  # Normalization
  # ------------------------
  def normalize(h)
    return nil unless h.is_a?(Hash)

    out = {}

    h.each do |k, v|
      sym = k.to_sym

      out[sym] =
        case sym
        when :ltp, :prev_close, :oi, :oi_prev
          v.to_f
        else
          v
        end
    end

    return nil if out[:segment].nil? || out[:security_id].nil?

    out[:segment] = out[:segment].to_s
    out[:security_id] = out[:security_id].to_s

    out
  end

  def cache_key(seg, sid)
    "#{seg}:#{sid}"
  end
end


# File: app/services/trading/admin_actions.rb
# frozen_string_literal: true

# Administrative conveniences for manual trading interventions.
# Provides thin wrappers around model-level helpers so ops teams
# can reuse the live trading pipeline without bypassing risk guards.
module Trading
  module AdminActions
    class << self
      # Buy a chosen derivative (CE/PE) and start tracking immediately.
      # @param derivative_id [Integer]
      # @param qty [Integer, nil]
      # @param product_type [String]
      # @param index_key [String, nil]
      # @param meta [Hash]
      # @return [Object, nil]
      def buy_derivative!(derivative_id:, qty: nil, product_type: 'INTRADAY', index_key: nil, meta: {})
        derivative = Derivative.find(derivative_id)
        derivative.buy_option!(
          qty: qty,
          product_type: product_type,
          index_cfg: find_index_config(derivative: derivative, override_key: index_key),
          meta: meta
        )
      end

      # Sell (exit) a derivative position tracked by the system.
      # @param derivative_id [Integer]
      # @param qty [Integer, nil]
      # @param meta [Hash]
      # @return [Object, nil]
      def sell_derivative!(derivative_id:, qty: nil, meta: {})
        Derivative.find(derivative_id).sell_option!(qty: qty, meta: meta)
      end

      private

      def find_index_config(derivative:, override_key: nil)
        key = (override_key || derivative.underlying_symbol || derivative.symbol_name).to_s
        return nil if key.blank?

        indices = Array(AlgoConfig.fetch[:indices])
        indices.find { |cfg| cfg[:key].to_s.casecmp?(key) }
      rescue StandardError => e
        # Rails.logger.error("[AdminActions] Failed to resolve index config for #{key}: #{e.message}")
        nil
      end
    end
  end
end



# File: app/services/trading/indicators.rb
# frozen_string_literal: true

require 'bigdecimal'

module Trading
  module Indicators
    module_function

    def rsi(closes, period: 14)
      return if closes.size < period + 1

      gains = []
      losses = []

      closes.each_cons(2) do |prev, curr|
        change = decimal(curr) - decimal(prev)
        if change.positive?
          gains << change
          losses << BigDecimal(0)
        else
          gains << BigDecimal(0)
          losses << change.abs
        end
      end

      avg_gain = average(gains.last(period))
      avg_loss = average(losses.last(period))
      return BigDecimal(50) if avg_loss.zero?

      rs = avg_gain / avg_loss
      100 - (100 / (1 + rs))
    end

    def atr(candles, period: 7)
      return if candles.size < period + 1

      trs = candles.each_cons(2).filter_map do |prev, curr|
        high = curr[:high]
        low = curr[:low]
        prev_close = prev[:close]

        next unless high && low && prev_close

        ranges = [high - low, (high - prev_close).abs, (low - prev_close).abs]
        ranges.compact.max
      end

      average(trs.last(period))
    end

    def supertrend(candles, period: 7, multiplier: 3)
      return if candles.size < period

      atr_value = atr(candles, period: period)
      return unless atr_value

      last_candle = candles.last
      hl2 = (decimal(last_candle[:high]) + decimal(last_candle[:low])) / 2
      basic_upper = hl2 + (multiplier * atr_value)
      basic_lower = hl2 - (multiplier * atr_value)

      close = decimal(last_candle[:close])
      return unless close

      trend = close > basic_upper ? :bearish : :bullish
      { trend: trend == :bearish ? :bearish : :bullish, band: trend == :bearish ? basic_upper : basic_lower }
    end

    def average(values)
      values = Array(values).compact.map { |value| decimal(value) }
      return BigDecimal(0) if values.empty?

      values.sum(BigDecimal(0)) / values.size
    end

    def decimal(value)
      return BigDecimal(0) if value.nil?

      BigDecimal(value.to_s)
    end
  end
end


# File: app/services/trading_system/base_service.rb
# frozen_string_literal: true

module TradingSystem
  class BaseService
    def start
      raise NotImplementedError, "#{self.class} must implement #start"
    end

    def stop
      raise NotImplementedError, "#{self.class} must implement #stop"
    end
  end
end


# File: app/services/trading_system/order_router.rb
module TradingSystem
  class OrderRouter < BaseService
    RETRY_COUNT = 3
    RETRY_BASE_SLEEP = 0.2

    def initialize(gateway: Orders.config.gateway)
      @gateway = gateway
    end

     # Required by BaseService (Supervisor calls start/stop)
     def start
      Rails.logger.info("[OrderRouter] ready (no-op)")
      true
    end

    def stop
      Rails.logger.info("[OrderRouter] stopped (no-op)")
      true
    end


    def exit_market(tracker)
      with_retries do
        @gateway.exit_market(tracker)
      end
    rescue StandardError => e
      Rails.logger.error("[OrderRouter] exit_market exception for #{tracker.order_no}: #{e.class} - #{e.message}")
      { success: false, error: e.message }
    end

    private

    def with_retries
      attempts = 0
      begin
        attempts += 1
        yield
      rescue StandardError => e
        raise if attempts >= RETRY_COUNT

        sleep RETRY_BASE_SLEEP * attempts
        retry
      end
    end
  end
end


# File: app/services/trading_system/position_heartbeat.rb
# frozen_string_literal: true

module TradingSystem
  class PositionHeartbeat
    INTERVAL = 10 # seconds

    def initialize
      @running = false
      @thread  = nil
    end

    def start
      return if @running
      @running = true

      @thread = Thread.new do
        Thread.current.name = "position-heartbeat"

        loop do
          break unless @running
          begin
            Live::PositionIndex.instance.bulk_load_active!
            Live::PositionTrackerPruner.call
          rescue => e
            Rails.logger.error("[PositionHeartbeat] #{e.class} - #{e.message}")
          end

          sleep INTERVAL
        end
      end
    end

    def stop
      @running = false
      @thread&.kill
      @thread = nil
    end
  end
end


# File: app/services/trading_system/signal_scheduler.rb
# frozen_string_literal: true

module TradingSystem
  class SignalScheduler < BaseService
    INTERVAL = 1 # seconds

    def initialize
      super
      @thread = nil
      @running = false
    end

    def start
      return if @running

      @running = true
      @thread = Thread.new { run_loop }
    end

    def stop
      @running = false
      @thread&.kill
      @thread = nil
    end

    private

    def run_loop
      loop do
        break unless @running

        begin
          perform_signal_scan
        rescue StandardError => e
          Rails.logger.error("[SignalScheduler] error: #{e.class} - #{e.message}")
        end

        sleep INTERVAL
      end
    end

    # Real logic (your existing scheduler call)
    def perform_signal_scan
      # This is equivalent to: Signal::Scheduler.instance.perform!
      ::Signal::Scheduler.new.perform!
    end
  end
end


# File: app/strategies/inside_bar_strategy.rb
# app/strategies/inside_bar_strategy.rb
# frozen_string_literal: true

class InsideBarStrategy
  attr_reader :series

  def initialize(series:)
    @series = series
  end

  # Generates entry signal at given candle index
  # Returns: { type: :ce/:pe, confidence: 0-100 } or nil
  def generate_signal(index)
    return nil if index < 2 # Need at least 2 bars
    return nil unless trading_hours?(series.candles[index])

    candle = series.candles[index]
    prev1 = series.candles[index - 1]
    prev2 = series.candles[index - 2]

    # Check if prev1 was an inside bar using CandleSeries helper method
    return nil unless series.inside_bar?(index - 1)

    # CE Signal: Breakout above inside bar high
    if candle.high > prev1.high && candle.close > prev1.high
      return { type: :ce, confidence: calculate_confidence(candle, prev1, prev2, :bullish) }
    end

    # PE Signal: Breakout below inside bar low
    if candle.low < prev1.low && candle.close < prev1.low
      return { type: :pe, confidence: calculate_confidence(candle, prev1, prev2, :bearish) }
    end

    nil
  end

  private

  def trading_hours?(candle)
    # Convert timestamp to IST timezone explicitly
    ist_time = candle.timestamp.in_time_zone('Asia/Kolkata')
    hour = ist_time.hour
    minute = ist_time.min

    # Only trade between 10:00 AM - 2:30 PM IST
    return false if hour < 10
    return false if hour > 14
    return false if hour == 14 && minute > 30

    true
  end


  def calculate_confidence(candle, inside_bar, parent, _direction)
    confidence = 60 # Base for inside bar breakout

    # Add confidence for strong breakout candle
    body_pct = candle_body_percent(candle)
    confidence += 10 if body_pct > 70
    confidence += 5 if body_pct > 60

    # Add confidence for clean inside bar (smaller range)
    inside_range = inside_bar.high - inside_bar.low
    parent_range = parent.high - parent.low
    return [confidence, 100].min if parent_range.zero?

    range_ratio = inside_range / parent_range
    confidence += 10 if range_ratio < 0.5 # Inside bar is <50% of parent

    # Add confidence for volume expansion on breakout
    if candle.volume > 0 && inside_bar.volume > 0
      confidence += 10 if candle.volume > inside_bar.volume * 1.3
    end

    [confidence, 100].min
  end

  def candle_body_percent(candle)
    range = candle.high - candle.low
    return 0 if range.zero?

    body = (candle.close - candle.open).abs
    (body / range * 100).round(2)
  end
end

# File: app/strategies/simple_momentum_strategy.rb
# app/strategies/simple_momentum_strategy.rb
# frozen_string_literal: true

class SimpleMomentumStrategy
  attr_reader :series

  def initialize(series:)
    @series = series
  end

  # Generates entry signal at given candle index
  # Returns: { type: :ce/:pe, confidence: 0-100 } or nil
  def generate_signal(index)
    return nil if index < 3 # Need at least 3 bars for momentum check
    return nil unless trading_hours?(series.candles[index])

    candle = series.candles[index]
    prev1 = series.candles[index - 1]
    prev2 = series.candles[index - 2]

    # Strategy: Strong directional candle with confirmation

    # CE Signal (Bullish)
    if bullish_setup?(candle, prev1, prev2)
      return { type: :ce, confidence: calculate_confidence(candle, prev1, prev2, :bullish) }
    end

    # PE Signal (Bearish)
    if bearish_setup?(candle, prev1, prev2)
      return { type: :pe, confidence: calculate_confidence(candle, prev1, prev2, :bearish) }
    end

    nil
  end

  private

  def trading_hours?(candle)
    # Convert timestamp to IST timezone explicitly
    ist_time = candle.timestamp.in_time_zone('Asia/Kolkata')
    hour = ist_time.hour
    minute = ist_time.min

    # Only trade between 10:00 AM - 2:30 PM IST
    return false if hour < 10
    return false if hour > 14
    return false if hour == 14 && minute > 30

    true
  end

  def bullish_setup?(candle, prev1, prev2)
    # Condition 1: Strong green candle (body > 70% of range)
    strong_candle = candle.bullish? && candle_body_percent(candle) > 70

    # Condition 2: Previous 2 candles also green (momentum)
    momentum = prev1.bullish? && prev2.bullish?

    # Condition 3: Closes in top 30% of range
    range = candle.high - candle.low
    return false if range.zero?

    closes_high = (candle.close - candle.low) / range > 0.70

    strong_candle && momentum && closes_high
  end

  def bearish_setup?(candle, prev1, prev2)
    # Condition 1: Strong red candle (body > 70% of range)
    strong_candle = candle.bearish? && candle_body_percent(candle) > 70

    # Condition 2: Previous 2 candles also red (momentum)
    momentum = prev1.bearish? && prev2.bearish?

    # Condition 3: Closes in bottom 30% of range
    range = candle.high - candle.low
    return false if range.zero?

    closes_low = (candle.close - candle.low) / range < 0.30

    strong_candle && momentum && closes_low
  end

  def candle_body_percent(candle)
    range = candle.high - candle.low
    return 0 if range.zero?

    body = (candle.close - candle.open).abs
    (body / range * 100).round(2)
  end

  def calculate_confidence(candle, prev1, prev2, direction)
    confidence = 50 # Base

    # Add confidence for strong body
    body_pct = candle_body_percent(candle)
    confidence += 10 if body_pct > 80
    confidence += 5 if body_pct > 75

    # Add confidence for consistent momentum
    if direction == :bullish
      confidence += 10 if prev1.close > prev2.close
      confidence += 10 if candle.close > prev1.high
    else
      confidence += 10 if prev1.close < prev2.close
      confidence += 10 if candle.close < prev1.low
    end

    # Add confidence for volume (if available)
    if candle.volume > 0 && prev1.volume > 0
      confidence += 10 if candle.volume > prev1.volume * 1.2
    end

    [confidence, 100].min
  end
end

# File: app/strategies/supertrend_adx_strategy.rb
# app/strategies/supertrend_adx_strategy.rb
# frozen_string_literal: true

class SupertrendAdxStrategy
  attr_reader :series, :supertrend_cfg, :adx_min_strength

  def initialize(series:, supertrend_cfg:, adx_min_strength: 20)
    @series = series
    @supertrend_cfg = supertrend_cfg
    @adx_min_strength = adx_min_strength
    @supertrend_result = nil
    @supertrend_calculated = false
  end

  # Generates entry signal at given candle index
  # Returns: { type: :ce/:pe, confidence: 0-100 } or nil
  def generate_signal(index)
    return nil if index < supertrend_cfg[:period] # Need enough bars for indicator calculation
    return nil unless trading_hours?(series.candles[index])

    # Calculate Supertrend once for the entire series (cached)
    calculate_supertrend_once unless @supertrend_calculated

    return nil if @supertrend_result.nil? || @supertrend_result[:trend].nil?

    # Get trend at current index
    trend_at_index = get_trend_at_index(index)
    return nil if trend_at_index.nil?

    # Calculate ADX from candles up to current index using CandleSeries helper
    partial_series = create_partial_series(index)
    adx_value = partial_series&.adx(14)
    return nil if adx_value.nil? || adx_value < adx_min_strength

    # Determine direction from supertrend
    direction = trend_at_index == :bullish ? :ce : :pe

    confidence = calculate_confidence(@supertrend_result, adx_value)

    confidence >= 60 ? { type: direction, confidence: confidence } : nil
  end

  private

  def calculate_supertrend_once
    # Calculate Supertrend once for the entire series
    st_service = Indicators::Supertrend.new(series: series, **supertrend_cfg)
    @supertrend_result = st_service.call
    @supertrend_calculated = true
  end

  def get_trend_at_index(index)
    return nil if @supertrend_result.nil?
    return nil if index >= @supertrend_result[:line].size

    # Determine trend at specific index by comparing close to supertrend line
    close = series.candles[index].close
    supertrend_value = @supertrend_result[:line][index]
    return nil if close.nil? || supertrend_value.nil?

    close >= supertrend_value ? :bullish : :bearish
  end

  def trading_hours?(candle)
    # Convert timestamp to IST timezone explicitly
    ist_time = candle.timestamp.in_time_zone('Asia/Kolkata')
    hour = ist_time.hour
    minute = ist_time.min

    # Active between 10:00 AM and 2:30 PM IST
    return false if hour < 10
    return false if hour > 14
    return false if hour == 14 && minute > 30

    true
  end

  def calculate_confidence(supertrend_result, adx)
    base = 50
    base += 30 if supertrend_result[:trend]
    base += 10 if adx > 30
    [base, 100].min
  end

  def create_partial_series(index)
    # Create a partial CandleSeries with candles up to the current index
    partial_series = CandleSeries.new(symbol: series.symbol, interval: series.interval)
    series.candles[0..index].each { |candle| partial_series.add_candle(candle) }
    partial_series
  end
end


# File: app/views/layouts/mailer.html.erb
<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <style>
      /* Email styles need to be inline */
    </style>
  </head>

  <body>
    <%= yield %>
  </body>
</html>


# File: app/views/layouts/mailer.text.erb
<%= yield %>


# File: lib/providers/dhanhq_provider.rb
# frozen_string_literal: true

module Providers
  class DhanhqProvider
    def initialize(client: default_client)
      @client = client
      @tick_cache = Live::RedisTickCache.instance
    end

    def underlying_spot(index)
      inst = index_config(index)
      raise "missing_index_config:#{index}" unless inst

      tick = @tick_cache.fetch_tick(inst[:segment], inst[:sid])
      tick&.dig(:ltp)&.to_f
    end

    def option_chain(index)
      inst = index_config(index)
      raise "missing_index_config:#{index}" unless inst
      raise 'dhanhq_client_missing' unless @client

      chain = @client.option_chain(inst[:key])
      Array(chain).map do |opt|
        {
          strike: opt.respond_to?(:strike) ? opt.strike : opt[:strike],
          type: opt.respond_to?(:option_type) ? opt.option_type : opt[:option_type],
          ltp: opt.respond_to?(:ltp) ? opt.ltp : opt[:ltp],
          bid: opt.respond_to?(:bid_price) ? opt.bid_price : opt[:bid_price],
          ask: opt.respond_to?(:ask_price) ? opt.ask_price : opt[:ask_price],
          oi: opt.respond_to?(:open_interest) ? opt.open_interest : opt[:open_interest],
          iv: opt.respond_to?(:iv) ? opt.iv : opt[:iv],
          volume: opt.respond_to?(:volume) ? opt.volume : opt[:volume]
        }
      end
    end

    private

    def index_config(index)
      key = index.to_s.upcase
      Array(AlgoConfig.fetch[:indices]).find { |cfg| cfg[:key].to_s.upcase == key }
    end

    def default_client
      DhanHQ::Client.new
    rescue StandardError => e
      Rails.logger.warn("[Providers::DhanhqProvider] Failed to build client: #{e.message}")
      nil
    end
  end
end



# File: lib/providers/mock_option_chain_provider.rb
# frozen_string_literal: true

module Providers
  class MockOptionChainProvider
    def initialize(spot_price: 20_000, strike_interval: 50)
      @spot_price = spot_price
      @strike_interval = strike_interval
    end

    def underlying_spot(_index)
      @spot_price
    end

    def option_chain(_index)
      atm_strike = (@spot_price / @strike_interval).round * @strike_interval
      strikes = generate_strikes(atm_strike)

      strikes.map do |strike|
        {
          strike: strike,
          type: strike >= atm_strike ? 'CE' : 'PE',
          ltp: calculate_mock_ltp(strike, atm_strike),
          bid: calculate_mock_bid(strike, atm_strike),
          ask: calculate_mock_ask(strike, atm_strike),
          oi: rand(50_000..1_000_000),
          iv: rand(15.0..35.0).round(2),
          volume: rand(1000..50_000),
          prev_close: calculate_mock_ltp(strike, atm_strike) * (0.95 + rand * 0.1)
        }
      end
    end

    private

    def generate_strikes(atm_strike)
      strikes = []
      (-3..3).each do |offset|
        strikes << atm_strike + (offset * @strike_interval)
      end
      strikes.select(&:positive?).sort
    end

    def calculate_mock_ltp(strike, atm_strike)
      distance = (strike - atm_strike).abs
      base_price = 100.0
      time_value = 50.0
      intrinsic = [atm_strike - strike, 0].max * 0.01
      (base_price + time_value - (distance * 0.5) + intrinsic).round(2)
    end

    def calculate_mock_bid(strike, atm_strike)
      ltp = calculate_mock_ltp(strike, atm_strike)
      (ltp * 0.995).round(2)
    end

    def calculate_mock_ask(strike, atm_strike)
      ltp = calculate_mock_ltp(strike, atm_strike)
      (ltp * 1.005).round(2)
    end
  end
end



# File: lib/services/option_chain_cache.rb
# frozen_string_literal: true

module Services
  class OptionChainCache
    CACHE_PREFIX = 'option_chain'
    DEFAULT_TTL = 3 # seconds (respects DhanHQ rate limit: 1 req / 3s)

    class << self
      def fetch(underlying_key:, expiry:, force_refresh: false)
        cache_key = build_cache_key(underlying_key, expiry)
        cached = force_refresh ? nil : redis.get(cache_key)

        return JSON.parse(cached) if cached

        nil
      end

      def store(underlying_key:, expiry:, chain_data:, ttl: DEFAULT_TTL)
        cache_key = build_cache_key(underlying_key, expiry)
        redis.setex(cache_key, ttl, chain_data.to_json)
      end

      def clear(underlying_key: nil, expiry: nil)
        if underlying_key && expiry
          cache_key = build_cache_key(underlying_key, expiry)
          redis.del(cache_key)
        else
          pattern = underlying_key ? "#{CACHE_PREFIX}:#{underlying_key}:*" : "#{CACHE_PREFIX}:*"
          redis.scan_each(match: pattern) { |key| redis.del(key) }
        end
      end

      private

      def build_cache_key(underlying_key, expiry)
        "#{CACHE_PREFIX}:#{underlying_key}:#{expiry}"
      end

      def redis
        @redis ||= Redis.new(url: ENV.fetch('REDIS_URL', 'redis://127.0.0.1:6379/0'))
      end
    end
  end
end



# File: lib/tasks/auto_annotate_models.rake
# frozen_string_literal: true

# NOTE: only doing this in development as some production environments (Heroku)
# NOTE: are sensitive to local FS writes, and besides -- it's just not proper
# NOTE: to have a dev-mode tool do its thing in production.
if Rails.env.development?
  task set_annotation_options: :environment do
    # You can override any of these by setting an environment variable of the
    # same name.
    Annotate.set_defaults({
                            'position_in_routes' => 'before',
                            'position_in_class' => 'before',
                            'position_in_test' => 'before',
                            'position_in_fixture' => 'before',
                            'position_in_factory' => 'before',
                            'show_indexes' => 'true',
                            'simple_indexes' => 'false',
                            'model_dir' => 'app/models',
                            'include_version' => 'false',
                            'require' => '',
                            'exclude_tests' => 'false',
                            'exclude_fixtures' => 'false',
                            'exclude_factories' => 'false',
                            'ignore_model_sub_dir' => 'false',
                            'skip_on_db_migrate' => 'false',
                            'format_bare' => 'true',
                            'format_rdoc' => 'false',
                            'format_markdown' => 'false',
                            'sort' => 'false',
                            'force' => 'false',
                            'trace' => 'false'
                          })
  end

  Annotate.load_tasks
end


# File: lib/tasks/backtest.rake
# lib/tasks/backtest.rake
# frozen_string_literal: true

namespace :backtest do
  # Ensure services are disabled during backtests
  task :env do
    ENV['BACKTEST_MODE'] = '1'
  end
  desc 'Run backtest on an instrument'
  task :run, %i[symbol interval days] => [:env, :environment] do |_t, args|
    symbol = args[:symbol] || 'NIFTY'
    interval = args[:interval] || '5'
    days = (args[:days] || '90').to_i

    puts "\n🔍 Running backtest..."
    puts "Symbol: #{symbol} | Interval: #{interval}min | Days: #{days}"

    result = BacktestService.run(
      symbol: symbol,
      interval: interval,
      days_back: days,
      strategy: SimpleMomentumStrategy
    )

    result.print_summary
  end

  desc 'Run backtest on all indices'
  task :indices, %i[interval days] => [:env, :environment] do |_t, args|
    interval = args[:interval] || '5'
    days = (args[:days] || '90').to_i

    symbols = %w[NIFTY BANKNIFTY SENSEX]

    symbols.each do |symbol|
      puts "\n#{'=' * 60}"
      puts "Testing #{symbol}..."
      puts '=' * 60

      result = BacktestService.run(
        symbol: symbol,
        interval: interval,
        days_back: days,
        strategy: SimpleMomentumStrategy
      )

      result.print_summary
      sleep 2 # Rate limit protection
    end
  end

  # desc 'Compare both strategies (SimpleMomentum vs InsideBar)'
  # task :compare, %i[symbol interval days] => :environment do |_t, args|
  #   symbol = args[:symbol] || 'NIFTY'
  #   interval = args[:interval] || '5'
  #   days = (args[:days] || '90').to_i

  #   puts "\n🔍 Comparing Strategies..."
  #   puts "Symbol: #{symbol} | Interval: #{interval}min | Days: #{days}"
  #   puts "\n#{'=' * 80}"

  #   strategies = [
  #     { name: 'SimpleMomentumStrategy', class: SimpleMomentumStrategy },
  #     { name: 'InsideBarStrategy', class: InsideBarStrategy }
  #   ]

  #   results = {}

  #   strategies.each do |strategy_info|
  #     puts "\n📊 Running #{strategy_info[:name]}..."
  #     puts '-' * 80

  #     result = BacktestService.run(
  #       symbol: symbol,
  #       interval: interval,
  #       days_back: days,
  #       strategy: strategy_info[:class]
  #     )

  #     results[strategy_info[:name]] = result.summary
  #     result.print_summary
  #     sleep 1 # Rate limit protection
  #   end

  #   # Comparison summary
  #   puts "\n#{'=' * 80}"
  #   puts '📈 COMPARISON SUMMARY'
  #   puts '=' * 80

  #   strategies.each do |strategy_info|
  #     name = strategy_info[:name]
  #     summary = results[name]

  #     next if summary.empty?

  #     puts "\n#{name}:"
  #     puts "  Total Trades:    #{summary[:total_trades]}"
  #     puts "  Win Rate:        #{summary[:win_rate]}%"
  #     puts "  Total P&L:       #{'+' if summary[:total_pnl_percent].positive?}#{summary[:total_pnl_percent]}%"
  #     puts "  Expectancy:      #{'+' if summary[:expectancy].positive?}#{summary[:expectancy]}% per trade"
  #     puts "  Avg Win:         +#{summary[:avg_win_percent]}%"
  #     puts "  Avg Loss:        #{summary[:avg_loss_percent]}%"
  #   end

  #   # Winner determination
  #   if results.values.all?(&:empty?)
  #     puts "\n⚠️  No trades executed by either strategy"
  #   else
  #     winner = results.max_by { |_name, summary| summary[:expectancy] || -999 }
  #     puts "\n🏆 Best Strategy: #{winner[0]} (Expectancy: #{winner[1][:expectancy]}%)"
  #   end

  #   puts "\n#{'=' * 80}"
  # end

  desc 'Compare strategies on an instrument'
  task :compare, %i[symbol interval days] => [:env, :environment] do |_t, args|
    symbol = args[:symbol] || 'NIFTY'
    interval = args[:interval] || '5'
    days = (args[:days] || '90').to_i

    puts "\n🔍 Comparing Strategies..."
    puts "Symbol: #{symbol} | Interval: #{interval}min | Days: #{days}"

    strategies = {
      'SimpleMomentumStrategy' => ->(series) { SimpleMomentumStrategy.new(series: series) },
      'InsideBarStrategy' => ->(series) { InsideBarStrategy.new(series: series) },
      'SupertrendAdxStrategy' => lambda { |series|
        SupertrendAdxStrategy.new(
          series: series,
          supertrend_cfg: AlgoConfig.fetch.dig(:signals, :supertrend) || { period: 7, multiplier: 3 },
          adx_min_strength: AlgoConfig.fetch.dig(:signals, :adx, :min_strength) || 20
        )
      }
    }

    strategies.each do |name, strategy_lambda|
      puts "\n============================================================"
      puts "📊 Running #{name}..."
      puts '--------------------------------------------------------------------------------'

      result = BacktestService.run(
        symbol: symbol,
        interval: interval,
        days_back: days,
        strategy: strategy_lambda
      )

      result.print_summary
    end

    puts "\n================================================================================"
    puts '📈 Comparison complete'
    puts '================================================================================'
  end

  desc 'Run comprehensive backtest on all indices and timeframes'
  task :all_indices, [:days] => [:env, :environment] do |_t, args|
    days = (args[:days] || '90').to_i
    symbols = %w[NIFTY BANKNIFTY SENSEX]
    intervals = %w[5 15]
    all_results = []

    strategies = {
      'SimpleMomentumStrategy' => ->(series) { SimpleMomentumStrategy.new(series: series) },
      'InsideBarStrategy' => ->(series) { InsideBarStrategy.new(series: series) },
      'SupertrendAdxStrategy' => lambda { |series|
        SupertrendAdxStrategy.new(
          series: series,
          supertrend_cfg: AlgoConfig.fetch.dig(:signals, :supertrend) || { period: 7, multiplier: 3 },
          adx_min_strength: AlgoConfig.fetch.dig(:signals, :adx, :min_strength) || 20
        )
      }
    }

    puts "\n" + ('=' * 100)
    puts '🚀 COMPREHENSIVE BACKTEST: All Indices × All Timeframes × All Strategies'
    puts '=' * 100
    puts "Days: #{days} | Symbols: #{symbols.join(', ')} | Intervals: #{intervals.join(', ')}min"
    puts '=' * 100

    symbols.each do |symbol|
      intervals.each do |interval|
        puts "\n" + ('=' * 100)
        puts "📊 #{symbol} - #{interval}min Timeframe"
        puts '=' * 100

        strategies.each do |strategy_name, strategy_lambda|
          puts "\n" + ('-' * 100)
          puts "  Strategy: #{strategy_name}"
          puts '-' * 100

          begin
            result = BacktestService.run(
              symbol: symbol,
              interval: interval,
              days_back: days,
              strategy: strategy_lambda
            )

            summary = result.summary
            next if summary.empty?

            all_results << {
              symbol: symbol,
              interval: interval,
              strategy: strategy_name,
              summary: summary
            }

            puts "  Total Trades:    #{summary[:total_trades]}"
            puts "  Win Rate:        #{summary[:win_rate]}%"
            puts "  Total P&L:       #{'+' if summary[:total_pnl_percent].positive?}#{summary[:total_pnl_percent]}%"
            puts "  Expectancy:      #{'+' if summary[:expectancy].positive?}#{summary[:expectancy]}% per trade"
            puts "  Avg Win:         +#{summary[:avg_win_percent]}%"
            puts "  Avg Loss:        #{summary[:avg_loss_percent]}%"
          rescue StandardError => e
            puts "  ❌ Error: #{e.message}"
            Rails.logger.error("[Backtest] Failed for #{symbol}/#{interval}min/#{strategy_name}: #{e.message}")
          end

          sleep 1 # Rate limit protection
        end
      end
    end

    # Summary of best results
    puts "\n" + ('=' * 100)
    puts '🏆 BEST RESULTS SUMMARY'
    puts '=' * 100

    if all_results.empty?
      puts "\n⚠️  No successful backtests completed"
      next
    end

    # Best by Expectancy
    best_expectancy = all_results.max_by { |r| r[:summary][:expectancy] || -999 }
    puts "\n📈 Best Expectancy:"
    puts "  #{best_expectancy[:symbol]} | #{best_expectancy[:interval]}min | #{best_expectancy[:strategy]}"
    puts "  Expectancy: #{best_expectancy[:summary][:expectancy]}% | Total P&L: #{best_expectancy[:summary][:total_pnl_percent]}% | Trades: #{best_expectancy[:summary][:total_trades]}"

    # Best by Total P&L
    best_pnl = all_results.max_by { |r| r[:summary][:total_pnl_percent] || -999 }
    puts "\n💰 Best Total P&L:"
    puts "  #{best_pnl[:symbol]} | #{best_pnl[:interval]}min | #{best_pnl[:strategy]}"
    puts "  Total P&L: #{best_pnl[:summary][:total_pnl_percent]}% | Expectancy: #{best_pnl[:summary][:expectancy]}% | Trades: #{best_pnl[:summary][:total_trades]}"

    # Best by Win Rate
    best_winrate = all_results.max_by { |r| r[:summary][:win_rate] || 0 }
    puts "\n🎯 Best Win Rate:"
    puts "  #{best_winrate[:symbol]} | #{best_winrate[:interval]}min | #{best_winrate[:strategy]}"
    puts "  Win Rate: #{best_winrate[:summary][:win_rate]}% | Expectancy: #{best_winrate[:summary][:expectancy]}% | Trades: #{best_winrate[:summary][:total_trades]}"

    # Top 5 by Expectancy
    puts "\n" + ('-' * 100)
    puts '📊 Top 5 by Expectancy:'
    puts '-' * 100
    top_5 = all_results.sort_by { |r| -(r[:summary][:expectancy] || -999) }.first(5)
    top_5.each_with_index do |result, idx|
      puts "  #{idx + 1}. #{result[:symbol]} | #{result[:interval]}min | #{result[:strategy]}"
      puts "     Expectancy: #{result[:summary][:expectancy]}% | P&L: #{result[:summary][:total_pnl_percent]}% | Win Rate: #{result[:summary][:win_rate]}% | Trades: #{result[:summary][:total_trades]}"
    end

    puts "\n" + ('=' * 100)
    puts "✅ Completed #{all_results.size} successful backtests"
    puts '=' * 100
  end

  desc 'Export backtest results to CSV'
  task :export, %i[symbol interval days output] => [:env, :environment] do |_t, args|
    symbol = args[:symbol] || 'NIFTY'
    interval = args[:interval] || '5'
    days = (args[:days] || '90').to_i
    output_file = args[:output] || "backtest_#{symbol}_#{Time.current.to_i}.csv"

    result = BacktestService.run(
      symbol: symbol,
      interval: interval,
      days_back: days,
      strategy: SimpleMomentumStrategy
    )

    summary = result.summary
    return puts 'No trades to export' if summary[:trades].blank?

    require 'csv'
    CSV.open(output_file, 'w') do |csv|
      # Headers
      csv << ['Signal Type', 'Entry Time', 'Entry Price', 'Exit Time', 'Exit Price', 'P&L %', 'Exit Reason', 'Bars Held']

      # Data
      summary[:trades].each do |trade|
        csv << [
          trade[:signal_type].to_s.upcase,
          trade[:entry_time],
          trade[:entry_price],
          trade[:exit_time],
          trade[:exit_price],
          trade[:pnl_percent],
          trade[:exit_reason],
          trade[:bars_held]
        ]
      end
    end

    puts "\n✅ Exported #{summary[:trades].size} trades to #{output_file}"
    result.print_summary
  end
end


# File: lib/tasks/instruments.rake
# frozen_string_literal: true

require 'pp'

namespace :instruments do
  desc 'Import instruments from DhanHQ CSV'
  task import: :environment do
    pp 'Starting instruments import...'
    start_time = Time.current

    begin
      result   = InstrumentsImporter.import_from_url
      duration = result[:duration] || (Time.current - start_time)
      pp "\nImport completed successfully in #{duration.round(2)} seconds!"
      pp "Total Instruments: #{result[:instrument_total]}"
      pp "Total Derivatives: #{result[:derivative_total]}"

      # Show some stats
      pp "\n--- Stats ---"
      pp "NSE Instruments: #{Instrument.nse.count}"
      pp "BSE Instruments: #{Instrument.bse.count}"
      pp "NSE Derivatives: #{Derivative.nse.count}"
      pp "BSE Derivatives: #{Derivative.bse.count}"
      pp "Options: #{Derivative.options.count}"
      pp "Futures: #{Derivative.futures.count}"
      pp 'Instruments: Instrument.count'
      pp 'Derivatives: Derivative.count'
      pp "TOTAL: #{Instrument.count + Derivative.count}"
    rescue StandardError => e
      pp "Import failed: #{e.message}"
      pp e.backtrace.join("\n")
    end
  end

  desc 'Reimport instruments and derivatives (upserts - adds new, updates existing, preserves positions)'
  task reimport: :environment do
    pp 'Starting instruments reimport (upsert mode)...'
    pp 'Note: Import uses upsert logic - will add new contracts and update existing ones.'
    pp 'Existing instruments/derivatives will NOT be deleted, so positions remain safe.'
    pp ''
    Rake::Task['instruments:import'].invoke
  end

  desc 'Clear all instruments and derivatives (DANGER: Will fail if active positions exist)'
  desc 'Only use this if you need to completely reset the database. Normal imports use upsert and do not require clearing.'
  task :clear, [:force] => :environment do |_t, args|
    pp '⚠️  WARNING: This will delete ALL instruments and derivatives!'
    pp '⚠️  This is usually NOT needed since imports use upsert (add/update only).'
    pp ''

    # Check for active position trackers that reference instruments
    active_trackers = PositionTracker.where(status: PositionTracker::STATUSES[:active])
    if active_trackers.any?
      pp "ERROR: Found #{active_trackers.count} active position tracker(s) that reference instruments."
      pp 'Active trackers:'
      active_trackers.limit(10).each do |tracker|
        pp "  - Order: #{tracker.order_no}, Instrument ID: #{tracker.instrument_id}, Status: #{tracker.status}, Symbol: #{tracker.symbol}"
      end

      if args[:force] == 'true'
        pp ''
        pp "FORCE mode enabled: Marking active position trackers as 'closed'..."
        active_trackers.update_all(
          status: PositionTracker::STATUSES[:closed],
          updated_at: Time.current
        )
        pp "Marked #{active_trackers.count} active tracker(s) as closed."
      else
        pp ''
        pp 'To force clear (will mark active positions as closed), run:'
        pp '  bin/rails instruments:clear[true]'
        pp 'Or manually close/exit positions first.'
        pp ''
        pp '💡 TIP: You probably don\'t need to clear - just run `bin/rails instruments:reimport`'
        pp '    which uses upsert and safely adds/updates without deleting.'
        raise 'Cannot clear instruments while active position trackers exist'
      end
    end

    # Delete inactive/closed trackers that reference instruments (to avoid FK constraint issues)
    inactive_trackers = PositionTracker.where.not(status: PositionTracker::STATUSES[:active])
    if inactive_trackers.any?
      pp "Found #{inactive_trackers.count} inactive/closed position tracker(s)."
      if args[:force] == 'true'
        pp 'FORCE mode: Deleting inactive trackers to avoid FK constraints...'
        inactive_trackers.delete_all
        pp "Deleted #{inactive_trackers.count} inactive tracker(s)."
      else
        pp 'These will cause FK constraint errors. To delete them, use force mode:'
        pp '  bin/rails instruments:clear[true]'
        pp '⚠️  Or they will prevent instrument deletion.'
      end
    end

    pp ''
    pp 'Proceeding with deletion of all instruments and derivatives...'
    # Now safe to delete derivatives and instruments
    Derivative.delete_all
    Instrument.delete_all
    pp '✅ Cleared successfully!'
  end

  desc 'Check instrument inventory freshness and counts'
  task status: :environment do
    last_import_raw = Setting.fetch('instruments.last_imported_at')

    unless last_import_raw
      pp 'No instrument import recorded yet.'
      exit 1
    end

    imported_at = Time.zone.parse(last_import_raw.to_s)
    age_seconds = Time.current - imported_at
    max_age     = InstrumentsImporter::CACHE_MAX_AGE

    pp "Last import at: #{imported_at}"
    pp "Age (seconds): #{age_seconds.round(2)}"
    pp "Import duration (sec): #{Setting.fetch('instruments.last_import_duration_sec', 'unknown')}"
    pp "Last instrument rows: #{Setting.fetch('instruments.last_instrument_rows', '0')}"
    pp "Last derivative rows: #{Setting.fetch('instruments.last_derivative_rows', '0')}"
    pp "Upserts (instruments): #{Setting.fetch('instruments.last_instrument_upserts', '0')}"
    pp "Upserts (derivatives): #{Setting.fetch('instruments.last_derivative_upserts', '0')}"
    pp "Total instruments: #{Setting.fetch('instruments.instrument_total', '0')}"
    pp "Total derivatives: #{Setting.fetch('instruments.derivative_total', '0')}"

    if age_seconds > max_age
      pp "Status: STALE (older than #{max_age.inspect})"
      exit 1
    end

    pp 'Status: OK'
  rescue ArgumentError => e
    pp "Failed to parse last import timestamp: #{e.message}"
    exit 1
  end
end

# Provide aliases for legacy singular namespace usage.
namespace :instrument do
  desc 'Alias for instruments:import'
  task import: 'instruments:import'

  desc 'Alias for instruments:clear'
  task clear: 'instruments:clear'

  desc 'Alias for instruments:reimport'
  task reimport: 'instruments:reimport'
end


# File: lib/tasks/position.rake
# frozen_string_literal: true

namespace :position do
  desc 'Sync positions between DhanHQ and PositionTracker database'
  task sync: :environment do
    puts 'Starting position synchronization...'

    begin
      Live::PositionSyncService.instance.force_sync!
      puts 'Position synchronization completed successfully!'
    rescue StandardError => e
      puts "Position synchronization failed: #{e.class} - #{e.message}"
      exit 1
    end
  end

  desc 'Show position sync status'
  task status: :environment do
    puts 'Position Sync Status:'
    puts '===================='

    begin
      # Count DhanHQ positions
      dhan_positions = DhanHQ::Models::Position.active
      puts "DhanHQ Active Positions: #{dhan_positions.size}"

      # Count tracked positions
      tracked_positions = PositionTracker.active
      puts "Tracked Positions: #{tracked_positions.size}"

      # Show untracked positions
      tracked_security_ids = tracked_positions.pluck(:security_id).map(&:to_s)
      untracked = dhan_positions.reject do |pos|
        security_id = pos.security_id
        tracked_security_ids.include?(security_id.to_s)
      end

      puts "Untracked Positions: #{untracked.size}"

      if untracked.any?
        puts "\nUntracked Position Details:"
        untracked.each do |pos|
          security_id = pos.security_id
          symbol = pos.trading_symbol
          puts "  - #{security_id}: #{symbol}"
        end
      end
    rescue StandardError => e
      puts "Failed to get position status: #{e.class} - #{e.message}"
      exit 1
    end
  end
end


# File: lib/tasks/redis_pnl_inspect.rake
# lib/tasks/redis_pnl_inspect.rake
namespace :redis do
  desc "Inspect pnl:tracker:* keys with color-coded PnL"
  task inspect: :environment do
    redis = Redis.new(url: ENV.fetch('REDIS_URL', 'redis://localhost:6379/0'))
    keys = redis.keys('pnl:tracker:*')
    if keys.empty?
      puts "No pnl:tracker keys found."
      next
    end

    keys.each do |key|
      data = redis.hgetall(key)
      pnl = data['pnl']&.to_f
      pnl_pct = data['pnl_pct']&.to_f
      ltp = data['ltp']&.to_f
      updated = Time.at(data['updated_at'].to_i).strftime('%H:%M:%S')

      color =
        if pnl.to_f > 0
          "\e[32m"  # green
        elsif pnl.to_f < 0
          "\e[31m"  # red
        else
          "\e[33m"  # yellow
        end

      puts "#{color}#{key.ljust(25)} PnL=#{pnl.round(2)} (#{(pnl_pct * 100).round(2)}%) LTP=#{ltp.round(2)} updated=#{updated}\e[0m"
    end
  end
end


# File: lib/tasks/test_ws.rake
# frozen_string_literal: true

namespace :test do
  desc 'Test WebSocket connection and LTP retrieval for subscribed instruments'
  task :ws, [:instruments, :segment, :wait] => :environment do |_t, args|
    instruments = args[:instruments]
    segment = args[:segment] || 'IDX_I'
    wait_seconds = (args[:wait] || '15').to_i

    load File.expand_path('ws_connection_test.rb', __dir__)
    result = WsConnectionTest.run(
      instruments: instruments,
      segment: segment,
      wait_seconds: wait_seconds
    )

    exit(result[:success] ? 0 : 1)
  end
end



# File: lib/tasks/ws_connection_test.rb
# frozen_string_literal: true

# WebSocket Connection Test Script
# Tests WS connection and LTP retrieval for subscribed instruments
#
# Usage (via Rails runner):
#   rails runner lib/tasks/ws_connection_test.rb
#   rails runner lib/tasks/ws_connection_test.rb NIFTY,BANKNIFTY
#   rails runner lib/tasks/ws_connection_test.rb NIFTY --segment=IDX_I --wait=20
#
# Usage (via Rake task):
#   rake test:ws
#   rake test:ws[NIFTY,BANKNIFTY]
#   rake test:ws[NIFTY,IDX_I,20]

module WsConnectionTest
  class << self
    def run(instruments: nil, segment: 'IDX_I', wait_seconds: 15)
      # Detect market status
      market_status = detect_market_status

      puts "\n" + "=" * 80
      puts "WebSocket Connection & LTP Test"
      puts "=" * 80
      puts "\nConfiguration:"
      puts "  Segment: #{segment}"
      puts "  Wait time: #{wait_seconds} seconds"
      puts "  Instruments: #{instruments || 'from config'}"
      puts "\nMarket Status:"
      puts "  Trading Day: #{market_status[:is_trading_day] ? '✅ Yes' : '❌ No (Weekend/Holiday)'}"
      puts "  Market Hours: #{market_status[:status]}"
      puts "  Expectation: #{market_status[:expectation]}"
      puts "\n"

      # Step 1: Check if WS hub is running
      puts "[1/5] Checking WebSocket Hub Status..."
      hub = Live::MarketFeedHub.instance

      unless hub.running?
        puts "❌ FAIL: WebSocket hub is NOT running"
        puts "\nDiagnostics:"

        # Check if credentials are configured
        client_id = ENV['DHANHQ_CLIENT_ID'].presence || ENV['CLIENT_ID'].presence
        access_token = ENV['DHANHQ_ACCESS_TOKEN'].presence || ENV['ACCESS_TOKEN'].presence

        if client_id.blank? || access_token.blank?
          puts "   ❌ DhanHQ credentials not configured"
          puts "      Required: DHANHQ_CLIENT_ID (or CLIENT_ID)"
          puts "      Required: DHANHQ_ACCESS_TOKEN (or ACCESS_TOKEN)"
          puts "\n   To fix: Set credentials in environment variables or .env file"
          return { success: false, error: 'credentials_missing', message: 'DhanHQ credentials not configured' }
        else
          puts "   ✅ DhanHQ credentials found"
        end

        puts "\nAttempting to start WebSocket hub..."
        begin
          if hub.start!
            puts "✅ WebSocket hub started successfully"
          else
            puts "❌ FAIL: Could not start WebSocket hub (start! returned false)"
            puts "   Possible causes:"
            puts "   - DhanHQ API connectivity issues"
            puts "   - Invalid credentials"
            puts "   - Network/firewall blocking WebSocket connections"
            puts "   - DhanHQ service temporarily unavailable"
            return { success: false, error: 'hub_start_failed', message: 'WebSocket hub failed to start' }
          end
        rescue StandardError => e
          puts "❌ FAIL: Error starting WebSocket hub: #{e.class} - #{e.message}"
          puts "   Check logs for detailed error information"
          return { success: false, error: 'hub_start_error', message: e.message, exception: e.class.to_s }
        end
      else
        puts "✅ WebSocket hub is running"
      end

      # Step 2: Determine test instruments
      puts "\n[2/5] Determining test instruments..."
      test_instruments = if instruments
                           parse_instruments(instruments, segment)
                         else
                           load_from_config(segment)
                         end

      if test_instruments.empty?
        puts "❌ FAIL: No instruments found to test"
        return { success: false, error: 'no_instruments' }
      end

      puts "✅ Found #{test_instruments.size} instrument(s) to test:"
      test_instruments.each do |inst|
        puts "   - #{inst[:key]} (#{inst[:segment]}:#{inst[:security_id]})"
      end

      # Step 3: Subscribe to instruments
      puts "\n[3/5] Subscribing to instruments..."
      subscribed = []
      test_instruments.each do |inst|
        begin
          hub.subscribe(segment: inst[:segment], security_id: inst[:security_id])
          subscribed << inst
          puts "   ✅ Subscribed: #{inst[:key]} (#{inst[:segment]}:#{inst[:security_id]})"
        rescue StandardError => e
          puts "   ❌ Failed to subscribe #{inst[:key]}: #{e.message}"
        end
      end

      if subscribed.empty?
        puts "❌ FAIL: Could not subscribe to any instruments"
        return { success: false, error: 'subscription_failed' }
      end

      # Step 4: Wait for ticks and verify
      puts "\n[4/5] Waiting #{wait_seconds} seconds for tick data..."
      if market_status[:is_market_hours]
        puts "   (Listening for live ticks during market hours...)"
        puts "   ⚠️  During market hours: Expecting multiple live ticks"
      else
        puts "   (Market closed - verifying WebSocket connection with stale ticks...)"
        puts "   ⚠️  After market hours: Need at least one tick to verify connection"
      end

      received_ticks = {}
      tick_listener = lambda do |tick|
        key = "#{tick[:segment]}:#{tick[:security_id]}"
        received_ticks[key] = {
          ltp: tick[:ltp],
          timestamp: Time.current,
          raw: tick
        }
        puts "   📊 Tick received: #{key} → LTP: #{tick[:ltp]}"
      end

      # Register callback using proper API
      hub.on_tick(&tick_listener)

      sleep(wait_seconds)

      # Step 5: Verify LTPs from cache
      puts "\n[5/5] Verifying LTP retrieval from cache..."
      results = {}
      all_passed = true

      subscribed.each do |inst|
        key = "#{inst[:segment]}:#{inst[:security_id]}"
        tick_key = "#{inst[:segment]}:#{inst[:security_id]}"

        # Try TickCache first (in-memory)
        tick_cache_ltp = Live::TickCache.ltp(inst[:segment], inst[:security_id])

        # Try RedisPnlCache second
        redis_tick = Live::RedisPnlCache.instance.fetch_tick(segment: inst[:segment], security_id: inst[:security_id])
        redis_ltp = redis_tick&.dig(:ltp)

        # Check if we received tick during wait period
        received_tick = received_ticks[tick_key]

        result = {
          key: inst[:key],
          segment: inst[:segment],
          security_id: inst[:security_id],
          subscribed: true,
          tick_received: !received_tick.nil?,
          tick_cache_ltp: tick_cache_ltp,
          redis_cache_ltp: redis_ltp,
          last_received: received_tick&.dig(:timestamp),
          success: false
        }

        # Success criteria depends on market hours
        if market_status[:is_market_hours]
          # During market hours: Must receive live tick during wait period
          if received_tick
            result[:success] = true
            result[:ltp_source] = 'Live tick (market hours)'
            result[:final_ltp] = received_tick[:ltp]
            puts "   ✅ #{inst[:key]}: LTP = #{result[:final_ltp]} (Live tick received)"
          elsif tick_cache_ltp || redis_ltp
            result[:success] = true
            result[:ltp_source] = tick_cache_ltp ? 'TickCache (in-memory)' : 'RedisPnlCache'
            result[:final_ltp] = tick_cache_ltp || redis_ltp
            puts "   ⚠️  #{inst[:key]}: LTP = #{result[:final_ltp]} (#{result[:ltp_source]} - cached, no live tick received)"
          else
            result[:success] = false
            all_passed = false
            puts "   ❌ #{inst[:key]}: No LTP found - expected live tick during market hours"
          end
        else
          # After market hours/weekend: Cached data is acceptable, but we still need at least one tick
          # to verify WebSocket connection is working
          if received_tick
            result[:success] = true
            result[:ltp_source] = 'Stale tick received (market closed)'
            result[:final_ltp] = received_tick[:ltp]
            puts "   ✅ #{inst[:key]}: LTP = #{result[:final_ltp]} (#{result[:ltp_source]})"
          elsif tick_cache_ltp || redis_ltp
            result[:success] = true
            result[:ltp_source] = tick_cache_ltp ? 'TickCache (cached, no fresh tick)' : 'RedisPnlCache (cached, no fresh tick)'
            result[:final_ltp] = tick_cache_ltp || redis_ltp
            puts "   ⚠️  #{inst[:key]}: LTP = #{result[:final_ltp]} (#{result[:ltp_source]})"
            puts "      Note: No fresh tick received during wait - WebSocket may not be streaming"
          else
            result[:success] = false
            all_passed = false
            puts "   ❌ #{inst[:key]}: No LTP found - WebSocket connection may not be working"
          end
        end

        results[inst[:key]] = result
      end

      # Summary
      puts "\n" + "=" * 80
      puts "Test Summary"
      puts "=" * 80
      puts "\nWebSocket Hub: #{hub.running? ? '✅ Running' : '❌ Not Running'}"
      puts "Market Status: #{market_status[:status]}"
      puts "Instruments Tested: #{subscribed.size}"
      successful_count = results.values.count { |r| r[:success] }
      puts "Instruments with LTP: #{successful_count}"
      puts "Success Rate: #{successful_count}/#{subscribed.size}"

      ticks_received = results.values.count { |r| r[:tick_received] }
      if market_status[:is_market_hours]
        puts "Live Ticks Received: #{ticks_received}/#{subscribed.size}"
        if ticks_received < subscribed.size
          puts "⚠️  Warning: Not all instruments received live ticks during market hours"
        end
      else
        puts "Ticks Received (stale/cached): #{ticks_received}/#{subscribed.size}"
        if ticks_received.zero?
          puts "⚠️  Warning: No ticks received - WebSocket connection may not be working"
          puts "   (Even during non-market hours, we expect at least one tick to verify connection)"
        elsif ticks_received < subscribed.size
          puts "⚠️  Warning: Some instruments did not receive ticks"
        end
      end

      puts "\nDetailed Results:"
      results.each do |key, result|
        status = result[:success] ? '✅' : '❌'
        puts "  #{status} #{key}:"
        puts "     Subscribed: #{result[:subscribed] ? 'Yes' : 'No'}"
        puts "     Tick Received: #{result[:tick_received] ? 'Yes' : 'No'}"
        puts "     TickCache LTP: #{result[:tick_cache_ltp] || 'N/A'}"
        puts "     RedisCache LTP: #{result[:redis_cache_ltp] || 'N/A'}"
        if result[:success]
          puts "     ✅ Final LTP: #{result[:final_ltp]} (from #{result[:ltp_source]})"
        end
      end

      # Additional validation: Even during non-market hours, we need at least one tick
      # to verify WebSocket connection is actually working
      overall_success = all_passed && subscribed.size == successful_count
      if !market_status[:is_market_hours]
        # After market hours/weekend: Require at least one tick to verify connection
        if ticks_received.zero?
          overall_success = false
          puts "\n⚠️  CRITICAL: No ticks received during wait period"
          puts "   Even when market is closed, we need at least one tick to verify WebSocket connection"
          puts "   This indicates WebSocket may not be properly connected or streaming"
        end
      end

      puts "\n" + "=" * 80
      if overall_success
        puts "✅ ALL TESTS PASSED"
        puts "=" * 80
        { success: true, results: results, market_status: market_status }
      else
        puts "❌ SOME TESTS FAILED"
        puts "=" * 80
        puts "\nNext Steps:"
        unless hub.running?
          puts "1. Ensure WebSocket hub is running: Live::MarketFeedHub.instance.start!"
        end
        if ticks_received.zero?
          puts "2. Verify WebSocket connection is active and receiving ticks"
          puts "3. Check DhanHQ credentials: DHANHQ_CLIENT_ID and DHANHQ_ACCESS_TOKEN"
        end
        puts "4. Review application logs for WebSocket errors"
        puts "=" * 80
        { success: false, results: results, market_status: market_status }
      end
    end

    private

    def detect_market_status
      current_time = Time.zone.now
      hour = current_time.hour
      minute = current_time.min

      # Check if it's a trading day (not weekend/holiday)
      is_trading_day = begin
        Market::Calendar.trading_day_today?
      rescue StandardError
        # Fallback: simple weekend check
        !current_time.saturday? && !current_time.sunday?
      end

      # Market hours: 9:15 AM to 3:30 PM IST
      market_open = hour > 9 || (hour == 9 && minute >= 15)
      market_closed = hour > 15 || (hour == 15 && minute >= 30)
      is_market_hours = market_open && !market_closed

      status = if !is_trading_day
                 'Weekend/Holiday (Market Closed)'
               elsif !market_open
                 "Pre-Market (Before 9:15 AM)"
               elsif market_closed
                 "Post-Market (After 3:30 PM)"
               else
                 'Market Open (9:15 AM - 3:30 PM IST)'
               end

      expectation = if !is_trading_day
                      'At least one stale tick to verify connection (no live ticks)'
                    elsif is_market_hours
                      'Live ticks expected (multiple ticks during wait period)'
                    else
                      'At least one stale tick to verify connection (no live ticks)'
                    end

      {
        is_trading_day: is_trading_day,
        is_market_hours: is_market_hours && is_trading_day,
        status: status,
        expectation: expectation,
        current_time: current_time.strftime('%Y-%m-%d %H:%M:%S %Z')
      }
    end

    def parse_instruments(instruments_str, segment)
      instruments_str.split(',').map do |key|
        key = key.strip.upcase
        # Look up security_id from Instrument table
        inst = Instrument.find_by(symbol_name: key, segment: Instrument.segment_key_for(segment))
        if inst
          {
            key: key,
            segment: inst.exchange_segment,
            security_id: inst.security_id
          }
        else
          # Fallback: use config to find security_id
          config = AlgoConfig.fetch[:indices]&.find { |i| i[:key] == key }
          if config
            {
              key: key,
              segment: config[:segment] || segment,
              security_id: config[:sid]
            }
          else
            puts "⚠️  Warning: Could not find instrument #{key}"
            nil
          end
        end
      end.compact
    end

    def load_from_config(segment)
      indices = AlgoConfig.fetch[:indices] || []
      indices.map do |cfg|
        next unless cfg[:segment] == segment || segment == 'IDX_I'

        {
          key: cfg[:key],
          segment: cfg[:segment] || segment,
          security_id: cfg[:sid]
        }
      end.compact
    end
  end
end

# Main execution
if __FILE__ == $PROGRAM_NAME || defined?(Rails::Console)
  # Parse command line arguments
  instruments = ARGV.find { |a| !a.start_with?('--') }
  segment = ARGV.find { |a| a.start_with?('--segment=') }&.split('=')&.last || 'IDX_I'
  wait_arg = ARGV.find { |a| a.start_with?('--wait=') }&.split('=')&.last
  wait_seconds = wait_arg ? wait_arg.to_i : 15

  result = WsConnectionTest.run(
    instruments: instruments,
    segment: segment,
    wait_seconds: wait_seconds
  )

  exit(result[:success] ? 0 : 1)
end



# File: lib/tasks/ws_feed_diagnostics.rake
# frozen_string_literal: true

namespace :ws do
  desc 'Check WebSocket market feed diagnostics'
  task diagnostics: :environment do
    load File.expand_path('ws_feed_diagnostics.rb', __dir__)
    WsFeedDiagnostics.run
  end
end



# File: lib/tasks/ws_feed_diagnostics.rb
# frozen_string_literal: true

# WebSocket Market Feed Diagnostics
# Usage: bundle exec rails runner "load 'lib/tasks/ws_feed_diagnostics.rb'"

module WsFeedDiagnostics
  class << self
    def run
      puts "\n" + "=" * 80
      puts "WebSocket Market Feed Diagnostics"
      puts "=" * 80
      puts

      hub = Live::MarketFeedHub.instance
      diagnostics = hub.diagnostics

      # Hub Status
      puts "📊 Hub Status:"
      puts "  Running: #{diagnostics[:hub_status][:running] ? '✅ Yes' : '❌ No'}"
      puts "  Connected: #{diagnostics[:hub_status][:connected] ? '✅ Yes' : '❌ No'}"
      puts "  Connection State: #{diagnostics[:hub_status][:connection_state].to_s.upcase}"
      puts "  Started At: #{diagnostics[:hub_status][:started_at] || 'Not started'}"
      puts "  Last Tick: #{diagnostics[:last_tick]}"
      puts "  Watchlist Size: #{diagnostics[:hub_status][:watchlist_size]}"
      puts

      # Credentials
      puts "🔐 Credentials:"
      puts "  Client ID: #{diagnostics[:credentials][:client_id]}"
      puts "  Access Token: #{diagnostics[:credentials][:access_token]}"
      puts

      # Configuration
      puts "⚙️  Configuration:"
      puts "  Enabled: #{diagnostics[:enabled] ? '✅ Yes' : '❌ No'}"
      puts "  Mode: #{diagnostics[:mode]}"
      puts

      # Last Error
      if diagnostics[:last_error_details]
        puts "❌ Last Error:"
        error = diagnostics[:last_error_details]
        puts "  Error: #{error[:error]}"
        puts "  At: #{error[:at]}"
        puts
      end

      # Feed Health Service
      puts "🏥 Feed Health Service:"
      begin
        health_service = Live::FeedHealthService.instance
        ticks_stale = health_service.stale?(:ticks)
        puts "  Ticks Feed: #{ticks_stale ? '❌ STALE' : '✅ Healthy'}"

        if ticks_stale
          threshold_overrides = health_service.instance_variable_get(:@threshold_overrides) rescue {}
          threshold = threshold_overrides[:ticks] ||
                      Live::FeedHealthService::DEFAULT_THRESHOLDS[:ticks]
          puts "  Threshold: #{threshold} seconds"

          timestamps = health_service.instance_variable_get(:@timestamps) rescue {}
          last_seen = timestamps[:ticks]
          if last_seen
            seconds_ago = (Time.current - last_seen).round(1)
            puts "  Last Success: #{seconds_ago} seconds ago"
          else
            puts "  Last Success: Never"
          end

          failures = health_service.instance_variable_get(:@failures) rescue {}
          failure_info = failures[:ticks]
          if failure_info
            puts "  Last Failure: #{failure_info[:error]}"
            puts "  Failure At: #{failure_info[:at]}"
          end
        end
      rescue StandardError => e
        puts "  ⚠️  Could not check FeedHealthService: #{e.message}"
      end
      puts

      # Recommendations
      puts "💡 Recommendations:"
      recommendations = []

      unless diagnostics[:hub_status][:running]
        recommendations << "  - Start the hub: Live::MarketFeedHub.instance.start!"
      end

      unless diagnostics[:hub_status][:connected]
        if diagnostics[:hub_status][:running]
          recommendations << "  - Hub is running but not connected - check WebSocket connection"
          recommendations << "  - Verify DhanHQ credentials are valid and not expired"
          recommendations << "  - Check network connectivity to DhanHQ servers"
        end
      end

      if diagnostics[:last_tick] == 'Never' && diagnostics[:hub_status][:running]
        recommendations << "  - No ticks received - verify subscriptions and market status"
      end

      if ticks_stale
        recommendations << "  - Ticks feed is stale - investigate connection issues"
      end

      if diagnostics[:last_error_details]
        recommendations << "  - Review last error and check application logs"
      end

      if recommendations.empty?
        puts "  ✅ No issues detected!"
      else
        recommendations.each { |rec| puts rec }
      end

      puts
      puts "=" * 80

      # Return summary
      {
        healthy: diagnostics[:hub_status][:running] &&
                 diagnostics[:hub_status][:connected] &&
                 !ticks_stale,
        diagnostics: diagnostics
      }
    end
  end
end

# Run diagnostics if loaded directly
WsFeedDiagnostics.run if __FILE__ == $PROGRAM_NAME || defined?(Rails::Console)



# File: config/initializers/algo_config.rb
# frozen_string_literal: true

# Load algo configuration from config/algo.yml
Rails.application.configure do
  begin
    algo_config = YAML.load_file(Rails.root.join('config', 'algo.yml'), aliases: true)
    config.x.algo = ActiveSupport::InheritableOptions.new(algo_config.deep_symbolize_keys)
    # Rails.logger.info("[AlgoConfig] Loaded algo configuration with #{algo_config[:indices]&.size || 0} indices")
  rescue StandardError => e
    # Rails.logger.error("[AlgoConfig] Failed to load algo configuration: #{e.message}")
    config.x.algo = ActiveSupport::InheritableOptions.new({})
  end
end


# File: config/initializers/cors.rb
# Be sure to restart your server when you modify this file.

# Avoid CORS issues when API is called from the frontend app.
# Handle Cross-Origin Resource Sharing (CORS) in order to accept cross-origin Ajax requests.

# Read more: https://github.com/cyu/rack-cors

Rails.application.config.middleware.insert_before 0, Rack::Cors do
  allow do
    origins "*"

    resource "*",
      headers: :any,
      methods: [ :get, :post, :put, :patch, :delete, :options, :head ]
  end
end


# File: config/initializers/dhanhq_config.rb
# frozen_string_literal: true

require "dhan_hq"

# Normalize environment variables to support both naming conventions
# The DhanHQ gem expects variables with DHAN_ prefix (or CLIENT_ID/ACCESS_TOKEN)
# We support both DHANHQ_ and DHAN_ prefixes for flexibility

# Required credentials - support both naming conventions
ENV['CLIENT_ID'] ||= ENV['DHANHQ_CLIENT_ID'] if ENV['DHANHQ_CLIENT_ID'].present?
ENV['ACCESS_TOKEN'] ||= ENV['DHANHQ_ACCESS_TOKEN'] if ENV['DHANHQ_ACCESS_TOKEN'].present?

# Optional gem configuration - normalize DHANHQ_ prefix to DHAN_ prefix for gem compatibility
# The gem's configure_with_env reads directly from ENV with DHAN_ prefix
ENV['DHAN_BASE_URL'] ||= ENV['DHANHQ_BASE_URL'] if ENV['DHANHQ_BASE_URL'].present?
ENV['DHAN_WS_VERSION'] ||= ENV['DHANHQ_WS_VERSION'] if ENV['DHANHQ_WS_VERSION'].present?
ENV['DHAN_WS_ORDER_URL'] ||= ENV['DHANHQ_WS_ORDER_URL'] if ENV['DHANHQ_WS_ORDER_URL'].present?
ENV['DHAN_WS_MARKET_FEED_URL'] ||= ENV['DHANHQ_WS_MARKET_FEED_URL'] if ENV['DHANHQ_WS_MARKET_FEED_URL'].present?
ENV['DHAN_WS_MARKET_DEPTH_URL'] ||= ENV['DHANHQ_WS_MARKET_DEPTH_URL'] if ENV['DHANHQ_WS_MARKET_DEPTH_URL'].present?
ENV['DHAN_MARKET_DEPTH_LEVEL'] ||= ENV['DHANHQ_MARKET_DEPTH_LEVEL'] if ENV['DHANHQ_MARKET_DEPTH_LEVEL'].present?
ENV['DHAN_WS_USER_TYPE'] ||= ENV['DHANHQ_WS_USER_TYPE'] if ENV['DHANHQ_WS_USER_TYPE'].present?
ENV['DHAN_PARTNER_ID'] ||= ENV['DHANHQ_PARTNER_ID'] if ENV['DHANHQ_PARTNER_ID'].present?
ENV['DHAN_PARTNER_SECRET'] ||= ENV['DHANHQ_PARTNER_SECRET'] if ENV['DHANHQ_PARTNER_SECRET'].present?
ENV['DHAN_LOG_LEVEL'] ||= ENV['DHANHQ_LOG_LEVEL'] if ENV['DHANHQ_LOG_LEVEL'].present?

# Bootstrap DhanHQ from ENV only
# The gem reads: CLIENT_ID, ACCESS_TOKEN, and all DHAN_* variables
DhanHQ.configure_with_env

# Set logger level (supports both DHAN_LOG_LEVEL and DHANHQ_LOG_LEVEL via normalization above)
level_name = (ENV["DHAN_LOG_LEVEL"] || "INFO").upcase
begin
  DhanHQ.logger.level = Logger.const_get(level_name)
rescue NameError
  DhanHQ.logger.level = Logger::INFO
end

# Configure Rails app settings for DhanHQ integration
Rails.application.configure do
  config.x.dhanhq = ActiveSupport::InheritableOptions.new(
    enabled: !Rails.env.test?,  # Disable in test environment
    ws_enabled: !Rails.env.test?,  # Disable WebSocket in test environment
    order_ws_enabled: !Rails.env.test?,  # Disable order WebSocket in test environment
    enable_order_logging: ENV["ENABLE_ORDER"] == "true",  # Order payload logging
    ws_mode: (ENV["DHANHQ_WS_MODE"] || "quote").to_sym,
    ws_watchlist: ENV["DHANHQ_WS_WATCHLIST"],
    order_ws_url: ENV["DHANHQ_WS_ORDER_URL"],
    ws_user_type: ENV["DHANHQ_WS_USER_TYPE"],
    partner_id: ENV["DHANHQ_PARTNER_ID"],
    partner_secret: ENV["DHANHQ_PARTNER_SECRET"]
  )
end


# File: config/initializers/filter_parameter_logging.rb
# Be sure to restart your server when you modify this file.

# Configure parameters to be partially matched (e.g. passw matches password) and filtered from the log file.
# Use this to limit dissemination of sensitive information.
# See the ActiveSupport::ParameterFilter documentation for supported notations and behaviors.
Rails.application.config.filter_parameters += [
  :passw, :email, :secret, :token, :_key, :crypt, :salt, :certificate, :otp, :ssn, :cvv, :cvc
]


# File: config/initializers/inflections.rb
# Be sure to restart your server when you modify this file.

# Add new inflection rules using the following format. Inflections
# are locale specific, and you may define rules for as many different
# locales as you wish. All of these examples are active by default:
# ActiveSupport::Inflector.inflections(:en) do |inflect|
#   inflect.plural /^(ox)$/i, "\\1en"
#   inflect.singular /^(ox)en/i, "\\1"
#   inflect.irregular "person", "people"
#   inflect.uncountable %w( fish sheep )
# end

# These inflection rules are supported but not enabled by default:
# ActiveSupport::Inflector.inflections(:en) do |inflect|
#   inflect.acronym "RESTful"
# end


# File: config/initializers/market_stream.rb
# # frozen_string_literal: true

# module MarketStreamLifecycle
#   module_function

#   def safely_start
#     yield
#   rescue NameError
#     nil
#   end

#   def safely_stop
#     yield
#   rescue NameError
#     nil
#   end

#   # Resubscribe to all active PositionTracker positions after server restart
#   def resubscribe_active_positions
#     return unless defined?(PositionTracker)

#     # Wait a moment for MarketFeedHub to be ready
#     sleep(0.5)

#     # Can't eagerly load polymorphic :watchable, so just load instrument
#     active_positions = PositionTracker.active.includes(:instrument).to_a
#     return if active_positions.empty?

#     subscribed_count = 0
#     failed_count = 0

#     active_positions.each do |tracker|
#       begin
#         tracker.subscribe
#         subscribed_count += 1
#       rescue StandardError => e
#         Rails.logger.error("[MarketStream] Failed to resubscribe position #{tracker.order_no}: #{e.message}")
#         failed_count += 1
#       end
#     end

#     Rails.logger.info("[MarketStream] Resubscribed to #{subscribed_count} active positions#{failed_count.positive? ? " (#{failed_count} failed)" : ''}")
#   rescue StandardError => e
#     Rails.logger.error("[MarketStream] Failed to resubscribe active positions: #{e.class} - #{e.message}")
#   end
# end

# # Rails.application.config.to_prepare do
# #   # Skip automated trading services in console mode and test environment
# #   is_rake = defined?(Rake)
# #   backtest_env = ENV['BACKTEST_MODE'] == '1'
# #   backtest_task = is_rake && Rake.application.respond_to?(:top_level_tasks) && Rake.application.top_level_tasks.any? { |t| t.start_with?('backtest:') }
# #   skip_services = Rails.const_defined?(:Console) || Rails.env.test? || backtest_env || backtest_task

# #   unless skip_services
# #     # 1️⃣ Start Market Feed Hub
# #     MarketStreamLifecycle.safely_start { Live::MarketFeedHub.instance.start! }

# #     # DISABLED: Order Update WebSocket Handler
# #     # We use PositionSyncService polling approach instead for simplicity:
# #     # - PositionSyncService periodically polls DhanHQ REST API for active positions (every 30s)
# #     # - On sync, it finds untracked positions and creates PositionTracker records
# #     # - Active positions are automatically subscribed to market feed WebSocket
# #     # - This polling approach is simpler, more reliable, and sufficient for our use case
# #     # - Real-time order updates are not critical since position status changes are eventually consistent
# #     #
# #     # If you need real-time order updates (< 1s latency), uncomment the line below:
# #     # MarketStreamLifecycle.safely_start { Live::OrderUpdateHandler.instance.start! }

# #     # 2️⃣ Start Signal Scheduler # Start trading scheduler (signals → entries)
# #     MarketStreamLifecycle.safely_start { Signal::Scheduler.instance.start! }

# #     # 3️⃣ Start Risk Manager Service
# #     MarketStreamLifecycle.safely_start { Live::RiskManagerService.instance.start! }

# #     # 4️⃣ Start new PnL Updater Service # Start real-time PnL updater (computes pnl:tracker data every second from TickCache)
# #     # Start PnL updater service (batch writer) — start after market feed hub is up
# #     MarketStreamLifecycle.safely_start do
# #       # tiny delay to let MarketFeedHub/TickCache populate initial ticks
# #       Thread.new do
# #         sleep 0.5
# #         Live::PnlUpdaterService.instance.start!
# #       end
# #     end

# #     # 5️⃣ Resubscribe & Sync Positions (syncs positions from DhanHQ and creates PositionTracker records) # Resubscribe to all active positions after MarketFeedHub starts
# #     MarketStreamLifecycle.safely_start { resubscribe_active_positions }

# #     # Perform initial position sync to ensure all DhanHQ positions are tracked
# #     MarketStreamLifecycle.safely_start { Live::PositionSyncService.instance.force_sync! }
# #   else
# #     # Rails.logger.info("[MarketStream] Skipping automated trading services in #{Rails.const_defined?(:Console) ? 'console' : 'test'} mode")
# #   end
# # end

# # # Graceful shutdown handler
# # def shutdown_services
# #   return if Rails.const_defined?(:Console) || Rails.env.test?

# #   Rails.logger.info('[MarketStream] Shutting down services...') if defined?(Rails.logger)

# #   # Stop all services in reverse order of startup
# #   MarketStreamLifecycle.safely_stop { Live::PnlUpdaterService.instance.stop! }
# #   MarketStreamLifecycle.safely_stop { Live::RiskManagerService.instance.stop! }
# #   MarketStreamLifecycle.safely_stop { Signal::Scheduler.instance.stop! }
# #   MarketStreamLifecycle.safely_stop { Live::MarketFeedHub.instance.stop! }
# #   # DISABLED: Order Update Handler stop (not started - see above)
# #   # MarketStreamLifecycle.safely_stop { Live::OrderUpdateHandler.instance.stop! }

# #   # Disconnect all WebSocket connections
# #   MarketStreamLifecycle.safely_stop { DhanHQ::WS.disconnect_all_local! }

# #   Rails.logger.info('[MarketStream] Services shut down successfully') if defined?(Rails.logger)
# # rescue StandardError => e
# #   Rails.logger.error("[MarketStream] Error during shutdown: #{e.class} - #{e.message}") if defined?(Rails.logger)
# # end

# # # Register signal handlers for graceful shutdown on Ctrl+C (SIGINT) or kill (SIGTERM)
# # %w[INT TERM].each do |signal|
# #   Signal.trap(signal) do
# #     Rails.logger.info("[MarketStream] Received #{signal} signal, shutting down...") if defined?(Rails.logger)
# #     shutdown_services
# #     exit(0)
# #   end
# # end

# # # Also register at_exit hook as fallback
# # at_exit do
# #   shutdown_services
# # end

# # frozen_string_literal: true

# # Skip in console and tests
# return if Rails.const_defined?(:Console) || Rails.env.test?

# Rails.application.config.after_initialize do
#   # ensure services start only once per process
#   unless defined?($market_stream_started) && $market_stream_started
#     $market_stream_started = true

#     # --- SERVICE STARTUP ---
#     MarketStreamLifecycle.safely_start { Live::MarketFeedHub.instance.start! }
#     MarketStreamLifecycle.safely_start { Signal::Scheduler.instance.start! }
#     MarketStreamLifecycle.safely_start { Live::RiskManagerService.instance.start! }

#     Thread.new do
#       sleep(0.5)
#       MarketStreamLifecycle.safely_start { Live::PnlUpdaterService.instance.start! }
#     end

#     MarketStreamLifecycle.safely_start { MarketStreamLifecycle.resubscribe_active_positions }
#     MarketStreamLifecycle.safely_start { Live::PositionSyncService.instance.force_sync! }

#     # --- REGISTER ONE-TIME SIGNAL HANDLERS ---
#     %w[INT TERM].each do |signal|
#       Signal.trap(signal) do
#         Rails.logger.info("[MarketStream] Received #{signal}, shutting down...") if defined?(Rails.logger)
#         shutdown_services
#         exit(0)
#       end
#     end

#     # --- AT EXIT ---
#     at_exit do
#       shutdown_services
#     end
#   end
# end

# def shutdown_services
#   return if Rails.const_defined?(:Console) || Rails.env.test?

#   Rails.logger.info('[MarketStream] Shutting down services...') if defined?(Rails.logger)

#   MarketStreamLifecycle.safely_stop { Live::PnlUpdaterService.instance.stop! }
#   MarketStreamLifecycle.safely_stop { Live::RiskManagerService.instance.stop! }
#   MarketStreamLifecycle.safely_stop { Signal::Scheduler.instance.stop! }
#   MarketStreamLifecycle.safely_stop { Live::MarketFeedHub.instance.stop! }
#   MarketStreamLifecycle.safely_stop { DhanHQ::WS.disconnect_all_local! }

#   Rails.logger.info('[MarketStream] Services shut down successfully') if defined?(Rails.logger)
# rescue => e
#   Rails.logger.error("[MarketStream] Shutdown error: #{e.class} - #{e.message}") if defined?(Rails.logger)
# end


# File: config/initializers/mock_data_service.rb
# Start mock data service if WebSocket is disabled
Rails.application.config.after_initialize do
  if Rails.env.development? && !Rails.env.test? && ENV["DHANHQ_WS_ENABLED"] == "false"
    # Rails.logger.info("[MockData] Starting mock data service (WebSocket disabled)")
    Live::MockDataService.instance.start!
  end
end


# File: config/initializers/nemesis_feed_listener.rb
# frozen_string_literal: true

# NEMESIS V3 FeedListener Initializer
# Starts FeedListener to process ticks and emit events via EventBus
# This is optional - FeedListener can also be started manually

# Skip in console and tests
return if Rails.const_defined?(:Console) || Rails.env.test?

Rails.application.config.after_initialize do
  # Start FeedListener after MarketFeedHub (if enabled)
  # FeedListener subscribes to MarketFeedHub callbacks, so it's safe to start anytime

  if ENV.fetch('NEMESIS_FEED_LISTENER_ENABLED', 'true') == 'true'
    Live::FeedListener.instance.start!
    Rails.logger.info('[Nemesis] FeedListener started')
  else
    Rails.logger.debug('[Nemesis] FeedListener disabled via NEMESIS_FEED_LISTENER_ENABLED')
  end
rescue StandardError => e
  Rails.logger.warn("[Nemesis] Failed to start FeedListener: #{e.class} - #{e.message}")
  # Non-fatal - system continues without FeedListener
end


# File: config/initializers/orders_gateway.rb
# frozen_string_literal: true

Rails.application.config.to_prepare do
  module Orders
    class << self
      attr_accessor :config
    end
  end

  paper_enabled =
    begin
      AlgoConfig.fetch.dig(:paper_trading, :enabled) == true
    rescue
      true
    end

  gateway = if paper_enabled
              Orders::GatewayPaper.new
            else
              Orders::GatewayLive.new
            end

  # Set structured config, not raw gateway
  Orders.config = Orders::Config.new(gateway: gateway)

  Rails.logger.info("[Orders] Using #{gateway.class.name}")
end


# File: config/initializers/sidekiq.rb
# frozen_string_literal: true

if defined?(Sidekiq)
  redis_url = ENV.fetch("REDIS_URL", "redis://localhost:6379/0")

  Sidekiq.configure_server do |config|
    config.redis = { url: redis_url }
  end

  Sidekiq.configure_client do |config|
    config.redis = { url: redis_url }
  end
end


# File: config/initializers/trading_supervisor.rb
# frozen_string_literal: true

# --------------------------------------------------------------------
# RUN ONLY INSIDE PUMA/RAILS WEB SERVER (bin/dev or rails s)
# --------------------------------------------------------------------

if Rails.env.test? ||
  defined?(Rails::Console) ||
  (defined?(Rails::Generators) && Rails::Generators.const_defined?(:Base))
 return
end

# bin/dev uses Puma, not Rails::Server
is_web_process =
 $PROGRAM_NAME.include?("puma") ||
 $PROGRAM_NAME.include?("rails") ||
 ENV["WEB_CONCURRENCY"].present?

return unless is_web_process

# --------------------------------------------------------------------
# SUPERVISOR - NO SINGLETONS
# --------------------------------------------------------------------
module TradingSystem
 class Supervisor
   def initialize
     @services = {}     # { name => service_instance }
     @running  = false
   end

   def register(name, instance)
     @services[name] = instance
   end

   def [](name)
     @services[name]
   end

   def start_all
     return if @running

     @services.each do |name, service|
       begin
         service.start
         Rails.logger.info("[Supervisor] started #{name}")
       rescue => e
         Rails.logger.error("[Supervisor] failed starting #{name}: #{e.class} - #{e.message}")
       end
     end

     @running = true
   end

   def stop_all
     return unless @running

     @services.reverse_each do |name, service|
       begin
         service.stop
         Rails.logger.info("[Supervisor] stopped #{name}")
       rescue => e
         Rails.logger.error("[Supervisor] error stopping #{name}: #{e.class} - #{e.message}")
       end
     end

     @running = false
   end
 end
end

# --------------------------------------------------------------------
# SERVICE ADAPTERS
# --------------------------------------------------------------------

# Wrap Live::MarketFeedHub singleton
class MarketFeedHubService
 def initialize
   @hub = Live::MarketFeedHub.instance
 end

 def start
   @hub.start!
 end

 def stop
   @hub.stop!
 end

 def subscribe_many(list)
   @hub.subscribe_many(list)
 end
end

# Wrap your existing PnlUpdaterService singleton
class PnlUpdaterServiceAdapter
 def initialize
   @svc = Live::PnlUpdaterService.instance
 end

 def start
   @svc.start!
 end

 def stop
   @svc.stop!
 end
end

# --------------------------------------------------------------------
# INITIALIZER (runs on each reload in dev)
# --------------------------------------------------------------------
Rails.application.config.to_prepare do
  supervisor = TradingSystem::Supervisor.new

  # # Register services through adapters
  # supervisor.register(:market_feed, MarketFeedHubService.new)
  # supervisor.register(:signal_scheduler, Signal::Scheduler.new)
  # supervisor.register(:risk_manager,     Live::RiskManagerService.new)
  # supervisor.register(:position_heartbeat, TradingSystem::PositionHeartbeat.new)
  # supervisor.register(:order_router, TradingSystem::OrderRouter.new)
  # supervisor.register(:position_heartbeat, TradingSystem::PositionHeartbeat.new)
  # supervisor.register(:paper_pnl_refresher, Live::PaperPnlRefresher.new)
  # supervisor.register(
  #   :exit_manager,
  #   Live::ExitEngine.new(order_router: TradingSystem::OrderRouter.new)
  # )

  feed = MarketFeedHubService.new
  router = TradingSystem::OrderRouter.new

  supervisor.register(:market_feed, feed)
  supervisor.register(:signal_scheduler, Signal::Scheduler.new)
  supervisor.register(:risk_manager,     Live::RiskManagerService.new)
  supervisor.register(:position_heartbeat, TradingSystem::PositionHeartbeat.new)
  supervisor.register(:order_router, router)
  supervisor.register(:paper_pnl_refresher, Live::PaperPnlRefresher.new)
  supervisor.register(:exit_manager, Live::ExitEngine.new(order_router: router))




 # Future:
 # supervisor.register(:pnl_updater, PnlUpdaterServiceAdapter.new)
 # supervisor.register(:risk_manager, TradingSystem::RiskManager.new)
 # supervisor.register(:order_router, TradingSystem::OrderRouter.new)

 unless defined?($trading_supervisor_started) && $trading_supervisor_started
   $trading_supervisor_started = true

   supervisor.start_all

   # ----------------------------------------------------
   # SUBSCRIBE ACTIVE POSITIONS VIA PositionIndex
   # ----------------------------------------------------
   active_pairs = Live::PositionIndex.instance.all_keys.map do |k|
     seg, sid = k.split(":", 2)
     { segment: seg, security_id: sid }
   end

   if active_pairs.any?
     supervisor[:market_feed].subscribe_many(active_pairs)
   end

   # ----------------------------------------------------
   # SIGNAL HANDLERS (CTRL+C)
   # ----------------------------------------------------
   %w[INT TERM].each do |sig|
     Signal.trap(sig) do
       Rails.logger.info("[TradingSupervisor] Received #{sig}, shutting down...")
       supervisor.stop_all
       exit(0)
     end
   end

   # ----------------------------------------------------
   # at_exit fallback
   # ----------------------------------------------------
   at_exit do
     supervisor.stop_all
   end
 end

 Rails.application.config.x.trading_supervisor = supervisor
end


